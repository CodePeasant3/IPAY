// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: tensorflow/core/framework/step_stats.proto
// Protobuf C++ Version: 5.29.0

#include "tensorflow/core/framework/step_stats.pb.h"

#include <algorithm>
#include <type_traits>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/generated_message_tctable_impl.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace tensorflow {

inline constexpr MemoryStats::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : persistent_tensor_alloc_ids_{},
        _persistent_tensor_alloc_ids_cached_byte_size_{0},
        device_persistent_tensor_alloc_ids_{},
        _device_persistent_tensor_alloc_ids_cached_byte_size_{0},
        temp_memory_size_{::int64_t{0}},
        device_temp_memory_size_{::int64_t{0}},
        persistent_memory_size_{::int64_t{0}},
        device_persistent_memory_size_{::int64_t{0}},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR MemoryStats::MemoryStats(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct MemoryStatsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR MemoryStatsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~MemoryStatsDefaultTypeInternal() {}
  union {
    MemoryStats _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 MemoryStatsDefaultTypeInternal _MemoryStats_default_instance_;
              template <typename>
PROTOBUF_CONSTEXPR DeviceStepStats_ThreadNamesEntry_DoNotUse::DeviceStepStats_ThreadNamesEntry_DoNotUse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : DeviceStepStats_ThreadNamesEntry_DoNotUse::MapEntry(_class_data_.base()){}
#else   // PROTOBUF_CUSTOM_VTABLE
    : DeviceStepStats_ThreadNamesEntry_DoNotUse::MapEntry() {
}
#endif  // PROTOBUF_CUSTOM_VTABLE
struct DeviceStepStats_ThreadNamesEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR DeviceStepStats_ThreadNamesEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~DeviceStepStats_ThreadNamesEntry_DoNotUseDefaultTypeInternal() {}
  union {
    DeviceStepStats_ThreadNamesEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 DeviceStepStats_ThreadNamesEntry_DoNotUseDefaultTypeInternal _DeviceStepStats_ThreadNamesEntry_DoNotUse_default_instance_;

inline constexpr AllocationRecord::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : alloc_micros_{::int64_t{0}},
        alloc_bytes_{::int64_t{0}},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR AllocationRecord::AllocationRecord(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct AllocationRecordDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AllocationRecordDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~AllocationRecordDefaultTypeInternal() {}
  union {
    AllocationRecord _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AllocationRecordDefaultTypeInternal _AllocationRecord_default_instance_;

inline constexpr AllocatorMemoryUsed::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : allocation_records_{},
        allocator_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        total_bytes_{::int64_t{0}},
        peak_bytes_{::int64_t{0}},
        live_bytes_{::int64_t{0}},
        allocator_bytes_in_use_{::int64_t{0}},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR AllocatorMemoryUsed::AllocatorMemoryUsed(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct AllocatorMemoryUsedDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AllocatorMemoryUsedDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~AllocatorMemoryUsedDefaultTypeInternal() {}
  union {
    AllocatorMemoryUsed _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AllocatorMemoryUsedDefaultTypeInternal _AllocatorMemoryUsed_default_instance_;

inline constexpr NodeOutput::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        tensor_description_{nullptr},
        slot_{0} {}

template <typename>
PROTOBUF_CONSTEXPR NodeOutput::NodeOutput(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct NodeOutputDefaultTypeInternal {
  PROTOBUF_CONSTEXPR NodeOutputDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~NodeOutputDefaultTypeInternal() {}
  union {
    NodeOutput _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 NodeOutputDefaultTypeInternal _NodeOutput_default_instance_;

inline constexpr NodeExecStats::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        memory_{},
        output_{},
        referenced_tensor_{},
        node_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        timeline_label_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        memory_stats_{nullptr},
        all_start_micros_{::int64_t{0}},
        op_start_rel_micros_{::int64_t{0}},
        op_end_rel_micros_{::int64_t{0}},
        all_end_rel_micros_{::int64_t{0}},
        scheduled_micros_{::int64_t{0}},
        all_start_nanos_{::int64_t{0}},
        op_start_rel_nanos_{::int64_t{0}},
        op_end_rel_nanos_{::int64_t{0}},
        all_end_rel_nanos_{::int64_t{0}},
        scheduled_nanos_{::int64_t{0}},
        thread_id_{0u} {}

template <typename>
PROTOBUF_CONSTEXPR NodeExecStats::NodeExecStats(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct NodeExecStatsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR NodeExecStatsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~NodeExecStatsDefaultTypeInternal() {}
  union {
    NodeExecStats _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 NodeExecStatsDefaultTypeInternal _NodeExecStats_default_instance_;

inline constexpr DeviceStepStats::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : node_stats_{},
        thread_names_{},
        device_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR DeviceStepStats::DeviceStepStats(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct DeviceStepStatsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR DeviceStepStatsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~DeviceStepStatsDefaultTypeInternal() {}
  union {
    DeviceStepStats _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 DeviceStepStatsDefaultTypeInternal _DeviceStepStats_default_instance_;

inline constexpr StepStats::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : dev_stats_{},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR StepStats::StepStats(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct StepStatsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR StepStatsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~StepStatsDefaultTypeInternal() {}
  union {
    StepStats _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 StepStatsDefaultTypeInternal _StepStats_default_instance_;
}  // namespace tensorflow
static constexpr const ::_pb::EnumDescriptor**
    file_level_enum_descriptors_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto = nullptr;
static constexpr const ::_pb::ServiceDescriptor**
    file_level_service_descriptors_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto = nullptr;
const ::uint32_t
    TableStruct_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto::offsets[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
        protodesc_cold) = {
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocationRecord, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocationRecord, _impl_.alloc_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocationRecord, _impl_.alloc_bytes_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.allocator_name_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.total_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.peak_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.live_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.allocation_records_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::AllocatorMemoryUsed, _impl_.allocator_bytes_in_use_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeOutput, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeOutput, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeOutput, _impl_.slot_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeOutput, _impl_.tensor_description_),
        ~0u,
        0,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.temp_memory_size_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.persistent_memory_size_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.persistent_tensor_alloc_ids_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.device_temp_memory_size_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.device_persistent_memory_size_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::MemoryStats, _impl_.device_persistent_tensor_alloc_ids_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.node_name_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.all_start_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.op_start_rel_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.op_end_rel_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.all_end_rel_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.memory_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.output_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.timeline_label_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.scheduled_micros_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.thread_id_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.referenced_tensor_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.memory_stats_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.all_start_nanos_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.op_start_rel_nanos_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.op_end_rel_nanos_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.all_end_rel_nanos_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::NodeExecStats, _impl_.scheduled_nanos_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.key_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.value_),
        0,
        1,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats, _impl_.device_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats, _impl_.node_stats_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::DeviceStepStats, _impl_.thread_names_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::StepStats, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::StepStats, _impl_.dev_stats_),
};

static const ::_pbi::MigrationSchema
    schemas[] ABSL_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
        {0, -1, -1, sizeof(::tensorflow::AllocationRecord)},
        {10, -1, -1, sizeof(::tensorflow::AllocatorMemoryUsed)},
        {24, 34, -1, sizeof(::tensorflow::NodeOutput)},
        {36, -1, -1, sizeof(::tensorflow::MemoryStats)},
        {50, 75, -1, sizeof(::tensorflow::NodeExecStats)},
        {92, 102, -1, sizeof(::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse)},
        {104, -1, -1, sizeof(::tensorflow::DeviceStepStats)},
        {115, -1, -1, sizeof(::tensorflow::StepStats)},
};
static const ::_pb::Message* const file_default_instances[] = {
    &::tensorflow::_AllocationRecord_default_instance_._instance,
    &::tensorflow::_AllocatorMemoryUsed_default_instance_._instance,
    &::tensorflow::_NodeOutput_default_instance_._instance,
    &::tensorflow::_MemoryStats_default_instance_._instance,
    &::tensorflow::_NodeExecStats_default_instance_._instance,
    &::tensorflow::_DeviceStepStats_ThreadNamesEntry_DoNotUse_default_instance_._instance,
    &::tensorflow::_DeviceStepStats_default_instance_._instance,
    &::tensorflow::_StepStats_default_instance_._instance,
};
const char descriptor_table_protodef_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
    protodesc_cold) = {
    "\n*tensorflow/core/framework/step_stats.p"
    "roto\022\ntensorflow\0326tensorflow/core/framew"
    "ork/allocation_description.proto\0322tensor"
    "flow/core/framework/tensor_description.p"
    "roto\"=\n\020AllocationRecord\022\024\n\014alloc_micros"
    "\030\001 \001(\003\022\023\n\013alloc_bytes\030\002 \001(\003\"\304\001\n\023Allocato"
    "rMemoryUsed\022\026\n\016allocator_name\030\001 \001(\t\022\023\n\013t"
    "otal_bytes\030\002 \001(\003\022\022\n\npeak_bytes\030\003 \001(\003\022\022\n\n"
    "live_bytes\030\004 \001(\003\0228\n\022allocation_records\030\006"
    " \003(\0132\034.tensorflow.AllocationRecord\022\036\n\026al"
    "locator_bytes_in_use\030\005 \001(\003\"U\n\nNodeOutput"
    "\022\014\n\004slot\030\001 \001(\005\0229\n\022tensor_description\030\003 \001"
    "(\0132\035.tensorflow.TensorDescription\"\354\001\n\013Me"
    "moryStats\022\030\n\020temp_memory_size\030\001 \001(\003\022\036\n\026p"
    "ersistent_memory_size\030\003 \001(\003\022#\n\033persisten"
    "t_tensor_alloc_ids\030\005 \003(\003\022#\n\027device_temp_"
    "memory_size\030\002 \001(\003B\002\030\001\022)\n\035device_persiste"
    "nt_memory_size\030\004 \001(\003B\002\030\001\022.\n\"device_persi"
    "stent_tensor_alloc_ids\030\006 \003(\003B\002\030\001\"\236\004\n\rNod"
    "eExecStats\022\021\n\tnode_name\030\001 \001(\t\022\030\n\020all_sta"
    "rt_micros\030\002 \001(\003\022\033\n\023op_start_rel_micros\030\003"
    " \001(\003\022\031\n\021op_end_rel_micros\030\004 \001(\003\022\032\n\022all_e"
    "nd_rel_micros\030\005 \001(\003\022/\n\006memory\030\006 \003(\0132\037.te"
    "nsorflow.AllocatorMemoryUsed\022&\n\006output\030\007"
    " \003(\0132\026.tensorflow.NodeOutput\022\026\n\016timeline"
    "_label\030\010 \001(\t\022\030\n\020scheduled_micros\030\t \001(\003\022\021"
    "\n\tthread_id\030\n \001(\r\022<\n\021referenced_tensor\030\013"
    " \003(\0132!.tensorflow.AllocationDescription\022"
    "-\n\014memory_stats\030\014 \001(\0132\027.tensorflow.Memor"
    "yStats\022\027\n\017all_start_nanos\030\r \001(\003\022\032\n\022op_st"
    "art_rel_nanos\030\016 \001(\003\022\030\n\020op_end_rel_nanos\030"
    "\017 \001(\003\022\031\n\021all_end_rel_nanos\030\020 \001(\003\022\027\n\017sche"
    "duled_nanos\030\021 \001(\003\"\310\001\n\017DeviceStepStats\022\016\n"
    "\006device\030\001 \001(\t\022-\n\nnode_stats\030\002 \003(\0132\031.tens"
    "orflow.NodeExecStats\022B\n\014thread_names\030\003 \003"
    "(\0132,.tensorflow.DeviceStepStats.ThreadNa"
    "mesEntry\0322\n\020ThreadNamesEntry\022\013\n\003key\030\001 \001("
    "\r\022\r\n\005value\030\002 \001(\t:\0028\001\";\n\tStepStats\022.\n\tdev"
    "_stats\030\001 \003(\0132\033.tensorflow.DeviceStepStat"
    "sB\203\001\n\030org.tensorflow.frameworkB\017StepStat"
    "sProtosP\001ZQgithub.com/tensorflow/tensorf"
    "low/tensorflow/go/core/framework/step_st"
    "ats_go_proto\370\001\001b\006proto3"
};
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto_deps[2] =
    {
        &::descriptor_table_tensorflow_2fcore_2fframework_2fallocation_5fdescription_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fframework_2ftensor_5fdescription_2eproto,
};
static ::absl::once_flag descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto_once;
PROTOBUF_CONSTINIT const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto = {
    false,
    false,
    1703,
    descriptor_table_protodef_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    "tensorflow/core/framework/step_stats.proto",
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto_once,
    descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto_deps,
    2,
    8,
    schemas,
    file_default_instances,
    TableStruct_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto::offsets,
    file_level_enum_descriptors_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
};
namespace tensorflow {
// ===================================================================

class AllocationRecord::_Internal {
 public:
};

AllocationRecord::AllocationRecord(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.AllocationRecord)
}
AllocationRecord::AllocationRecord(
    ::google::protobuf::Arena* arena, const AllocationRecord& from)
    : AllocationRecord(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE AllocationRecord::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void AllocationRecord::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, alloc_micros_),
           0,
           offsetof(Impl_, alloc_bytes_) -
               offsetof(Impl_, alloc_micros_) +
               sizeof(Impl_::alloc_bytes_));
}
AllocationRecord::~AllocationRecord() {
  // @@protoc_insertion_point(destructor:tensorflow.AllocationRecord)
  SharedDtor(*this);
}
inline void AllocationRecord::SharedDtor(MessageLite& self) {
  AllocationRecord& this_ = static_cast<AllocationRecord&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* AllocationRecord::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) AllocationRecord(arena);
}
constexpr auto AllocationRecord::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(AllocationRecord),
                                            alignof(AllocationRecord));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull AllocationRecord::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_AllocationRecord_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &AllocationRecord::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<AllocationRecord>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &AllocationRecord::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<AllocationRecord>(), &AllocationRecord::ByteSizeLong,
            &AllocationRecord::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_._cached_size_),
        false,
    },
    &AllocationRecord::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* AllocationRecord::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 0, 2> AllocationRecord::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::AllocationRecord>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int64 alloc_bytes = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocationRecord, _impl_.alloc_bytes_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_bytes_)}},
    // int64 alloc_micros = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocationRecord, _impl_.alloc_micros_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_micros_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int64 alloc_micros = 1;
    {PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_micros_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 alloc_bytes = 2;
    {PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_bytes_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void AllocationRecord::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.AllocationRecord)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.alloc_micros_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.alloc_bytes_) -
      reinterpret_cast<char*>(&_impl_.alloc_micros_)) + sizeof(_impl_.alloc_bytes_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* AllocationRecord::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const AllocationRecord& this_ = static_cast<const AllocationRecord&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* AllocationRecord::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const AllocationRecord& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.AllocationRecord)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int64 alloc_micros = 1;
          if (this_._internal_alloc_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<1>(
                    stream, this_._internal_alloc_micros(), target);
          }

          // int64 alloc_bytes = 2;
          if (this_._internal_alloc_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_alloc_bytes(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.AllocationRecord)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t AllocationRecord::ByteSizeLong(const MessageLite& base) {
          const AllocationRecord& this_ = static_cast<const AllocationRecord&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t AllocationRecord::ByteSizeLong() const {
          const AllocationRecord& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.AllocationRecord)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // int64 alloc_micros = 1;
            if (this_._internal_alloc_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_alloc_micros());
            }
            // int64 alloc_bytes = 2;
            if (this_._internal_alloc_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_alloc_bytes());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void AllocationRecord::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<AllocationRecord*>(&to_msg);
  auto& from = static_cast<const AllocationRecord&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.AllocationRecord)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_alloc_micros() != 0) {
    _this->_impl_.alloc_micros_ = from._impl_.alloc_micros_;
  }
  if (from._internal_alloc_bytes() != 0) {
    _this->_impl_.alloc_bytes_ = from._impl_.alloc_bytes_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void AllocationRecord::CopyFrom(const AllocationRecord& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.AllocationRecord)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void AllocationRecord::InternalSwap(AllocationRecord* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_bytes_)
      + sizeof(AllocationRecord::_impl_.alloc_bytes_)
      - PROTOBUF_FIELD_OFFSET(AllocationRecord, _impl_.alloc_micros_)>(
          reinterpret_cast<char*>(&_impl_.alloc_micros_),
          reinterpret_cast<char*>(&other->_impl_.alloc_micros_));
}

::google::protobuf::Metadata AllocationRecord::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class AllocatorMemoryUsed::_Internal {
 public:
};

AllocatorMemoryUsed::AllocatorMemoryUsed(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.AllocatorMemoryUsed)
}
inline PROTOBUF_NDEBUG_INLINE AllocatorMemoryUsed::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::AllocatorMemoryUsed& from_msg)
      : allocation_records_{visibility, arena, from.allocation_records_},
        allocator_name_(arena, from.allocator_name_),
        _cached_size_{0} {}

AllocatorMemoryUsed::AllocatorMemoryUsed(
    ::google::protobuf::Arena* arena,
    const AllocatorMemoryUsed& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  AllocatorMemoryUsed* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_bytes_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, total_bytes_),
           offsetof(Impl_, allocator_bytes_in_use_) -
               offsetof(Impl_, total_bytes_) +
               sizeof(Impl_::allocator_bytes_in_use_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.AllocatorMemoryUsed)
}
inline PROTOBUF_NDEBUG_INLINE AllocatorMemoryUsed::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : allocation_records_{visibility, arena},
        allocator_name_(arena),
        _cached_size_{0} {}

inline void AllocatorMemoryUsed::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, total_bytes_),
           0,
           offsetof(Impl_, allocator_bytes_in_use_) -
               offsetof(Impl_, total_bytes_) +
               sizeof(Impl_::allocator_bytes_in_use_));
}
AllocatorMemoryUsed::~AllocatorMemoryUsed() {
  // @@protoc_insertion_point(destructor:tensorflow.AllocatorMemoryUsed)
  SharedDtor(*this);
}
inline void AllocatorMemoryUsed::SharedDtor(MessageLite& self) {
  AllocatorMemoryUsed& this_ = static_cast<AllocatorMemoryUsed&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.allocator_name_.Destroy();
  this_._impl_.~Impl_();
}

inline void* AllocatorMemoryUsed::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) AllocatorMemoryUsed(arena);
}
constexpr auto AllocatorMemoryUsed::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocation_records_) +
          decltype(AllocatorMemoryUsed::_impl_.allocation_records_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(AllocatorMemoryUsed), alignof(AllocatorMemoryUsed), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&AllocatorMemoryUsed::PlacementNew_,
                                 sizeof(AllocatorMemoryUsed),
                                 alignof(AllocatorMemoryUsed));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull AllocatorMemoryUsed::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_AllocatorMemoryUsed_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &AllocatorMemoryUsed::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<AllocatorMemoryUsed>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &AllocatorMemoryUsed::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<AllocatorMemoryUsed>(), &AllocatorMemoryUsed::ByteSizeLong,
            &AllocatorMemoryUsed::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_._cached_size_),
        false,
    },
    &AllocatorMemoryUsed::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* AllocatorMemoryUsed::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 1, 53, 2> AllocatorMemoryUsed::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::AllocatorMemoryUsed>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // string allocator_name = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocator_name_)}},
    // int64 total_bytes = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocatorMemoryUsed, _impl_.total_bytes_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.total_bytes_)}},
    // int64 peak_bytes = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocatorMemoryUsed, _impl_.peak_bytes_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.peak_bytes_)}},
    // int64 live_bytes = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocatorMemoryUsed, _impl_.live_bytes_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.live_bytes_)}},
    // int64 allocator_bytes_in_use = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(AllocatorMemoryUsed, _impl_.allocator_bytes_in_use_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocator_bytes_in_use_)}},
    // repeated .tensorflow.AllocationRecord allocation_records = 6;
    {::_pbi::TcParser::FastMtR1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocation_records_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // string allocator_name = 1;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocator_name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int64 total_bytes = 2;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.total_bytes_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 peak_bytes = 3;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.peak_bytes_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 live_bytes = 4;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.live_bytes_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 allocator_bytes_in_use = 5;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocator_bytes_in_use_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // repeated .tensorflow.AllocationRecord allocation_records = 6;
    {PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocation_records_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::AllocationRecord>()},
  }}, {{
    "\36\16\0\0\0\0\0\0"
    "tensorflow.AllocatorMemoryUsed"
    "allocator_name"
  }},
};

PROTOBUF_NOINLINE void AllocatorMemoryUsed::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.AllocatorMemoryUsed)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.allocation_records_.Clear();
  _impl_.allocator_name_.ClearToEmpty();
  ::memset(&_impl_.total_bytes_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.allocator_bytes_in_use_) -
      reinterpret_cast<char*>(&_impl_.total_bytes_)) + sizeof(_impl_.allocator_bytes_in_use_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* AllocatorMemoryUsed::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const AllocatorMemoryUsed& this_ = static_cast<const AllocatorMemoryUsed&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* AllocatorMemoryUsed::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const AllocatorMemoryUsed& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.AllocatorMemoryUsed)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string allocator_name = 1;
          if (!this_._internal_allocator_name().empty()) {
            const std::string& _s = this_._internal_allocator_name();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.AllocatorMemoryUsed.allocator_name");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // int64 total_bytes = 2;
          if (this_._internal_total_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_total_bytes(), target);
          }

          // int64 peak_bytes = 3;
          if (this_._internal_peak_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<3>(
                    stream, this_._internal_peak_bytes(), target);
          }

          // int64 live_bytes = 4;
          if (this_._internal_live_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<4>(
                    stream, this_._internal_live_bytes(), target);
          }

          // int64 allocator_bytes_in_use = 5;
          if (this_._internal_allocator_bytes_in_use() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<5>(
                    stream, this_._internal_allocator_bytes_in_use(), target);
          }

          // repeated .tensorflow.AllocationRecord allocation_records = 6;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_allocation_records_size());
               i < n; i++) {
            const auto& repfield = this_._internal_allocation_records().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    6, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.AllocatorMemoryUsed)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t AllocatorMemoryUsed::ByteSizeLong(const MessageLite& base) {
          const AllocatorMemoryUsed& this_ = static_cast<const AllocatorMemoryUsed&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t AllocatorMemoryUsed::ByteSizeLong() const {
          const AllocatorMemoryUsed& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.AllocatorMemoryUsed)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.AllocationRecord allocation_records = 6;
            {
              total_size += 1UL * this_._internal_allocation_records_size();
              for (const auto& msg : this_._internal_allocation_records()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string allocator_name = 1;
            if (!this_._internal_allocator_name().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_allocator_name());
            }
            // int64 total_bytes = 2;
            if (this_._internal_total_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_total_bytes());
            }
            // int64 peak_bytes = 3;
            if (this_._internal_peak_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_peak_bytes());
            }
            // int64 live_bytes = 4;
            if (this_._internal_live_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_live_bytes());
            }
            // int64 allocator_bytes_in_use = 5;
            if (this_._internal_allocator_bytes_in_use() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_allocator_bytes_in_use());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void AllocatorMemoryUsed::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<AllocatorMemoryUsed*>(&to_msg);
  auto& from = static_cast<const AllocatorMemoryUsed&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.AllocatorMemoryUsed)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_allocation_records()->MergeFrom(
      from._internal_allocation_records());
  if (!from._internal_allocator_name().empty()) {
    _this->_internal_set_allocator_name(from._internal_allocator_name());
  }
  if (from._internal_total_bytes() != 0) {
    _this->_impl_.total_bytes_ = from._impl_.total_bytes_;
  }
  if (from._internal_peak_bytes() != 0) {
    _this->_impl_.peak_bytes_ = from._impl_.peak_bytes_;
  }
  if (from._internal_live_bytes() != 0) {
    _this->_impl_.live_bytes_ = from._impl_.live_bytes_;
  }
  if (from._internal_allocator_bytes_in_use() != 0) {
    _this->_impl_.allocator_bytes_in_use_ = from._impl_.allocator_bytes_in_use_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void AllocatorMemoryUsed::CopyFrom(const AllocatorMemoryUsed& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.AllocatorMemoryUsed)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void AllocatorMemoryUsed::InternalSwap(AllocatorMemoryUsed* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.allocation_records_.InternalSwap(&other->_impl_.allocation_records_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.allocator_name_, &other->_impl_.allocator_name_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.allocator_bytes_in_use_)
      + sizeof(AllocatorMemoryUsed::_impl_.allocator_bytes_in_use_)
      - PROTOBUF_FIELD_OFFSET(AllocatorMemoryUsed, _impl_.total_bytes_)>(
          reinterpret_cast<char*>(&_impl_.total_bytes_),
          reinterpret_cast<char*>(&other->_impl_.total_bytes_));
}

::google::protobuf::Metadata AllocatorMemoryUsed::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class NodeOutput::_Internal {
 public:
  using HasBits =
      decltype(std::declval<NodeOutput>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_._has_bits_);
};

void NodeOutput::clear_tensor_description() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.tensor_description_ != nullptr) _impl_.tensor_description_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
NodeOutput::NodeOutput(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.NodeOutput)
}
inline PROTOBUF_NDEBUG_INLINE NodeOutput::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::NodeOutput& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

NodeOutput::NodeOutput(
    ::google::protobuf::Arena* arena,
    const NodeOutput& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  NodeOutput* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.tensor_description_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::TensorDescription>(
                              arena, *from._impl_.tensor_description_)
                        : nullptr;
  _impl_.slot_ = from._impl_.slot_;

  // @@protoc_insertion_point(copy_constructor:tensorflow.NodeOutput)
}
inline PROTOBUF_NDEBUG_INLINE NodeOutput::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void NodeOutput::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, tensor_description_),
           0,
           offsetof(Impl_, slot_) -
               offsetof(Impl_, tensor_description_) +
               sizeof(Impl_::slot_));
}
NodeOutput::~NodeOutput() {
  // @@protoc_insertion_point(destructor:tensorflow.NodeOutput)
  SharedDtor(*this);
}
inline void NodeOutput::SharedDtor(MessageLite& self) {
  NodeOutput& this_ = static_cast<NodeOutput&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.tensor_description_;
  this_._impl_.~Impl_();
}

inline void* NodeOutput::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) NodeOutput(arena);
}
constexpr auto NodeOutput::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(NodeOutput),
                                            alignof(NodeOutput));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull NodeOutput::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_NodeOutput_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &NodeOutput::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<NodeOutput>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &NodeOutput::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<NodeOutput>(), &NodeOutput::ByteSizeLong,
            &NodeOutput::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_._cached_size_),
        false,
    },
    &NodeOutput::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* NodeOutput::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 2, 1, 0, 2> NodeOutput::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_._has_bits_),
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967290,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::NodeOutput>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // int32 slot = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(NodeOutput, _impl_.slot_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.slot_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // .tensorflow.TensorDescription tensor_description = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 0, PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.tensor_description_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int32 slot = 1;
    {PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.slot_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // .tensorflow.TensorDescription tensor_description = 3;
    {PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.tensor_description_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::TensorDescription>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void NodeOutput::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.NodeOutput)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.tensor_description_ != nullptr);
    _impl_.tensor_description_->Clear();
  }
  _impl_.slot_ = 0;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* NodeOutput::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const NodeOutput& this_ = static_cast<const NodeOutput&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* NodeOutput::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const NodeOutput& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.NodeOutput)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int32 slot = 1;
          if (this_._internal_slot() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<1>(
                    stream, this_._internal_slot(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.TensorDescription tensor_description = 3;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.tensor_description_, this_._impl_.tensor_description_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.NodeOutput)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t NodeOutput::ByteSizeLong(const MessageLite& base) {
          const NodeOutput& this_ = static_cast<const NodeOutput&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t NodeOutput::ByteSizeLong() const {
          const NodeOutput& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.NodeOutput)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // .tensorflow.TensorDescription tensor_description = 3;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.tensor_description_);
            }
          }
           {
            // int32 slot = 1;
            if (this_._internal_slot() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_slot());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void NodeOutput::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<NodeOutput*>(&to_msg);
  auto& from = static_cast<const NodeOutput&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.NodeOutput)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.tensor_description_ != nullptr);
    if (_this->_impl_.tensor_description_ == nullptr) {
      _this->_impl_.tensor_description_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::TensorDescription>(arena, *from._impl_.tensor_description_);
    } else {
      _this->_impl_.tensor_description_->MergeFrom(*from._impl_.tensor_description_);
    }
  }
  if (from._internal_slot() != 0) {
    _this->_impl_.slot_ = from._impl_.slot_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void NodeOutput::CopyFrom(const NodeOutput& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.NodeOutput)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void NodeOutput::InternalSwap(NodeOutput* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.slot_)
      + sizeof(NodeOutput::_impl_.slot_)
      - PROTOBUF_FIELD_OFFSET(NodeOutput, _impl_.tensor_description_)>(
          reinterpret_cast<char*>(&_impl_.tensor_description_),
          reinterpret_cast<char*>(&other->_impl_.tensor_description_));
}

::google::protobuf::Metadata NodeOutput::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class MemoryStats::_Internal {
 public:
};

MemoryStats::MemoryStats(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.MemoryStats)
}
inline PROTOBUF_NDEBUG_INLINE MemoryStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::MemoryStats& from_msg)
      : persistent_tensor_alloc_ids_{visibility, arena, from.persistent_tensor_alloc_ids_},
        _persistent_tensor_alloc_ids_cached_byte_size_{0},
        device_persistent_tensor_alloc_ids_{visibility, arena, from.device_persistent_tensor_alloc_ids_},
        _device_persistent_tensor_alloc_ids_cached_byte_size_{0},
        _cached_size_{0} {}

MemoryStats::MemoryStats(
    ::google::protobuf::Arena* arena,
    const MemoryStats& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  MemoryStats* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, temp_memory_size_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, temp_memory_size_),
           offsetof(Impl_, device_persistent_memory_size_) -
               offsetof(Impl_, temp_memory_size_) +
               sizeof(Impl_::device_persistent_memory_size_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.MemoryStats)
}
inline PROTOBUF_NDEBUG_INLINE MemoryStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : persistent_tensor_alloc_ids_{visibility, arena},
        _persistent_tensor_alloc_ids_cached_byte_size_{0},
        device_persistent_tensor_alloc_ids_{visibility, arena},
        _device_persistent_tensor_alloc_ids_cached_byte_size_{0},
        _cached_size_{0} {}

inline void MemoryStats::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, temp_memory_size_),
           0,
           offsetof(Impl_, device_persistent_memory_size_) -
               offsetof(Impl_, temp_memory_size_) +
               sizeof(Impl_::device_persistent_memory_size_));
}
MemoryStats::~MemoryStats() {
  // @@protoc_insertion_point(destructor:tensorflow.MemoryStats)
  SharedDtor(*this);
}
inline void MemoryStats::SharedDtor(MessageLite& self) {
  MemoryStats& this_ = static_cast<MemoryStats&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* MemoryStats::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) MemoryStats(arena);
}
constexpr auto MemoryStats::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.persistent_tensor_alloc_ids_) +
          decltype(MemoryStats::_impl_.persistent_tensor_alloc_ids_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_tensor_alloc_ids_) +
          decltype(MemoryStats::_impl_.device_persistent_tensor_alloc_ids_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(MemoryStats), alignof(MemoryStats), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&MemoryStats::PlacementNew_,
                                 sizeof(MemoryStats),
                                 alignof(MemoryStats));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull MemoryStats::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_MemoryStats_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &MemoryStats::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<MemoryStats>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &MemoryStats::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<MemoryStats>(), &MemoryStats::ByteSizeLong,
            &MemoryStats::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_._cached_size_),
        false,
    },
    &MemoryStats::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* MemoryStats::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 6, 0, 0, 2> MemoryStats::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    6, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967232,  // skipmap
    offsetof(decltype(_table_), field_entries),
    6,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::MemoryStats>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // int64 temp_memory_size = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(MemoryStats, _impl_.temp_memory_size_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.temp_memory_size_)}},
    // int64 device_temp_memory_size = 2 [deprecated = true];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(MemoryStats, _impl_.device_temp_memory_size_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_temp_memory_size_)}},
    // int64 persistent_memory_size = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(MemoryStats, _impl_.persistent_memory_size_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.persistent_memory_size_)}},
    // int64 device_persistent_memory_size = 4 [deprecated = true];
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(MemoryStats, _impl_.device_persistent_memory_size_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_memory_size_)}},
    // repeated int64 persistent_tensor_alloc_ids = 5;
    {::_pbi::TcParser::FastV64P1,
     {42, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.persistent_tensor_alloc_ids_)}},
    // repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];
    {::_pbi::TcParser::FastV64P1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_tensor_alloc_ids_)}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // int64 temp_memory_size = 1;
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.temp_memory_size_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 device_temp_memory_size = 2 [deprecated = true];
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_temp_memory_size_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 persistent_memory_size = 3;
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.persistent_memory_size_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 device_persistent_memory_size = 4 [deprecated = true];
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_memory_size_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // repeated int64 persistent_tensor_alloc_ids = 5;
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.persistent_tensor_alloc_ids_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedInt64)},
    // repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];
    {PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_tensor_alloc_ids_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedInt64)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void MemoryStats::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.MemoryStats)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.persistent_tensor_alloc_ids_.Clear();
  _impl_.device_persistent_tensor_alloc_ids_.Clear();
  ::memset(&_impl_.temp_memory_size_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.device_persistent_memory_size_) -
      reinterpret_cast<char*>(&_impl_.temp_memory_size_)) + sizeof(_impl_.device_persistent_memory_size_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* MemoryStats::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const MemoryStats& this_ = static_cast<const MemoryStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* MemoryStats::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const MemoryStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.MemoryStats)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int64 temp_memory_size = 1;
          if (this_._internal_temp_memory_size() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<1>(
                    stream, this_._internal_temp_memory_size(), target);
          }

          // int64 device_temp_memory_size = 2 [deprecated = true];
          if (this_._internal_device_temp_memory_size() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_device_temp_memory_size(), target);
          }

          // int64 persistent_memory_size = 3;
          if (this_._internal_persistent_memory_size() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<3>(
                    stream, this_._internal_persistent_memory_size(), target);
          }

          // int64 device_persistent_memory_size = 4 [deprecated = true];
          if (this_._internal_device_persistent_memory_size() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<4>(
                    stream, this_._internal_device_persistent_memory_size(), target);
          }

          // repeated int64 persistent_tensor_alloc_ids = 5;
          {
            int byte_size = this_._impl_._persistent_tensor_alloc_ids_cached_byte_size_.Get();
            if (byte_size > 0) {
              target = stream->WriteInt64Packed(
                  5, this_._internal_persistent_tensor_alloc_ids(), byte_size, target);
            }
          }

          // repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];
          {
            int byte_size = this_._impl_._device_persistent_tensor_alloc_ids_cached_byte_size_.Get();
            if (byte_size > 0) {
              target = stream->WriteInt64Packed(
                  6, this_._internal_device_persistent_tensor_alloc_ids(), byte_size, target);
            }
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.MemoryStats)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t MemoryStats::ByteSizeLong(const MessageLite& base) {
          const MemoryStats& this_ = static_cast<const MemoryStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t MemoryStats::ByteSizeLong() const {
          const MemoryStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.MemoryStats)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated int64 persistent_tensor_alloc_ids = 5;
            {
              total_size +=
                  ::_pbi::WireFormatLite::Int64SizeWithPackedTagSize(
                      this_._internal_persistent_tensor_alloc_ids(), 1,
                      this_._impl_._persistent_tensor_alloc_ids_cached_byte_size_);
            }
            // repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];
            {
              total_size +=
                  ::_pbi::WireFormatLite::Int64SizeWithPackedTagSize(
                      this_._internal_device_persistent_tensor_alloc_ids(), 1,
                      this_._impl_._device_persistent_tensor_alloc_ids_cached_byte_size_);
            }
          }
           {
            // int64 temp_memory_size = 1;
            if (this_._internal_temp_memory_size() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_temp_memory_size());
            }
            // int64 device_temp_memory_size = 2 [deprecated = true];
            if (this_._internal_device_temp_memory_size() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_device_temp_memory_size());
            }
            // int64 persistent_memory_size = 3;
            if (this_._internal_persistent_memory_size() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_persistent_memory_size());
            }
            // int64 device_persistent_memory_size = 4 [deprecated = true];
            if (this_._internal_device_persistent_memory_size() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_device_persistent_memory_size());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void MemoryStats::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<MemoryStats*>(&to_msg);
  auto& from = static_cast<const MemoryStats&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.MemoryStats)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_persistent_tensor_alloc_ids()->MergeFrom(from._internal_persistent_tensor_alloc_ids());
  _this->_internal_mutable_device_persistent_tensor_alloc_ids()->MergeFrom(from._internal_device_persistent_tensor_alloc_ids());
  if (from._internal_temp_memory_size() != 0) {
    _this->_impl_.temp_memory_size_ = from._impl_.temp_memory_size_;
  }
  if (from._internal_device_temp_memory_size() != 0) {
    _this->_impl_.device_temp_memory_size_ = from._impl_.device_temp_memory_size_;
  }
  if (from._internal_persistent_memory_size() != 0) {
    _this->_impl_.persistent_memory_size_ = from._impl_.persistent_memory_size_;
  }
  if (from._internal_device_persistent_memory_size() != 0) {
    _this->_impl_.device_persistent_memory_size_ = from._impl_.device_persistent_memory_size_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void MemoryStats::CopyFrom(const MemoryStats& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.MemoryStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void MemoryStats::InternalSwap(MemoryStats* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.persistent_tensor_alloc_ids_.InternalSwap(&other->_impl_.persistent_tensor_alloc_ids_);
  _impl_.device_persistent_tensor_alloc_ids_.InternalSwap(&other->_impl_.device_persistent_tensor_alloc_ids_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.device_persistent_memory_size_)
      + sizeof(MemoryStats::_impl_.device_persistent_memory_size_)
      - PROTOBUF_FIELD_OFFSET(MemoryStats, _impl_.temp_memory_size_)>(
          reinterpret_cast<char*>(&_impl_.temp_memory_size_),
          reinterpret_cast<char*>(&other->_impl_.temp_memory_size_));
}

::google::protobuf::Metadata MemoryStats::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class NodeExecStats::_Internal {
 public:
  using HasBits =
      decltype(std::declval<NodeExecStats>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_._has_bits_);
};

void NodeExecStats::clear_referenced_tensor() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.referenced_tensor_.Clear();
}
NodeExecStats::NodeExecStats(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.NodeExecStats)
}
inline PROTOBUF_NDEBUG_INLINE NodeExecStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::NodeExecStats& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        memory_{visibility, arena, from.memory_},
        output_{visibility, arena, from.output_},
        referenced_tensor_{visibility, arena, from.referenced_tensor_},
        node_name_(arena, from.node_name_),
        timeline_label_(arena, from.timeline_label_) {}

NodeExecStats::NodeExecStats(
    ::google::protobuf::Arena* arena,
    const NodeExecStats& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  NodeExecStats* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.memory_stats_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::MemoryStats>(
                              arena, *from._impl_.memory_stats_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, all_start_micros_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, all_start_micros_),
           offsetof(Impl_, thread_id_) -
               offsetof(Impl_, all_start_micros_) +
               sizeof(Impl_::thread_id_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.NodeExecStats)
}
inline PROTOBUF_NDEBUG_INLINE NodeExecStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        memory_{visibility, arena},
        output_{visibility, arena},
        referenced_tensor_{visibility, arena},
        node_name_(arena),
        timeline_label_(arena) {}

inline void NodeExecStats::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, memory_stats_),
           0,
           offsetof(Impl_, thread_id_) -
               offsetof(Impl_, memory_stats_) +
               sizeof(Impl_::thread_id_));
}
NodeExecStats::~NodeExecStats() {
  // @@protoc_insertion_point(destructor:tensorflow.NodeExecStats)
  SharedDtor(*this);
}
inline void NodeExecStats::SharedDtor(MessageLite& self) {
  NodeExecStats& this_ = static_cast<NodeExecStats&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.node_name_.Destroy();
  this_._impl_.timeline_label_.Destroy();
  delete this_._impl_.memory_stats_;
  this_._impl_.~Impl_();
}

inline void* NodeExecStats::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) NodeExecStats(arena);
}
constexpr auto NodeExecStats::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_) +
          decltype(NodeExecStats::_impl_.memory_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.output_) +
          decltype(NodeExecStats::_impl_.output_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.referenced_tensor_) +
          decltype(NodeExecStats::_impl_.referenced_tensor_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(NodeExecStats), alignof(NodeExecStats), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&NodeExecStats::PlacementNew_,
                                 sizeof(NodeExecStats),
                                 alignof(NodeExecStats));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull NodeExecStats::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_NodeExecStats_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &NodeExecStats::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<NodeExecStats>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &NodeExecStats::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<NodeExecStats>(), &NodeExecStats::ByteSizeLong,
            &NodeExecStats::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_._cached_size_),
        false,
    },
    &NodeExecStats::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* NodeExecStats::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 17, 4, 72, 2> NodeExecStats::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_._has_bits_),
    0, // no _extensions_
    17, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294836224,  // skipmap
    offsetof(decltype(_table_), field_entries),
    17,  // num_field_entries
    4,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::NodeExecStats>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // string node_name = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.node_name_)}},
    // int64 all_start_micros = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.all_start_micros_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_start_micros_)}},
    // int64 op_start_rel_micros = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.op_start_rel_micros_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_start_rel_micros_)}},
    // int64 op_end_rel_micros = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.op_end_rel_micros_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_end_rel_micros_)}},
    // int64 all_end_rel_micros = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.all_end_rel_micros_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_end_rel_micros_)}},
    // repeated .tensorflow.AllocatorMemoryUsed memory = 6;
    {::_pbi::TcParser::FastMtR1,
     {50, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_)}},
    // repeated .tensorflow.NodeOutput output = 7;
    {::_pbi::TcParser::FastMtR1,
     {58, 63, 1, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.output_)}},
    // string timeline_label = 8;
    {::_pbi::TcParser::FastUS1,
     {66, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.timeline_label_)}},
    // int64 scheduled_micros = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.scheduled_micros_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.scheduled_micros_)}},
    // uint32 thread_id = 10;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(NodeExecStats, _impl_.thread_id_), 63>(),
     {80, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.thread_id_)}},
    // repeated .tensorflow.AllocationDescription referenced_tensor = 11;
    {::_pbi::TcParser::FastMtR1,
     {90, 63, 2, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.referenced_tensor_)}},
    // .tensorflow.MemoryStats memory_stats = 12;
    {::_pbi::TcParser::FastMtS1,
     {98, 0, 3, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_stats_)}},
    // int64 all_start_nanos = 13;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.all_start_nanos_), 63>(),
     {104, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_start_nanos_)}},
    // int64 op_start_rel_nanos = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.op_start_rel_nanos_), 63>(),
     {112, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_start_rel_nanos_)}},
    // int64 op_end_rel_nanos = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(NodeExecStats, _impl_.op_end_rel_nanos_), 63>(),
     {120, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_end_rel_nanos_)}},
    // int64 all_end_rel_nanos = 16;
    {::_pbi::TcParser::FastV64S2,
     {384, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_end_rel_nanos_)}},
    // int64 scheduled_nanos = 17;
    {::_pbi::TcParser::FastV64S2,
     {392, 63, 0, PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.scheduled_nanos_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // string node_name = 1;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.node_name_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int64 all_start_micros = 2;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_start_micros_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 op_start_rel_micros = 3;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_start_rel_micros_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 op_end_rel_micros = 4;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_end_rel_micros_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 all_end_rel_micros = 5;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_end_rel_micros_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // repeated .tensorflow.AllocatorMemoryUsed memory = 6;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .tensorflow.NodeOutput output = 7;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.output_), -1, 1,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // string timeline_label = 8;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.timeline_label_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int64 scheduled_micros = 9;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.scheduled_micros_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // uint32 thread_id = 10;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.thread_id_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUInt32)},
    // repeated .tensorflow.AllocationDescription referenced_tensor = 11;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.referenced_tensor_), -1, 2,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.MemoryStats memory_stats = 12;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_stats_), _Internal::kHasBitsOffset + 0, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 all_start_nanos = 13;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_start_nanos_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 op_start_rel_nanos = 14;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_start_rel_nanos_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 op_end_rel_nanos = 15;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.op_end_rel_nanos_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 all_end_rel_nanos = 16;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.all_end_rel_nanos_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int64 scheduled_nanos = 17;
    {PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.scheduled_nanos_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::AllocatorMemoryUsed>()},
    {::_pbi::TcParser::GetTable<::tensorflow::NodeOutput>()},
    {::_pbi::TcParser::GetTable<::tensorflow::AllocationDescription>()},
    {::_pbi::TcParser::GetTable<::tensorflow::MemoryStats>()},
  }}, {{
    "\30\11\0\0\0\0\0\0\16\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"
    "tensorflow.NodeExecStats"
    "node_name"
    "timeline_label"
  }},
};

PROTOBUF_NOINLINE void NodeExecStats::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.NodeExecStats)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.memory_.Clear();
  _impl_.output_.Clear();
  _impl_.referenced_tensor_.Clear();
  _impl_.node_name_.ClearToEmpty();
  _impl_.timeline_label_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.memory_stats_ != nullptr);
    _impl_.memory_stats_->Clear();
  }
  ::memset(&_impl_.all_start_micros_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.thread_id_) -
      reinterpret_cast<char*>(&_impl_.all_start_micros_)) + sizeof(_impl_.thread_id_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* NodeExecStats::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const NodeExecStats& this_ = static_cast<const NodeExecStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* NodeExecStats::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const NodeExecStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.NodeExecStats)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string node_name = 1;
          if (!this_._internal_node_name().empty()) {
            const std::string& _s = this_._internal_node_name();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.NodeExecStats.node_name");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // int64 all_start_micros = 2;
          if (this_._internal_all_start_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_all_start_micros(), target);
          }

          // int64 op_start_rel_micros = 3;
          if (this_._internal_op_start_rel_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<3>(
                    stream, this_._internal_op_start_rel_micros(), target);
          }

          // int64 op_end_rel_micros = 4;
          if (this_._internal_op_end_rel_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<4>(
                    stream, this_._internal_op_end_rel_micros(), target);
          }

          // int64 all_end_rel_micros = 5;
          if (this_._internal_all_end_rel_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<5>(
                    stream, this_._internal_all_end_rel_micros(), target);
          }

          // repeated .tensorflow.AllocatorMemoryUsed memory = 6;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_memory_size());
               i < n; i++) {
            const auto& repfield = this_._internal_memory().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    6, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // repeated .tensorflow.NodeOutput output = 7;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_output_size());
               i < n; i++) {
            const auto& repfield = this_._internal_output().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    7, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // string timeline_label = 8;
          if (!this_._internal_timeline_label().empty()) {
            const std::string& _s = this_._internal_timeline_label();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.NodeExecStats.timeline_label");
            target = stream->WriteStringMaybeAliased(8, _s, target);
          }

          // int64 scheduled_micros = 9;
          if (this_._internal_scheduled_micros() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<9>(
                    stream, this_._internal_scheduled_micros(), target);
          }

          // uint32 thread_id = 10;
          if (this_._internal_thread_id() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteUInt32ToArray(
                10, this_._internal_thread_id(), target);
          }

          // repeated .tensorflow.AllocationDescription referenced_tensor = 11;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_referenced_tensor_size());
               i < n; i++) {
            const auto& repfield = this_._internal_referenced_tensor().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    11, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.MemoryStats memory_stats = 12;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                12, *this_._impl_.memory_stats_, this_._impl_.memory_stats_->GetCachedSize(), target,
                stream);
          }

          // int64 all_start_nanos = 13;
          if (this_._internal_all_start_nanos() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<13>(
                    stream, this_._internal_all_start_nanos(), target);
          }

          // int64 op_start_rel_nanos = 14;
          if (this_._internal_op_start_rel_nanos() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<14>(
                    stream, this_._internal_op_start_rel_nanos(), target);
          }

          // int64 op_end_rel_nanos = 15;
          if (this_._internal_op_end_rel_nanos() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<15>(
                    stream, this_._internal_op_end_rel_nanos(), target);
          }

          // int64 all_end_rel_nanos = 16;
          if (this_._internal_all_end_rel_nanos() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt64ToArray(
                16, this_._internal_all_end_rel_nanos(), target);
          }

          // int64 scheduled_nanos = 17;
          if (this_._internal_scheduled_nanos() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt64ToArray(
                17, this_._internal_scheduled_nanos(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.NodeExecStats)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t NodeExecStats::ByteSizeLong(const MessageLite& base) {
          const NodeExecStats& this_ = static_cast<const NodeExecStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t NodeExecStats::ByteSizeLong() const {
          const NodeExecStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.NodeExecStats)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.AllocatorMemoryUsed memory = 6;
            {
              total_size += 1UL * this_._internal_memory_size();
              for (const auto& msg : this_._internal_memory()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // repeated .tensorflow.NodeOutput output = 7;
            {
              total_size += 1UL * this_._internal_output_size();
              for (const auto& msg : this_._internal_output()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // repeated .tensorflow.AllocationDescription referenced_tensor = 11;
            {
              total_size += 1UL * this_._internal_referenced_tensor_size();
              for (const auto& msg : this_._internal_referenced_tensor()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string node_name = 1;
            if (!this_._internal_node_name().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_node_name());
            }
            // string timeline_label = 8;
            if (!this_._internal_timeline_label().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_timeline_label());
            }
          }
           {
            // .tensorflow.MemoryStats memory_stats = 12;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.memory_stats_);
            }
          }
           {
            // int64 all_start_micros = 2;
            if (this_._internal_all_start_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_all_start_micros());
            }
            // int64 op_start_rel_micros = 3;
            if (this_._internal_op_start_rel_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_op_start_rel_micros());
            }
            // int64 op_end_rel_micros = 4;
            if (this_._internal_op_end_rel_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_op_end_rel_micros());
            }
            // int64 all_end_rel_micros = 5;
            if (this_._internal_all_end_rel_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_all_end_rel_micros());
            }
            // int64 scheduled_micros = 9;
            if (this_._internal_scheduled_micros() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_scheduled_micros());
            }
            // int64 all_start_nanos = 13;
            if (this_._internal_all_start_nanos() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_all_start_nanos());
            }
            // int64 op_start_rel_nanos = 14;
            if (this_._internal_op_start_rel_nanos() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_op_start_rel_nanos());
            }
            // int64 op_end_rel_nanos = 15;
            if (this_._internal_op_end_rel_nanos() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_op_end_rel_nanos());
            }
            // int64 all_end_rel_nanos = 16;
            if (this_._internal_all_end_rel_nanos() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int64Size(
                                              this_._internal_all_end_rel_nanos());
            }
            // int64 scheduled_nanos = 17;
            if (this_._internal_scheduled_nanos() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int64Size(
                                              this_._internal_scheduled_nanos());
            }
            // uint32 thread_id = 10;
            if (this_._internal_thread_id() != 0) {
              total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(
                  this_._internal_thread_id());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void NodeExecStats::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<NodeExecStats*>(&to_msg);
  auto& from = static_cast<const NodeExecStats&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.NodeExecStats)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_memory()->MergeFrom(
      from._internal_memory());
  _this->_internal_mutable_output()->MergeFrom(
      from._internal_output());
  _this->_internal_mutable_referenced_tensor()->MergeFrom(
      from._internal_referenced_tensor());
  if (!from._internal_node_name().empty()) {
    _this->_internal_set_node_name(from._internal_node_name());
  }
  if (!from._internal_timeline_label().empty()) {
    _this->_internal_set_timeline_label(from._internal_timeline_label());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.memory_stats_ != nullptr);
    if (_this->_impl_.memory_stats_ == nullptr) {
      _this->_impl_.memory_stats_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::MemoryStats>(arena, *from._impl_.memory_stats_);
    } else {
      _this->_impl_.memory_stats_->MergeFrom(*from._impl_.memory_stats_);
    }
  }
  if (from._internal_all_start_micros() != 0) {
    _this->_impl_.all_start_micros_ = from._impl_.all_start_micros_;
  }
  if (from._internal_op_start_rel_micros() != 0) {
    _this->_impl_.op_start_rel_micros_ = from._impl_.op_start_rel_micros_;
  }
  if (from._internal_op_end_rel_micros() != 0) {
    _this->_impl_.op_end_rel_micros_ = from._impl_.op_end_rel_micros_;
  }
  if (from._internal_all_end_rel_micros() != 0) {
    _this->_impl_.all_end_rel_micros_ = from._impl_.all_end_rel_micros_;
  }
  if (from._internal_scheduled_micros() != 0) {
    _this->_impl_.scheduled_micros_ = from._impl_.scheduled_micros_;
  }
  if (from._internal_all_start_nanos() != 0) {
    _this->_impl_.all_start_nanos_ = from._impl_.all_start_nanos_;
  }
  if (from._internal_op_start_rel_nanos() != 0) {
    _this->_impl_.op_start_rel_nanos_ = from._impl_.op_start_rel_nanos_;
  }
  if (from._internal_op_end_rel_nanos() != 0) {
    _this->_impl_.op_end_rel_nanos_ = from._impl_.op_end_rel_nanos_;
  }
  if (from._internal_all_end_rel_nanos() != 0) {
    _this->_impl_.all_end_rel_nanos_ = from._impl_.all_end_rel_nanos_;
  }
  if (from._internal_scheduled_nanos() != 0) {
    _this->_impl_.scheduled_nanos_ = from._impl_.scheduled_nanos_;
  }
  if (from._internal_thread_id() != 0) {
    _this->_impl_.thread_id_ = from._impl_.thread_id_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void NodeExecStats::CopyFrom(const NodeExecStats& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.NodeExecStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void NodeExecStats::InternalSwap(NodeExecStats* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.memory_.InternalSwap(&other->_impl_.memory_);
  _impl_.output_.InternalSwap(&other->_impl_.output_);
  _impl_.referenced_tensor_.InternalSwap(&other->_impl_.referenced_tensor_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.node_name_, &other->_impl_.node_name_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.timeline_label_, &other->_impl_.timeline_label_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.thread_id_)
      + sizeof(NodeExecStats::_impl_.thread_id_)
      - PROTOBUF_FIELD_OFFSET(NodeExecStats, _impl_.memory_stats_)>(
          reinterpret_cast<char*>(&_impl_.memory_stats_),
          reinterpret_cast<char*>(&other->_impl_.memory_stats_));
}

::google::protobuf::Metadata NodeExecStats::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

#if defined(PROTOBUF_CUSTOM_VTABLE)
              DeviceStepStats_ThreadNamesEntry_DoNotUse::DeviceStepStats_ThreadNamesEntry_DoNotUse() : SuperType(_class_data_.base()) {}
              DeviceStepStats_ThreadNamesEntry_DoNotUse::DeviceStepStats_ThreadNamesEntry_DoNotUse(::google::protobuf::Arena* arena)
                  : SuperType(arena, _class_data_.base()) {}
#else   // PROTOBUF_CUSTOM_VTABLE
              DeviceStepStats_ThreadNamesEntry_DoNotUse::DeviceStepStats_ThreadNamesEntry_DoNotUse() : SuperType() {}
              DeviceStepStats_ThreadNamesEntry_DoNotUse::DeviceStepStats_ThreadNamesEntry_DoNotUse(::google::protobuf::Arena* arena) : SuperType(arena) {}
#endif  // PROTOBUF_CUSTOM_VTABLE
              inline void* DeviceStepStats_ThreadNamesEntry_DoNotUse::PlacementNew_(const void*, void* mem,
                                                      ::google::protobuf::Arena* arena) {
                return ::new (mem) DeviceStepStats_ThreadNamesEntry_DoNotUse(arena);
              }
              constexpr auto DeviceStepStats_ThreadNamesEntry_DoNotUse::InternalNewImpl_() {
                return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(DeviceStepStats_ThreadNamesEntry_DoNotUse),
                                                          alignof(DeviceStepStats_ThreadNamesEntry_DoNotUse));
              }
              PROTOBUF_CONSTINIT
              PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
              const ::google::protobuf::internal::ClassDataFull DeviceStepStats_ThreadNamesEntry_DoNotUse::_class_data_ = {
                  ::google::protobuf::internal::ClassData{
                      &_DeviceStepStats_ThreadNamesEntry_DoNotUse_default_instance_._instance,
                      &_table_.header,
                      nullptr,  // OnDemandRegisterArenaDtor
                      nullptr,  // IsInitialized
                      &DeviceStepStats_ThreadNamesEntry_DoNotUse::MergeImpl,
                      ::google::protobuf::Message::GetNewImpl<DeviceStepStats_ThreadNamesEntry_DoNotUse>(),
              #if defined(PROTOBUF_CUSTOM_VTABLE)
                      &DeviceStepStats_ThreadNamesEntry_DoNotUse::SharedDtor,
                      static_cast<void (::google::protobuf::MessageLite::*)()>(
                          &DeviceStepStats_ThreadNamesEntry_DoNotUse::ClearImpl),
                          ::google::protobuf::Message::ByteSizeLongImpl, ::google::protobuf::Message::_InternalSerializeImpl
                          ,
              #endif  // PROTOBUF_CUSTOM_VTABLE
                      PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_._cached_size_),
                      false,
                  },
                  &DeviceStepStats_ThreadNamesEntry_DoNotUse::kDescriptorMethods,
                  &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
                  nullptr,  // tracker
              };
              const ::google::protobuf::internal::ClassData* DeviceStepStats_ThreadNamesEntry_DoNotUse::GetClassData() const {
                ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
                ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
                return _class_data_.base();
              }
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 57, 2> DeviceStepStats_ThreadNamesEntry_DoNotUse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::DiscardEverythingFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::DeviceStepStats_ThreadNamesEntry_DoNotUse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string value = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.value_)}},
    // uint32 key = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.key_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.key_)}},
  }}, {{
    65535, 65535
  }}, {{
    // uint32 key = 1;
    {PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.key_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUInt32)},
    // string value = 2;
    {PROTOBUF_FIELD_OFFSET(DeviceStepStats_ThreadNamesEntry_DoNotUse, _impl_.value_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\53\0\5\0\0\0\0\0"
    "tensorflow.DeviceStepStats.ThreadNamesEntry"
    "value"
  }},
};

// ===================================================================

class DeviceStepStats::_Internal {
 public:
};

DeviceStepStats::DeviceStepStats(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.DeviceStepStats)
}
inline PROTOBUF_NDEBUG_INLINE DeviceStepStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::DeviceStepStats& from_msg)
      : node_stats_{visibility, arena, from.node_stats_},
        thread_names_{visibility, arena, from.thread_names_},
        device_(arena, from.device_),
        _cached_size_{0} {}

DeviceStepStats::DeviceStepStats(
    ::google::protobuf::Arena* arena,
    const DeviceStepStats& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  DeviceStepStats* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);

  // @@protoc_insertion_point(copy_constructor:tensorflow.DeviceStepStats)
}
inline PROTOBUF_NDEBUG_INLINE DeviceStepStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : node_stats_{visibility, arena},
        thread_names_{visibility, arena},
        device_(arena),
        _cached_size_{0} {}

inline void DeviceStepStats::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
DeviceStepStats::~DeviceStepStats() {
  // @@protoc_insertion_point(destructor:tensorflow.DeviceStepStats)
  SharedDtor(*this);
}
inline void DeviceStepStats::SharedDtor(MessageLite& self) {
  DeviceStepStats& this_ = static_cast<DeviceStepStats&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.device_.Destroy();
  this_._impl_.~Impl_();
}

inline void* DeviceStepStats::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) DeviceStepStats(arena);
}
constexpr auto DeviceStepStats::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.node_stats_) +
          decltype(DeviceStepStats::_impl_.node_stats_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.thread_names_) +
          decltype(DeviceStepStats::_impl_.thread_names_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.thread_names_) +
          decltype(DeviceStepStats::_impl_.thread_names_)::
              InternalGetArenaOffsetAlt(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(DeviceStepStats), alignof(DeviceStepStats), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&DeviceStepStats::PlacementNew_,
                                 sizeof(DeviceStepStats),
                                 alignof(DeviceStepStats));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull DeviceStepStats::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_DeviceStepStats_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &DeviceStepStats::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<DeviceStepStats>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &DeviceStepStats::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<DeviceStepStats>(), &DeviceStepStats::ByteSizeLong,
            &DeviceStepStats::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_._cached_size_),
        false,
    },
    &DeviceStepStats::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* DeviceStepStats::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 3, 2, 53, 2> DeviceStepStats::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    3, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::DeviceStepStats>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // repeated .tensorflow.NodeExecStats node_stats = 2;
    {::_pbi::TcParser::FastMtR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.node_stats_)}},
    // string device = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.device_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string device = 1;
    {PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.device_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // repeated .tensorflow.NodeExecStats node_stats = 2;
    {PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.node_stats_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // map<uint32, string> thread_names = 3;
    {PROTOBUF_FIELD_OFFSET(DeviceStepStats, _impl_.thread_names_), 0, 1,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::NodeExecStats>()},
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(DeviceStepStats()._impl_.thread_names_)>(
        1, 0, 0, 13,
        9)},
  }}, {{
    "\32\6\0\14\0\0\0\0"
    "tensorflow.DeviceStepStats"
    "device"
    "thread_names"
  }},
};

PROTOBUF_NOINLINE void DeviceStepStats::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.DeviceStepStats)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.node_stats_.Clear();
  _impl_.thread_names_.Clear();
  _impl_.device_.ClearToEmpty();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* DeviceStepStats::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const DeviceStepStats& this_ = static_cast<const DeviceStepStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* DeviceStepStats::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const DeviceStepStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.DeviceStepStats)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string device = 1;
          if (!this_._internal_device().empty()) {
            const std::string& _s = this_._internal_device();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.DeviceStepStats.device");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // repeated .tensorflow.NodeExecStats node_stats = 2;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_node_stats_size());
               i < n; i++) {
            const auto& repfield = this_._internal_node_stats().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    2, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // map<uint32, string> thread_names = 3;
          if (!this_._internal_thread_names().empty()) {
            using MapType = ::google::protobuf::Map<::uint32_t, std::string>;
            using WireHelper = _pbi::MapEntryFuncs<::uint32_t, std::string,
                                           _pbi::WireFormatLite::TYPE_UINT32,
                                           _pbi::WireFormatLite::TYPE_STRING>;
            const auto& field = this_._internal_thread_names();

            if (stream->IsSerializationDeterministic() && field.size() > 1) {
              for (const auto& entry : ::google::protobuf::internal::MapSorterFlat<MapType>(field)) {
                target = WireHelper::InternalSerialize(
                    3, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.DeviceStepStats.thread_names");
              }
            } else {
              for (const auto& entry : field) {
                target = WireHelper::InternalSerialize(
                    3, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.DeviceStepStats.thread_names");
              }
            }
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.DeviceStepStats)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t DeviceStepStats::ByteSizeLong(const MessageLite& base) {
          const DeviceStepStats& this_ = static_cast<const DeviceStepStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t DeviceStepStats::ByteSizeLong() const {
          const DeviceStepStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.DeviceStepStats)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.NodeExecStats node_stats = 2;
            {
              total_size += 1UL * this_._internal_node_stats_size();
              for (const auto& msg : this_._internal_node_stats()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // map<uint32, string> thread_names = 3;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_thread_names_size());
              for (const auto& entry : this_._internal_thread_names()) {
                total_size += _pbi::MapEntryFuncs<::uint32_t, std::string,
                                               _pbi::WireFormatLite::TYPE_UINT32,
                                               _pbi::WireFormatLite::TYPE_STRING>::ByteSizeLong(entry.first, entry.second);
              }
            }
          }
           {
            // string device = 1;
            if (!this_._internal_device().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_device());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void DeviceStepStats::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<DeviceStepStats*>(&to_msg);
  auto& from = static_cast<const DeviceStepStats&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.DeviceStepStats)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_node_stats()->MergeFrom(
      from._internal_node_stats());
  _this->_impl_.thread_names_.MergeFrom(from._impl_.thread_names_);
  if (!from._internal_device().empty()) {
    _this->_internal_set_device(from._internal_device());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void DeviceStepStats::CopyFrom(const DeviceStepStats& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.DeviceStepStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void DeviceStepStats::InternalSwap(DeviceStepStats* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.node_stats_.InternalSwap(&other->_impl_.node_stats_);
  _impl_.thread_names_.InternalSwap(&other->_impl_.thread_names_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.device_, &other->_impl_.device_, arena);
}

::google::protobuf::Metadata DeviceStepStats::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class StepStats::_Internal {
 public:
};

StepStats::StepStats(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.StepStats)
}
inline PROTOBUF_NDEBUG_INLINE StepStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::StepStats& from_msg)
      : dev_stats_{visibility, arena, from.dev_stats_},
        _cached_size_{0} {}

StepStats::StepStats(
    ::google::protobuf::Arena* arena,
    const StepStats& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  StepStats* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);

  // @@protoc_insertion_point(copy_constructor:tensorflow.StepStats)
}
inline PROTOBUF_NDEBUG_INLINE StepStats::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : dev_stats_{visibility, arena},
        _cached_size_{0} {}

inline void StepStats::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
StepStats::~StepStats() {
  // @@protoc_insertion_point(destructor:tensorflow.StepStats)
  SharedDtor(*this);
}
inline void StepStats::SharedDtor(MessageLite& self) {
  StepStats& this_ = static_cast<StepStats&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* StepStats::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) StepStats(arena);
}
constexpr auto StepStats::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(StepStats, _impl_.dev_stats_) +
          decltype(StepStats::_impl_.dev_stats_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(StepStats), alignof(StepStats), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&StepStats::PlacementNew_,
                                 sizeof(StepStats),
                                 alignof(StepStats));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull StepStats::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_StepStats_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &StepStats::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<StepStats>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &StepStats::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<StepStats>(), &StepStats::ByteSizeLong,
            &StepStats::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(StepStats, _impl_._cached_size_),
        false,
    },
    &StepStats::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* StepStats::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 1, 0, 2> StepStats::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::StepStats>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // repeated .tensorflow.DeviceStepStats dev_stats = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(StepStats, _impl_.dev_stats_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .tensorflow.DeviceStepStats dev_stats = 1;
    {PROTOBUF_FIELD_OFFSET(StepStats, _impl_.dev_stats_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::DeviceStepStats>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void StepStats::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.StepStats)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.dev_stats_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* StepStats::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const StepStats& this_ = static_cast<const StepStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* StepStats::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const StepStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.StepStats)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .tensorflow.DeviceStepStats dev_stats = 1;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_dev_stats_size());
               i < n; i++) {
            const auto& repfield = this_._internal_dev_stats().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    1, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.StepStats)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t StepStats::ByteSizeLong(const MessageLite& base) {
          const StepStats& this_ = static_cast<const StepStats&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t StepStats::ByteSizeLong() const {
          const StepStats& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.StepStats)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.DeviceStepStats dev_stats = 1;
            {
              total_size += 1UL * this_._internal_dev_stats_size();
              for (const auto& msg : this_._internal_dev_stats()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void StepStats::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<StepStats*>(&to_msg);
  auto& from = static_cast<const StepStats&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.StepStats)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_dev_stats()->MergeFrom(
      from._internal_dev_stats());
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void StepStats::CopyFrom(const StepStats& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.StepStats)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void StepStats::InternalSwap(StepStats* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.dev_stats_.InternalSwap(&other->_impl_.dev_stats_);
}

::google::protobuf::Metadata StepStats::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::std::false_type
    _static_init2_ PROTOBUF_UNUSED =
        (::_pbi::AddDescriptors(&descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto),
         ::std::false_type{});
#include "google/protobuf/port_undef.inc"
