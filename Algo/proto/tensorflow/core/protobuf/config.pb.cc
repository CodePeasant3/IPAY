// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: tensorflow/core/protobuf/config.proto
// Protobuf C++ Version: 5.29.0

#include "tensorflow/core/protobuf/config.pb.h"

#include <algorithm>
#include <type_traits>
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/generated_message_tctable_impl.h"
#include "google/protobuf/extension_set.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/wire_format_lite.h"
#include "google/protobuf/descriptor.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/reflection_ops.h"
#include "google/protobuf/wire_format.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"
PROTOBUF_PRAGMA_INIT_SEG
namespace _pb = ::google::protobuf;
namespace _pbi = ::google::protobuf::internal;
namespace _fl = ::google::protobuf::internal::field_layout;
namespace tensorflow {

inline constexpr ThreadPoolOptionProto::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : global_name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        num_threads_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR ThreadPoolOptionProto::ThreadPoolOptionProto(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct ThreadPoolOptionProtoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ThreadPoolOptionProtoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~ThreadPoolOptionProtoDefaultTypeInternal() {}
  union {
    ThreadPoolOptionProto _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ThreadPoolOptionProtoDefaultTypeInternal _ThreadPoolOptionProto_default_instance_;

inline constexpr TensorConnection::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : from_tensor_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        to_tensor_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR TensorConnection::TensorConnection(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct TensorConnectionDefaultTypeInternal {
  PROTOBUF_CONSTEXPR TensorConnectionDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~TensorConnectionDefaultTypeInternal() {}
  union {
    TensorConnection _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 TensorConnectionDefaultTypeInternal _TensorConnection_default_instance_;

inline constexpr SessionMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : name_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        version_{::int64_t{0}},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR SessionMetadata::SessionMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct SessionMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR SessionMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~SessionMetadataDefaultTypeInternal() {}
  union {
    SessionMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 SessionMetadataDefaultTypeInternal _SessionMetadata_default_instance_;

inline constexpr RunOptions_Experimental_RunHandlerPoolOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : priority_{::int64_t{0}},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR RunOptions_Experimental_RunHandlerPoolOptions::RunOptions_Experimental_RunHandlerPoolOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RunOptions_Experimental_RunHandlerPoolOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RunOptions_Experimental_RunHandlerPoolOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RunOptions_Experimental_RunHandlerPoolOptionsDefaultTypeInternal() {}
  union {
    RunOptions_Experimental_RunHandlerPoolOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RunOptions_Experimental_RunHandlerPoolOptionsDefaultTypeInternal _RunOptions_Experimental_RunHandlerPoolOptions_default_instance_;

inline constexpr OptimizerOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : opt_level_{static_cast< ::tensorflow::OptimizerOptions_Level >(0)},
        do_common_subexpression_elimination_{false},
        do_constant_folding_{false},
        do_function_inlining_{false},
        cpu_global_jit_{false},
        max_folded_constant_in_bytes_{::int64_t{0}},
        global_jit_level_{static_cast< ::tensorflow::OptimizerOptions_GlobalJitLevel >(0)},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR OptimizerOptions::OptimizerOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct OptimizerOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR OptimizerOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~OptimizerOptionsDefaultTypeInternal() {}
  union {
    OptimizerOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 OptimizerOptionsDefaultTypeInternal _OptimizerOptions_default_instance_;

inline constexpr GPUOptions_Experimental_VirtualDevices::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : memory_limit_mb_{},
        priority_{},
        _priority_cached_byte_size_{0},
        device_ordinal_{},
        _device_ordinal_cached_byte_size_{0},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR GPUOptions_Experimental_VirtualDevices::GPUOptions_Experimental_VirtualDevices(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct GPUOptions_Experimental_VirtualDevicesDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GPUOptions_Experimental_VirtualDevicesDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~GPUOptions_Experimental_VirtualDevicesDefaultTypeInternal() {}
  union {
    GPUOptions_Experimental_VirtualDevices _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GPUOptions_Experimental_VirtualDevicesDefaultTypeInternal _GPUOptions_Experimental_VirtualDevices_default_instance_;

inline constexpr GPUOptions_Experimental_StreamMergeOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : merge_host_to_device_stream_{false},
        merge_device_to_host_stream_{false},
        merge_device_to_device_stream_{false},
        _cached_size_{0} {}

template <typename>
PROTOBUF_CONSTEXPR GPUOptions_Experimental_StreamMergeOptions::GPUOptions_Experimental_StreamMergeOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct GPUOptions_Experimental_StreamMergeOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GPUOptions_Experimental_StreamMergeOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~GPUOptions_Experimental_StreamMergeOptionsDefaultTypeInternal() {}
  union {
    GPUOptions_Experimental_StreamMergeOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GPUOptions_Experimental_StreamMergeOptionsDefaultTypeInternal _GPUOptions_Experimental_StreamMergeOptions_default_instance_;
              template <typename>
PROTOBUF_CONSTEXPR ConfigProto_DeviceCountEntry_DoNotUse::ConfigProto_DeviceCountEntry_DoNotUse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ConfigProto_DeviceCountEntry_DoNotUse::MapEntry(_class_data_.base()){}
#else   // PROTOBUF_CUSTOM_VTABLE
    : ConfigProto_DeviceCountEntry_DoNotUse::MapEntry() {
}
#endif  // PROTOBUF_CUSTOM_VTABLE
struct ConfigProto_DeviceCountEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ConfigProto_DeviceCountEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~ConfigProto_DeviceCountEntry_DoNotUseDefaultTypeInternal() {}
  union {
    ConfigProto_DeviceCountEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ConfigProto_DeviceCountEntry_DoNotUseDefaultTypeInternal _ConfigProto_DeviceCountEntry_DoNotUse_default_instance_;
              template <typename>
PROTOBUF_CONSTEXPR CallableOptions_FetchDevicesEntry_DoNotUse::CallableOptions_FetchDevicesEntry_DoNotUse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : CallableOptions_FetchDevicesEntry_DoNotUse::MapEntry(_class_data_.base()){}
#else   // PROTOBUF_CUSTOM_VTABLE
    : CallableOptions_FetchDevicesEntry_DoNotUse::MapEntry() {
}
#endif  // PROTOBUF_CUSTOM_VTABLE
struct CallableOptions_FetchDevicesEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CallableOptions_FetchDevicesEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~CallableOptions_FetchDevicesEntry_DoNotUseDefaultTypeInternal() {}
  union {
    CallableOptions_FetchDevicesEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CallableOptions_FetchDevicesEntry_DoNotUseDefaultTypeInternal _CallableOptions_FetchDevicesEntry_DoNotUse_default_instance_;
              template <typename>
PROTOBUF_CONSTEXPR CallableOptions_FeedDevicesEntry_DoNotUse::CallableOptions_FeedDevicesEntry_DoNotUse(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : CallableOptions_FeedDevicesEntry_DoNotUse::MapEntry(_class_data_.base()){}
#else   // PROTOBUF_CUSTOM_VTABLE
    : CallableOptions_FeedDevicesEntry_DoNotUse::MapEntry() {
}
#endif  // PROTOBUF_CUSTOM_VTABLE
struct CallableOptions_FeedDevicesEntry_DoNotUseDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CallableOptions_FeedDevicesEntry_DoNotUseDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~CallableOptions_FeedDevicesEntry_DoNotUseDefaultTypeInternal() {}
  union {
    CallableOptions_FeedDevicesEntry_DoNotUse _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CallableOptions_FeedDevicesEntry_DoNotUseDefaultTypeInternal _CallableOptions_FeedDevicesEntry_DoNotUse_default_instance_;

inline constexpr RunOptions_Experimental::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        run_handler_pool_options_{nullptr},
        collective_graph_key_{::int64_t{0}},
        use_run_handler_pool_{false} {}

template <typename>
PROTOBUF_CONSTEXPR RunOptions_Experimental::RunOptions_Experimental(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RunOptions_ExperimentalDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RunOptions_ExperimentalDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RunOptions_ExperimentalDefaultTypeInternal() {}
  union {
    RunOptions_Experimental _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RunOptions_ExperimentalDefaultTypeInternal _RunOptions_Experimental_default_instance_;

inline constexpr GPUOptions_Experimental::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        virtual_devices_{},
        collective_ring_order_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        stream_merge_options_{nullptr},
        num_dev_to_dev_copy_streams_{0},
        kernel_tracker_max_interval_{0},
        use_unified_memory_{false},
        timestamped_allocator_{false},
        use_cuda_malloc_async_{false},
        disallow_retry_on_allocation_failure_{false},
        kernel_tracker_max_bytes_{0},
        internal_fragmentation_fraction_{0},
        kernel_tracker_max_pending_{0},
        gpu_host_mem_limit_in_mb_{0},
        num_virtual_devices_per_gpu_{0},
        gpu_host_mem_disallow_growth_{false},
        populate_pjrt_gpu_client_creation_info_{false},
        gpu_system_memory_size_in_mb_{0},
        node_id_{0} {}

template <typename>
PROTOBUF_CONSTEXPR GPUOptions_Experimental::GPUOptions_Experimental(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct GPUOptions_ExperimentalDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GPUOptions_ExperimentalDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~GPUOptions_ExperimentalDefaultTypeInternal() {}
  union {
    GPUOptions_Experimental _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GPUOptions_ExperimentalDefaultTypeInternal _GPUOptions_Experimental_default_instance_;

inline constexpr RunOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        debug_options_{nullptr},
        experimental_{nullptr},
        timeout_in_ms_{::int64_t{0}},
        trace_level_{static_cast< ::tensorflow::RunOptions_TraceLevel >(0)},
        inter_op_thread_pool_{0},
        output_partition_graphs_{false},
        report_tensor_allocations_upon_oom_{false} {}

template <typename>
PROTOBUF_CONSTEXPR RunOptions::RunOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RunOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RunOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RunOptionsDefaultTypeInternal() {}
  union {
    RunOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RunOptionsDefaultTypeInternal _RunOptions_default_instance_;

inline constexpr GPUOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        allocator_type_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        visible_device_list_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        experimental_{nullptr},
        per_process_gpu_memory_fraction_{0},
        deferred_deletion_bytes_{::int64_t{0}},
        polling_active_delay_usecs_{0},
        allow_growth_{false},
        force_gpu_compatible_{false},
        polling_inactive_delay_msecs_{0} {}

template <typename>
PROTOBUF_CONSTEXPR GPUOptions::GPUOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct GPUOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GPUOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~GPUOptionsDefaultTypeInternal() {}
  union {
    GPUOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GPUOptionsDefaultTypeInternal _GPUOptions_default_instance_;

inline constexpr ConfigProto_Experimental::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        collective_group_leader_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        executor_type_(
            &::google::protobuf::internal::fixed_address_empty_string,
            ::_pbi::ConstantInitialized()),
        session_metadata_{nullptr},
        coordination_config_{nullptr},
        recv_buf_max_chunk_{0},
        use_numa_affinity_{false},
        collective_deterministic_sequential_execution_{false},
        collective_nccl_{false},
        share_session_state_in_clusterspec_propagation_{false},
        disable_thread_spinning_{false},
        share_cluster_devices_in_session_{false},
        optimize_for_static_graph_{false},
        enable_mlir_bridge_{false},
        mlir_bridge_rollout_{static_cast< ::tensorflow::ConfigProto_Experimental_MlirBridgeRollout >(0)},
        xla_fusion_autotuner_thresh_{::int64_t{0}},
        enable_mlir_graph_optimization_{false},
        disable_output_partition_graphs_{false},
        use_tfrt_{false},
        enable_multi_host_{false},
        xla_prefer_single_graph_cluster_{false},
        disable_optimize_for_static_graph_{false},
        disable_eager_executor_streaming_enqueue_{false},
        backend_server_port_{0},
        tfrt_use_ifrt_{false},
        target_tpu_{false},
        target_gpu_{false},
        disable_functional_ops_lowering_{false},
        stream_merge_threshold_{0} {}

template <typename>
PROTOBUF_CONSTEXPR ConfigProto_Experimental::ConfigProto_Experimental(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct ConfigProto_ExperimentalDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ConfigProto_ExperimentalDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~ConfigProto_ExperimentalDefaultTypeInternal() {}
  union {
    ConfigProto_Experimental _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ConfigProto_ExperimentalDefaultTypeInternal _ConfigProto_Experimental_default_instance_;

inline constexpr CallableOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        feed_{},
        fetch_{},
        target_{},
        tensor_connection_{},
        feed_devices_{},
        fetch_devices_{},
        run_options_{nullptr},
        fetch_skip_sync_{false} {}

template <typename>
PROTOBUF_CONSTEXPR CallableOptions::CallableOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct CallableOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR CallableOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~CallableOptionsDefaultTypeInternal() {}
  union {
    CallableOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 CallableOptionsDefaultTypeInternal _CallableOptions_default_instance_;

inline constexpr GraphOptions::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        optimizer_options_{nullptr},
        rewrite_options_{nullptr},
        build_cost_model_{::int64_t{0}},
        enable_recv_scheduling_{false},
        infer_shapes_{false},
        place_pruned_graph_{false},
        enable_bfloat16_sendrecv_{false},
        timeline_step_{0},
        build_cost_model_after_{::int64_t{0}} {}

template <typename>
PROTOBUF_CONSTEXPR GraphOptions::GraphOptions(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct GraphOptionsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR GraphOptionsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~GraphOptionsDefaultTypeInternal() {}
  union {
    GraphOptions _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 GraphOptionsDefaultTypeInternal _GraphOptions_default_instance_;

inline constexpr ConfigProto::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        device_count_{},
        device_filters_{},
        session_inter_op_thread_pool_{},
        gpu_options_{nullptr},
        graph_options_{nullptr},
        rpc_options_{nullptr},
        cluster_def_{nullptr},
        experimental_{nullptr},
        pluggable_device_options_{nullptr},
        intra_op_parallelism_threads_{0},
        placement_period_{0},
        inter_op_parallelism_threads_{0},
        use_per_session_threads_{false},
        allow_soft_placement_{false},
        log_device_placement_{false},
        isolate_session_state_{false},
        operation_timeout_in_ms_{::int64_t{0}},
        share_cluster_devices_in_session_{false} {}

template <typename>
PROTOBUF_CONSTEXPR ConfigProto::ConfigProto(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct ConfigProtoDefaultTypeInternal {
  PROTOBUF_CONSTEXPR ConfigProtoDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~ConfigProtoDefaultTypeInternal() {}
  union {
    ConfigProto _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 ConfigProtoDefaultTypeInternal _ConfigProto_default_instance_;

inline constexpr RunMetadata_FunctionGraphs::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        partition_graphs_{},
        pre_optimization_graph_{nullptr},
        post_optimization_graph_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RunMetadata_FunctionGraphs::RunMetadata_FunctionGraphs(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RunMetadata_FunctionGraphsDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RunMetadata_FunctionGraphsDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RunMetadata_FunctionGraphsDefaultTypeInternal() {}
  union {
    RunMetadata_FunctionGraphs _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RunMetadata_FunctionGraphsDefaultTypeInternal _RunMetadata_FunctionGraphs_default_instance_;

inline constexpr RunMetadata::Impl_::Impl_(
    ::_pbi::ConstantInitialized) noexcept
      : _cached_size_{0},
        partition_graphs_{},
        function_graphs_{},
        step_stats_{nullptr},
        cost_graph_{nullptr},
        session_metadata_{nullptr} {}

template <typename>
PROTOBUF_CONSTEXPR RunMetadata::RunMetadata(::_pbi::ConstantInitialized)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(_class_data_.base()),
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(),
#endif  // PROTOBUF_CUSTOM_VTABLE
      _impl_(::_pbi::ConstantInitialized()) {
}
struct RunMetadataDefaultTypeInternal {
  PROTOBUF_CONSTEXPR RunMetadataDefaultTypeInternal() : _instance(::_pbi::ConstantInitialized{}) {}
  ~RunMetadataDefaultTypeInternal() {}
  union {
    RunMetadata _instance;
  };
};

PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT
    PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 RunMetadataDefaultTypeInternal _RunMetadata_default_instance_;
}  // namespace tensorflow
static const ::_pb::EnumDescriptor* file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[4];
static constexpr const ::_pb::ServiceDescriptor**
    file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto = nullptr;
const ::uint32_t
    TableStruct_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::offsets[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
        protodesc_cold) = {
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_VirtualDevices, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_VirtualDevices, _impl_.memory_limit_mb_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_VirtualDevices, _impl_.priority_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_VirtualDevices, _impl_.device_ordinal_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_StreamMergeOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_host_to_device_stream_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_host_stream_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_device_stream_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.virtual_devices_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.num_virtual_devices_per_gpu_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.use_unified_memory_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.num_dev_to_dev_copy_streams_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.collective_ring_order_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.timestamped_allocator_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.kernel_tracker_max_interval_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.kernel_tracker_max_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.kernel_tracker_max_pending_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.internal_fragmentation_fraction_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.use_cuda_malloc_async_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.disallow_retry_on_allocation_failure_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.gpu_host_mem_limit_in_mb_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.gpu_host_mem_disallow_growth_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.gpu_system_memory_size_in_mb_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.populate_pjrt_gpu_client_creation_info_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.node_id_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions_Experimental, _impl_.stream_merge_options_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.per_process_gpu_memory_fraction_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.allow_growth_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.allocator_type_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.deferred_deletion_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.visible_device_list_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.polling_active_delay_usecs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.polling_inactive_delay_msecs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.force_gpu_compatible_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GPUOptions, _impl_.experimental_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.do_common_subexpression_elimination_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.do_constant_folding_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.max_folded_constant_in_bytes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.do_function_inlining_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.opt_level_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.global_jit_level_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::OptimizerOptions, _impl_.cpu_global_jit_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.enable_recv_scheduling_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.optimizer_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.build_cost_model_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.build_cost_model_after_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.infer_shapes_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.place_pruned_graph_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.enable_bfloat16_sendrecv_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.timeline_step_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::GraphOptions, _impl_.rewrite_options_),
        ~0u,
        0,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        1,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::ThreadPoolOptionProto, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::ThreadPoolOptionProto, _impl_.num_threads_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ThreadPoolOptionProto, _impl_.global_name_),
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::SessionMetadata, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::SessionMetadata, _impl_.name_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::SessionMetadata, _impl_.version_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse, _impl_.key_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse, _impl_.value_),
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.collective_group_leader_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.executor_type_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.recv_buf_max_chunk_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.use_numa_affinity_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.collective_deterministic_sequential_execution_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.collective_nccl_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.share_session_state_in_clusterspec_propagation_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.disable_thread_spinning_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.share_cluster_devices_in_session_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.session_metadata_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.optimize_for_static_graph_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.enable_mlir_bridge_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.mlir_bridge_rollout_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.enable_mlir_graph_optimization_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.disable_output_partition_graphs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.xla_fusion_autotuner_thresh_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.use_tfrt_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.enable_multi_host_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.tfrt_use_ifrt_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.backend_server_port_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.target_tpu_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.target_gpu_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.stream_merge_threshold_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.disable_functional_ops_lowering_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.xla_prefer_single_graph_cluster_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.coordination_config_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.disable_optimize_for_static_graph_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto_Experimental, _impl_.disable_eager_executor_streaming_enqueue_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        1,
        ~0u,
        ~0u,
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.device_count_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.intra_op_parallelism_threads_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.inter_op_parallelism_threads_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.use_per_session_threads_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.session_inter_op_thread_pool_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.placement_period_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.device_filters_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.gpu_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.pluggable_device_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.allow_soft_placement_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.log_device_placement_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.graph_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.operation_timeout_in_ms_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.rpc_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.cluster_def_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.isolate_session_state_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.share_cluster_devices_in_session_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::ConfigProto, _impl_.experimental_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        5,
        ~0u,
        ~0u,
        1,
        ~0u,
        2,
        3,
        ~0u,
        ~0u,
        4,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions, _impl_.priority_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental, _impl_.collective_graph_key_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental, _impl_.use_run_handler_pool_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions_Experimental, _impl_.run_handler_pool_options_),
        ~0u,
        ~0u,
        0,
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.trace_level_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.timeout_in_ms_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.inter_op_thread_pool_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.output_partition_graphs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.debug_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.report_tensor_allocations_upon_oom_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunOptions, _impl_.experimental_),
        ~0u,
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,
        1,
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata_FunctionGraphs, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata_FunctionGraphs, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata_FunctionGraphs, _impl_.partition_graphs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata_FunctionGraphs, _impl_.pre_optimization_graph_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata_FunctionGraphs, _impl_.post_optimization_graph_),
        ~0u,
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_.step_stats_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_.cost_graph_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_.partition_graphs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_.function_graphs_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::RunMetadata, _impl_.session_metadata_),
        0,
        1,
        ~0u,
        ~0u,
        2,
        ~0u,  // no _has_bits_
        PROTOBUF_FIELD_OFFSET(::tensorflow::TensorConnection, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::TensorConnection, _impl_.from_tensor_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::TensorConnection, _impl_.to_tensor_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.key_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.value_),
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.key_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.value_),
        0,
        1,
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_._has_bits_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _internal_metadata_),
        ~0u,  // no _extensions_
        ~0u,  // no _oneof_case_
        ~0u,  // no _weak_field_map_
        ~0u,  // no _inlined_string_donated_
        ~0u,  // no _split_
        ~0u,  // no sizeof(Split)
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.feed_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.fetch_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.target_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.run_options_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.tensor_connection_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.feed_devices_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.fetch_devices_),
        PROTOBUF_FIELD_OFFSET(::tensorflow::CallableOptions, _impl_.fetch_skip_sync_),
        ~0u,
        ~0u,
        ~0u,
        0,
        ~0u,
        ~0u,
        ~0u,
        ~0u,
};

static const ::_pbi::MigrationSchema
    schemas[] ABSL_ATTRIBUTE_SECTION_VARIABLE(protodesc_cold) = {
        {0, -1, -1, sizeof(::tensorflow::GPUOptions_Experimental_VirtualDevices)},
        {11, -1, -1, sizeof(::tensorflow::GPUOptions_Experimental_StreamMergeOptions)},
        {22, 48, -1, sizeof(::tensorflow::GPUOptions_Experimental)},
        {66, 83, -1, sizeof(::tensorflow::GPUOptions)},
        {92, -1, -1, sizeof(::tensorflow::OptimizerOptions)},
        {107, 124, -1, sizeof(::tensorflow::GraphOptions)},
        {133, -1, -1, sizeof(::tensorflow::ThreadPoolOptionProto)},
        {143, -1, -1, sizeof(::tensorflow::SessionMetadata)},
        {153, 163, -1, sizeof(::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse)},
        {165, 201, -1, sizeof(::tensorflow::ConfigProto_Experimental)},
        {229, 255, -1, sizeof(::tensorflow::ConfigProto)},
        {273, -1, -1, sizeof(::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions)},
        {282, 293, -1, sizeof(::tensorflow::RunOptions_Experimental)},
        {296, 311, -1, sizeof(::tensorflow::RunOptions)},
        {318, 329, -1, sizeof(::tensorflow::RunMetadata_FunctionGraphs)},
        {332, 345, -1, sizeof(::tensorflow::RunMetadata)},
        {350, -1, -1, sizeof(::tensorflow::TensorConnection)},
        {360, 370, -1, sizeof(::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse)},
        {372, 382, -1, sizeof(::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse)},
        {384, 400, -1, sizeof(::tensorflow::CallableOptions)},
};
static const ::_pb::Message* const file_default_instances[] = {
    &::tensorflow::_GPUOptions_Experimental_VirtualDevices_default_instance_._instance,
    &::tensorflow::_GPUOptions_Experimental_StreamMergeOptions_default_instance_._instance,
    &::tensorflow::_GPUOptions_Experimental_default_instance_._instance,
    &::tensorflow::_GPUOptions_default_instance_._instance,
    &::tensorflow::_OptimizerOptions_default_instance_._instance,
    &::tensorflow::_GraphOptions_default_instance_._instance,
    &::tensorflow::_ThreadPoolOptionProto_default_instance_._instance,
    &::tensorflow::_SessionMetadata_default_instance_._instance,
    &::tensorflow::_ConfigProto_DeviceCountEntry_DoNotUse_default_instance_._instance,
    &::tensorflow::_ConfigProto_Experimental_default_instance_._instance,
    &::tensorflow::_ConfigProto_default_instance_._instance,
    &::tensorflow::_RunOptions_Experimental_RunHandlerPoolOptions_default_instance_._instance,
    &::tensorflow::_RunOptions_Experimental_default_instance_._instance,
    &::tensorflow::_RunOptions_default_instance_._instance,
    &::tensorflow::_RunMetadata_FunctionGraphs_default_instance_._instance,
    &::tensorflow::_RunMetadata_default_instance_._instance,
    &::tensorflow::_TensorConnection_default_instance_._instance,
    &::tensorflow::_CallableOptions_FeedDevicesEntry_DoNotUse_default_instance_._instance,
    &::tensorflow::_CallableOptions_FetchDevicesEntry_DoNotUse_default_instance_._instance,
    &::tensorflow::_CallableOptions_default_instance_._instance,
};
const char descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[] ABSL_ATTRIBUTE_SECTION_VARIABLE(
    protodesc_cold) = {
    "\n%tensorflow/core/protobuf/config.proto\022"
    "\ntensorflow\032*tensorflow/core/framework/c"
    "ost_graph.proto\032%tensorflow/core/framewo"
    "rk/graph.proto\032*tensorflow/core/framewor"
    "k/step_stats.proto\032&tensorflow/core/prot"
    "obuf/cluster.proto\032$tensorflow/core/prot"
    "obuf/debug.proto\032.tensorflow/core/protob"
    "uf/rewriter_config.proto\032*tensorflow/cor"
    "e/protobuf/rpc_options.proto\032&tsl/protob"
    "uf/coordination_config.proto\"\211\n\n\nGPUOpti"
    "ons\022\'\n\037per_process_gpu_memory_fraction\030\001"
    " \001(\001\022\024\n\014allow_growth\030\004 \001(\010\022\026\n\016allocator_"
    "type\030\002 \001(\t\022\037\n\027deferred_deletion_bytes\030\003 "
    "\001(\003\022\033\n\023visible_device_list\030\005 \001(\t\022\"\n\032poll"
    "ing_active_delay_usecs\030\006 \001(\005\022$\n\034polling_"
    "inactive_delay_msecs\030\007 \001(\005\022\034\n\024force_gpu_"
    "compatible\030\010 \001(\010\0229\n\014experimental\030\t \001(\0132#"
    ".tensorflow.GPUOptions.Experimental\032\302\007\n\014"
    "Experimental\022K\n\017virtual_devices\030\001 \003(\01322."
    "tensorflow.GPUOptions.Experimental.Virtu"
    "alDevices\022#\n\033num_virtual_devices_per_gpu"
    "\030\017 \001(\005\022\032\n\022use_unified_memory\030\002 \001(\010\022#\n\033nu"
    "m_dev_to_dev_copy_streams\030\003 \001(\005\022\035\n\025colle"
    "ctive_ring_order\030\004 \001(\t\022\035\n\025timestamped_al"
    "locator\030\005 \001(\010\022#\n\033kernel_tracker_max_inte"
    "rval\030\007 \001(\005\022 \n\030kernel_tracker_max_bytes\030\010"
    " \001(\005\022\"\n\032kernel_tracker_max_pending\030\t \001(\005"
    "\022\'\n\037internal_fragmentation_fraction\030\n \001("
    "\001\022\035\n\025use_cuda_malloc_async\030\013 \001(\010\022,\n$disa"
    "llow_retry_on_allocation_failure\030\014 \001(\010\022 "
    "\n\030gpu_host_mem_limit_in_mb\030\r \001(\002\022$\n\034gpu_"
    "host_mem_disallow_growth\030\016 \001(\010\022$\n\034gpu_sy"
    "stem_memory_size_in_mb\030\020 \001(\005\022.\n&populate"
    "_pjrt_gpu_client_creation_info\030\021 \001(\010\022\017\n\007"
    "node_id\030\022 \001(\005\022T\n\024stream_merge_options\030\023 "
    "\001(\01326.tensorflow.GPUOptions.Experimental"
    ".StreamMergeOptions\032S\n\016VirtualDevices\022\027\n"
    "\017memory_limit_mb\030\001 \003(\002\022\020\n\010priority\030\002 \003(\005"
    "\022\026\n\016device_ordinal\030\003 \003(\005\032\205\001\n\022StreamMerge"
    "Options\022#\n\033merge_host_to_device_stream\030\001"
    " \001(\010\022#\n\033merge_device_to_host_stream\030\002 \001("
    "\010\022%\n\035merge_device_to_device_stream\030\003 \001(\010"
    "\"\235\003\n\020OptimizerOptions\022+\n#do_common_subex"
    "pression_elimination\030\001 \001(\010\022\033\n\023do_constan"
    "t_folding\030\002 \001(\010\022$\n\034max_folded_constant_i"
    "n_bytes\030\006 \001(\003\022\034\n\024do_function_inlining\030\004 "
    "\001(\010\0225\n\topt_level\030\003 \001(\0162\".tensorflow.Opti"
    "mizerOptions.Level\022E\n\020global_jit_level\030\005"
    " \001(\0162+.tensorflow.OptimizerOptions.Globa"
    "lJitLevel\022\026\n\016cpu_global_jit\030\007 \001(\010\" \n\005Lev"
    "el\022\006\n\002L1\020\000\022\017\n\002L0\020\377\377\377\377\377\377\377\377\377\001\"C\n\016GlobalJit"
    "Level\022\013\n\007DEFAULT\020\000\022\020\n\003OFF\020\377\377\377\377\377\377\377\377\377\001\022\010\n\004"
    "ON_1\020\001\022\010\n\004ON_2\020\002\"\356\002\n\014GraphOptions\022\036\n\026ena"
    "ble_recv_scheduling\030\002 \001(\010\0227\n\021optimizer_o"
    "ptions\030\003 \001(\0132\034.tensorflow.OptimizerOptio"
    "ns\022\030\n\020build_cost_model\030\004 \001(\003\022\036\n\026build_co"
    "st_model_after\030\t \001(\003\022\024\n\014infer_shapes\030\005 \001"
    "(\010\022\032\n\022place_pruned_graph\030\006 \001(\010\022 \n\030enable"
    "_bfloat16_sendrecv\030\007 \001(\010\022\025\n\rtimeline_ste"
    "p\030\010 \001(\005\0223\n\017rewrite_options\030\n \001(\0132\032.tenso"
    "rflow.RewriterConfigJ\004\010\001\020\002R%skip_common_"
    "subexpression_elimination\"A\n\025ThreadPoolO"
    "ptionProto\022\023\n\013num_threads\030\001 \001(\005\022\023\n\013globa"
    "l_name\030\002 \001(\t\"0\n\017SessionMetadata\022\014\n\004name\030"
    "\001 \001(\t\022\017\n\007version\030\002 \001(\003\"\346\020\n\013ConfigProto\022>"
    "\n\014device_count\030\001 \003(\0132(.tensorflow.Config"
    "Proto.DeviceCountEntry\022$\n\034intra_op_paral"
    "lelism_threads\030\002 \001(\005\022$\n\034inter_op_paralle"
    "lism_threads\030\005 \001(\005\022\037\n\027use_per_session_th"
    "reads\030\t \001(\010\022G\n\034session_inter_op_thread_p"
    "ool\030\014 \003(\0132!.tensorflow.ThreadPoolOptionP"
    "roto\022\030\n\020placement_period\030\003 \001(\005\022\026\n\016device"
    "_filters\030\004 \003(\t\022+\n\013gpu_options\030\006 \001(\0132\026.te"
    "nsorflow.GPUOptions\0228\n\030pluggable_device_"
    "options\030\022 \001(\0132\026.tensorflow.GPUOptions\022\034\n"
    "\024allow_soft_placement\030\007 \001(\010\022\034\n\024log_devic"
    "e_placement\030\010 \001(\010\022/\n\rgraph_options\030\n \001(\013"
    "2\030.tensorflow.GraphOptions\022\037\n\027operation_"
    "timeout_in_ms\030\013 \001(\003\022+\n\013rpc_options\030\r \001(\013"
    "2\026.tensorflow.RPCOptions\022+\n\013cluster_def\030"
    "\016 \001(\0132\026.tensorflow.ClusterDef\022\035\n\025isolate"
    "_session_state\030\017 \001(\010\022(\n share_cluster_de"
    "vices_in_session\030\021 \001(\010\022:\n\014experimental\030\020"
    " \001(\0132$.tensorflow.ConfigProto.Experiment"
    "al\0322\n\020DeviceCountEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005v"
    "alue\030\002 \001(\005:\0028\001\032\246\n\n\014Experimental\022\037\n\027colle"
    "ctive_group_leader\030\001 \001(\t\022\025\n\rexecutor_typ"
    "e\030\003 \001(\t\022\032\n\022recv_buf_max_chunk\030\004 \001(\005\022\031\n\021u"
    "se_numa_affinity\030\005 \001(\010\0225\n-collective_det"
    "erministic_sequential_execution\030\006 \001(\010\022\027\n"
    "\017collective_nccl\030\007 \001(\010\0226\n.share_session_"
    "state_in_clusterspec_propagation\030\010 \001(\010\022\037"
    "\n\027disable_thread_spinning\030\t \001(\010\022(\n share"
    "_cluster_devices_in_session\030\n \001(\010\0225\n\020ses"
    "sion_metadata\030\013 \001(\0132\033.tensorflow.Session"
    "Metadata\022!\n\031optimize_for_static_graph\030\014 "
    "\001(\010\022\032\n\022enable_mlir_bridge\030\r \001(\010\022S\n\023mlir_"
    "bridge_rollout\030\021 \001(\01626.tensorflow.Config"
    "Proto.Experimental.MlirBridgeRollout\022&\n\036"
    "enable_mlir_graph_optimization\030\020 \001(\010\022\'\n\037"
    "disable_output_partition_graphs\030\016 \001(\010\022#\n"
    "\033xla_fusion_autotuner_thresh\030\017 \001(\003\022\020\n\010us"
    "e_tfrt\030\022 \001(\010\022\031\n\021enable_multi_host\030\033 \001(\010\022"
    "\025\n\rtfrt_use_ifrt\030  \001(\010\022\033\n\023backend_server"
    "_port\030\034 \001(\005\022\022\n\ntarget_tpu\030\035 \001(\010\022\022\n\ntarge"
    "t_gpu\030\036 \001(\010\022\036\n\026stream_merge_threshold\030\037 "
    "\001(\005\022\'\n\037disable_functional_ops_lowering\030\025"
    " \001(\010\022\'\n\037xla_prefer_single_graph_cluster\030"
    "\026 \001(\010\022B\n\023coordination_config\030\027 \001(\0132%.ten"
    "sorflow.CoordinationServiceConfig\022)\n!dis"
    "able_optimize_for_static_graph\030\030 \001(\010\0220\n("
    "disable_eager_executor_streaming_enqueue"
    "\030\032 \001(\010\"\336\001\n\021MlirBridgeRollout\022#\n\037MLIR_BRI"
    "DGE_ROLLOUT_UNSPECIFIED\020\000\022\037\n\033MLIR_BRIDGE"
    "_ROLLOUT_ENABLED\020\001\022 \n\034MLIR_BRIDGE_ROLLOU"
    "T_DISABLED\020\002\"\004\010\003\020\003\"\004\010\004\020\004*%MLIR_BRIDGE_RO"
    "LLOUT_SAFE_MODE_ENABLED*.MLIR_BRIDGE_ROL"
    "LOUT_SAFE_MODE_FALLBACK_ENABLEDJ\004\010\002\020\003J\004\010"
    "\023\020\024J\004\010\024\020\025J\004\010\031\020\032\"\341\004\n\nRunOptions\0226\n\013trace_"
    "level\030\001 \001(\0162!.tensorflow.RunOptions.Trac"
    "eLevel\022\025\n\rtimeout_in_ms\030\002 \001(\003\022\034\n\024inter_o"
    "p_thread_pool\030\003 \001(\005\022\037\n\027output_partition_"
    "graphs\030\005 \001(\010\022/\n\rdebug_options\030\006 \001(\0132\030.te"
    "nsorflow.DebugOptions\022*\n\"report_tensor_a"
    "llocations_upon_oom\030\007 \001(\010\0229\n\014experimenta"
    "l\030\010 \001(\0132#.tensorflow.RunOptions.Experime"
    "ntal\032\322\001\n\014Experimental\022\034\n\024collective_grap"
    "h_key\030\001 \001(\003\022\034\n\024use_run_handler_pool\030\002 \001("
    "\010\022[\n\030run_handler_pool_options\030\003 \001(\01329.te"
    "nsorflow.RunOptions.Experimental.RunHand"
    "lerPoolOptions\032)\n\025RunHandlerPoolOptions\022"
    "\020\n\010priority\030\001 \001(\003\"R\n\nTraceLevel\022\014\n\010NO_TR"
    "ACE\020\000\022\022\n\016SOFTWARE_TRACE\020\001\022\022\n\016HARDWARE_TR"
    "ACE\020\002\022\016\n\nFULL_TRACE\020\003J\004\010\004\020\005\"\276\003\n\013RunMetad"
    "ata\022)\n\nstep_stats\030\001 \001(\0132\025.tensorflow.Ste"
    "pStats\022,\n\ncost_graph\030\002 \001(\0132\030.tensorflow."
    "CostGraphDef\022.\n\020partition_graphs\030\003 \003(\0132\024"
    ".tensorflow.GraphDef\022\?\n\017function_graphs\030"
    "\004 \003(\0132&.tensorflow.RunMetadata.FunctionG"
    "raphs\0225\n\020session_metadata\030\005 \001(\0132\033.tensor"
    "flow.SessionMetadata\032\255\001\n\016FunctionGraphs\022"
    ".\n\020partition_graphs\030\001 \003(\0132\024.tensorflow.G"
    "raphDef\0224\n\026pre_optimization_graph\030\002 \001(\0132"
    "\024.tensorflow.GraphDef\0225\n\027post_optimizati"
    "on_graph\030\003 \001(\0132\024.tensorflow.GraphDef\":\n\020"
    "TensorConnection\022\023\n\013from_tensor\030\001 \001(\t\022\021\n"
    "\tto_tensor\030\002 \001(\t\"\260\003\n\017CallableOptions\022\014\n\004"
    "feed\030\001 \003(\t\022\r\n\005fetch\030\002 \003(\t\022\016\n\006target\030\003 \003("
    "\t\022+\n\013run_options\030\004 \001(\0132\026.tensorflow.RunO"
    "ptions\0227\n\021tensor_connection\030\005 \003(\0132\034.tens"
    "orflow.TensorConnection\022B\n\014feed_devices\030"
    "\006 \003(\0132,.tensorflow.CallableOptions.FeedD"
    "evicesEntry\022D\n\rfetch_devices\030\007 \003(\0132-.ten"
    "sorflow.CallableOptions.FetchDevicesEntr"
    "y\022\027\n\017fetch_skip_sync\030\010 \001(\010\0322\n\020FeedDevice"
    "sEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\0323"
    "\n\021FetchDevicesEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005valu"
    "e\030\002 \001(\t:\0028\001B\204\001\n\030org.tensorflow.framework"
    "B\014ConfigProtosP\001ZUgithub.com/tensorflow/"
    "tensorflow/tensorflow/go/core/protobuf/f"
    "or_core_protos_go_proto\370\001\001b\006proto3"
};
static const ::_pbi::DescriptorTable* const descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto_deps[8] =
    {
        &::descriptor_table_tensorflow_2fcore_2fframework_2fcost_5fgraph_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fframework_2fgraph_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fframework_2fstep_5fstats_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fprotobuf_2fcluster_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fprotobuf_2fdebug_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fprotobuf_2frewriter_5fconfig_2eproto,
        &::descriptor_table_tensorflow_2fcore_2fprotobuf_2frpc_5foptions_2eproto,
        &::descriptor_table_tsl_2fprotobuf_2fcoordination_5fconfig_2eproto,
};
static ::absl::once_flag descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto_once;
PROTOBUF_CONSTINIT const ::_pbi::DescriptorTable descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto = {
    false,
    false,
    6434,
    descriptor_table_protodef_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    "tensorflow/core/protobuf/config.proto",
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto_once,
    descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto_deps,
    8,
    20,
    schemas,
    file_default_instances,
    TableStruct_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::offsets,
    file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    file_level_service_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
};
namespace tensorflow {
const ::google::protobuf::EnumDescriptor* OptimizerOptions_Level_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[0];
}
PROTOBUF_CONSTINIT const uint32_t OptimizerOptions_Level_internal_data_[] = {
    196607u, 0u, };
bool OptimizerOptions_Level_IsValid(int value) {
  return -1 <= value && value <= 0;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr OptimizerOptions_Level OptimizerOptions::L1;
constexpr OptimizerOptions_Level OptimizerOptions::L0;
constexpr OptimizerOptions_Level OptimizerOptions::Level_MIN;
constexpr OptimizerOptions_Level OptimizerOptions::Level_MAX;
constexpr int OptimizerOptions::Level_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* OptimizerOptions_GlobalJitLevel_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[1];
}
PROTOBUF_CONSTINIT const uint32_t OptimizerOptions_GlobalJitLevel_internal_data_[] = {
    327679u, 0u, };
bool OptimizerOptions_GlobalJitLevel_IsValid(int value) {
  return -1 <= value && value <= 2;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::DEFAULT;
constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::OFF;
constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::ON_1;
constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::ON_2;
constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::GlobalJitLevel_MIN;
constexpr OptimizerOptions_GlobalJitLevel OptimizerOptions::GlobalJitLevel_MAX;
constexpr int OptimizerOptions::GlobalJitLevel_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* ConfigProto_Experimental_MlirBridgeRollout_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[2];
}
PROTOBUF_CONSTINIT const uint32_t ConfigProto_Experimental_MlirBridgeRollout_internal_data_[] = {
    196608u, 0u, };
bool ConfigProto_Experimental_MlirBridgeRollout_IsValid(int value) {
  return 0 <= value && value <= 2;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr ConfigProto_Experimental_MlirBridgeRollout ConfigProto_Experimental::MLIR_BRIDGE_ROLLOUT_UNSPECIFIED;
constexpr ConfigProto_Experimental_MlirBridgeRollout ConfigProto_Experimental::MLIR_BRIDGE_ROLLOUT_ENABLED;
constexpr ConfigProto_Experimental_MlirBridgeRollout ConfigProto_Experimental::MLIR_BRIDGE_ROLLOUT_DISABLED;
constexpr ConfigProto_Experimental_MlirBridgeRollout ConfigProto_Experimental::MlirBridgeRollout_MIN;
constexpr ConfigProto_Experimental_MlirBridgeRollout ConfigProto_Experimental::MlirBridgeRollout_MAX;
constexpr int ConfigProto_Experimental::MlirBridgeRollout_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::google::protobuf::EnumDescriptor* RunOptions_TraceLevel_descriptor() {
  ::google::protobuf::internal::AssignDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto);
  return file_level_enum_descriptors_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto[3];
}
PROTOBUF_CONSTINIT const uint32_t RunOptions_TraceLevel_internal_data_[] = {
    262144u, 0u, };
bool RunOptions_TraceLevel_IsValid(int value) {
  return 0 <= value && value <= 3;
}
#if (__cplusplus < 201703) && \
  (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

constexpr RunOptions_TraceLevel RunOptions::NO_TRACE;
constexpr RunOptions_TraceLevel RunOptions::SOFTWARE_TRACE;
constexpr RunOptions_TraceLevel RunOptions::HARDWARE_TRACE;
constexpr RunOptions_TraceLevel RunOptions::FULL_TRACE;
constexpr RunOptions_TraceLevel RunOptions::TraceLevel_MIN;
constexpr RunOptions_TraceLevel RunOptions::TraceLevel_MAX;
constexpr int RunOptions::TraceLevel_ARRAYSIZE;

#endif  // (__cplusplus < 201703) &&
        // (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
// ===================================================================

class GPUOptions_Experimental_VirtualDevices::_Internal {
 public:
};

GPUOptions_Experimental_VirtualDevices::GPUOptions_Experimental_VirtualDevices(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GPUOptions.Experimental.VirtualDevices)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions_Experimental_VirtualDevices::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::GPUOptions_Experimental_VirtualDevices& from_msg)
      : memory_limit_mb_{visibility, arena, from.memory_limit_mb_},
        priority_{visibility, arena, from.priority_},
        _priority_cached_byte_size_{0},
        device_ordinal_{visibility, arena, from.device_ordinal_},
        _device_ordinal_cached_byte_size_{0},
        _cached_size_{0} {}

GPUOptions_Experimental_VirtualDevices::GPUOptions_Experimental_VirtualDevices(
    ::google::protobuf::Arena* arena,
    const GPUOptions_Experimental_VirtualDevices& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  GPUOptions_Experimental_VirtualDevices* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);

  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions.Experimental.VirtualDevices)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions_Experimental_VirtualDevices::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : memory_limit_mb_{visibility, arena},
        priority_{visibility, arena},
        _priority_cached_byte_size_{0},
        device_ordinal_{visibility, arena},
        _device_ordinal_cached_byte_size_{0},
        _cached_size_{0} {}

inline void GPUOptions_Experimental_VirtualDevices::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
GPUOptions_Experimental_VirtualDevices::~GPUOptions_Experimental_VirtualDevices() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions.Experimental.VirtualDevices)
  SharedDtor(*this);
}
inline void GPUOptions_Experimental_VirtualDevices::SharedDtor(MessageLite& self) {
  GPUOptions_Experimental_VirtualDevices& this_ = static_cast<GPUOptions_Experimental_VirtualDevices&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* GPUOptions_Experimental_VirtualDevices::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) GPUOptions_Experimental_VirtualDevices(arena);
}
constexpr auto GPUOptions_Experimental_VirtualDevices::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.memory_limit_mb_) +
          decltype(GPUOptions_Experimental_VirtualDevices::_impl_.memory_limit_mb_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.priority_) +
          decltype(GPUOptions_Experimental_VirtualDevices::_impl_.priority_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.device_ordinal_) +
          decltype(GPUOptions_Experimental_VirtualDevices::_impl_.device_ordinal_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(GPUOptions_Experimental_VirtualDevices), alignof(GPUOptions_Experimental_VirtualDevices), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&GPUOptions_Experimental_VirtualDevices::PlacementNew_,
                                 sizeof(GPUOptions_Experimental_VirtualDevices),
                                 alignof(GPUOptions_Experimental_VirtualDevices));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull GPUOptions_Experimental_VirtualDevices::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_GPUOptions_Experimental_VirtualDevices_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &GPUOptions_Experimental_VirtualDevices::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<GPUOptions_Experimental_VirtualDevices>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &GPUOptions_Experimental_VirtualDevices::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<GPUOptions_Experimental_VirtualDevices>(), &GPUOptions_Experimental_VirtualDevices::ByteSizeLong,
            &GPUOptions_Experimental_VirtualDevices::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_._cached_size_),
        false,
    },
    &GPUOptions_Experimental_VirtualDevices::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* GPUOptions_Experimental_VirtualDevices::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 0, 0, 2> GPUOptions_Experimental_VirtualDevices::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental_VirtualDevices>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated float memory_limit_mb = 1;
    {::_pbi::TcParser::FastF32P1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.memory_limit_mb_)}},
    // repeated int32 priority = 2;
    {::_pbi::TcParser::FastV32P1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.priority_)}},
    // repeated int32 device_ordinal = 3;
    {::_pbi::TcParser::FastV32P1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.device_ordinal_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated float memory_limit_mb = 1;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.memory_limit_mb_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedFloat)},
    // repeated int32 priority = 2;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.priority_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedInt32)},
    // repeated int32 device_ordinal = 3;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_VirtualDevices, _impl_.device_ordinal_), 0, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kPackedInt32)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void GPUOptions_Experimental_VirtualDevices::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GPUOptions.Experimental.VirtualDevices)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.memory_limit_mb_.Clear();
  _impl_.priority_.Clear();
  _impl_.device_ordinal_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* GPUOptions_Experimental_VirtualDevices::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const GPUOptions_Experimental_VirtualDevices& this_ = static_cast<const GPUOptions_Experimental_VirtualDevices&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* GPUOptions_Experimental_VirtualDevices::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const GPUOptions_Experimental_VirtualDevices& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions.Experimental.VirtualDevices)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated float memory_limit_mb = 1;
          if (this_._internal_memory_limit_mb_size() > 0) {
            target = stream->WriteFixedPacked(1, this_._internal_memory_limit_mb(), target);
          }

          // repeated int32 priority = 2;
          {
            int byte_size = this_._impl_._priority_cached_byte_size_.Get();
            if (byte_size > 0) {
              target = stream->WriteInt32Packed(
                  2, this_._internal_priority(), byte_size, target);
            }
          }

          // repeated int32 device_ordinal = 3;
          {
            int byte_size = this_._impl_._device_ordinal_cached_byte_size_.Get();
            if (byte_size > 0) {
              target = stream->WriteInt32Packed(
                  3, this_._internal_device_ordinal(), byte_size, target);
            }
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions.Experimental.VirtualDevices)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t GPUOptions_Experimental_VirtualDevices::ByteSizeLong(const MessageLite& base) {
          const GPUOptions_Experimental_VirtualDevices& this_ = static_cast<const GPUOptions_Experimental_VirtualDevices&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t GPUOptions_Experimental_VirtualDevices::ByteSizeLong() const {
          const GPUOptions_Experimental_VirtualDevices& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.GPUOptions.Experimental.VirtualDevices)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated float memory_limit_mb = 1;
            {
              std::size_t data_size = std::size_t{4} *
                  ::_pbi::FromIntSize(this_._internal_memory_limit_mb_size());
              std::size_t tag_size = data_size == 0
                  ? 0
                  : 1 + ::_pbi::WireFormatLite::Int32Size(
                                      static_cast<int32_t>(data_size));
              total_size += tag_size + data_size;
            }
            // repeated int32 priority = 2;
            {
              total_size +=
                  ::_pbi::WireFormatLite::Int32SizeWithPackedTagSize(
                      this_._internal_priority(), 1,
                      this_._impl_._priority_cached_byte_size_);
            }
            // repeated int32 device_ordinal = 3;
            {
              total_size +=
                  ::_pbi::WireFormatLite::Int32SizeWithPackedTagSize(
                      this_._internal_device_ordinal(), 1,
                      this_._impl_._device_ordinal_cached_byte_size_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void GPUOptions_Experimental_VirtualDevices::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<GPUOptions_Experimental_VirtualDevices*>(&to_msg);
  auto& from = static_cast<const GPUOptions_Experimental_VirtualDevices&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GPUOptions.Experimental.VirtualDevices)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_memory_limit_mb()->MergeFrom(from._internal_memory_limit_mb());
  _this->_internal_mutable_priority()->MergeFrom(from._internal_priority());
  _this->_internal_mutable_device_ordinal()->MergeFrom(from._internal_device_ordinal());
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void GPUOptions_Experimental_VirtualDevices::CopyFrom(const GPUOptions_Experimental_VirtualDevices& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GPUOptions.Experimental.VirtualDevices)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void GPUOptions_Experimental_VirtualDevices::InternalSwap(GPUOptions_Experimental_VirtualDevices* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.memory_limit_mb_.InternalSwap(&other->_impl_.memory_limit_mb_);
  _impl_.priority_.InternalSwap(&other->_impl_.priority_);
  _impl_.device_ordinal_.InternalSwap(&other->_impl_.device_ordinal_);
}

::google::protobuf::Metadata GPUOptions_Experimental_VirtualDevices::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class GPUOptions_Experimental_StreamMergeOptions::_Internal {
 public:
};

GPUOptions_Experimental_StreamMergeOptions::GPUOptions_Experimental_StreamMergeOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
}
GPUOptions_Experimental_StreamMergeOptions::GPUOptions_Experimental_StreamMergeOptions(
    ::google::protobuf::Arena* arena, const GPUOptions_Experimental_StreamMergeOptions& from)
    : GPUOptions_Experimental_StreamMergeOptions(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions_Experimental_StreamMergeOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void GPUOptions_Experimental_StreamMergeOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, merge_host_to_device_stream_),
           0,
           offsetof(Impl_, merge_device_to_device_stream_) -
               offsetof(Impl_, merge_host_to_device_stream_) +
               sizeof(Impl_::merge_device_to_device_stream_));
}
GPUOptions_Experimental_StreamMergeOptions::~GPUOptions_Experimental_StreamMergeOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
  SharedDtor(*this);
}
inline void GPUOptions_Experimental_StreamMergeOptions::SharedDtor(MessageLite& self) {
  GPUOptions_Experimental_StreamMergeOptions& this_ = static_cast<GPUOptions_Experimental_StreamMergeOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* GPUOptions_Experimental_StreamMergeOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) GPUOptions_Experimental_StreamMergeOptions(arena);
}
constexpr auto GPUOptions_Experimental_StreamMergeOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(GPUOptions_Experimental_StreamMergeOptions),
                                            alignof(GPUOptions_Experimental_StreamMergeOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull GPUOptions_Experimental_StreamMergeOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_GPUOptions_Experimental_StreamMergeOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &GPUOptions_Experimental_StreamMergeOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<GPUOptions_Experimental_StreamMergeOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &GPUOptions_Experimental_StreamMergeOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<GPUOptions_Experimental_StreamMergeOptions>(), &GPUOptions_Experimental_StreamMergeOptions::ByteSizeLong,
            &GPUOptions_Experimental_StreamMergeOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_._cached_size_),
        false,
    },
    &GPUOptions_Experimental_StreamMergeOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* GPUOptions_Experimental_StreamMergeOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 0, 0, 2> GPUOptions_Experimental_StreamMergeOptions::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental_StreamMergeOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // bool merge_host_to_device_stream = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_host_to_device_stream_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_host_to_device_stream_)}},
    // bool merge_device_to_host_stream = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_host_stream_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_host_stream_)}},
    // bool merge_device_to_device_stream = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_device_stream_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_device_stream_)}},
  }}, {{
    65535, 65535
  }}, {{
    // bool merge_host_to_device_stream = 1;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_host_to_device_stream_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool merge_device_to_host_stream = 2;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_host_stream_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool merge_device_to_device_stream = 3;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_device_stream_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void GPUOptions_Experimental_StreamMergeOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.merge_host_to_device_stream_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.merge_device_to_device_stream_) -
      reinterpret_cast<char*>(&_impl_.merge_host_to_device_stream_)) + sizeof(_impl_.merge_device_to_device_stream_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* GPUOptions_Experimental_StreamMergeOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const GPUOptions_Experimental_StreamMergeOptions& this_ = static_cast<const GPUOptions_Experimental_StreamMergeOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* GPUOptions_Experimental_StreamMergeOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const GPUOptions_Experimental_StreamMergeOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // bool merge_host_to_device_stream = 1;
          if (this_._internal_merge_host_to_device_stream() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                1, this_._internal_merge_host_to_device_stream(), target);
          }

          // bool merge_device_to_host_stream = 2;
          if (this_._internal_merge_device_to_host_stream() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_merge_device_to_host_stream(), target);
          }

          // bool merge_device_to_device_stream = 3;
          if (this_._internal_merge_device_to_device_stream() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                3, this_._internal_merge_device_to_device_stream(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t GPUOptions_Experimental_StreamMergeOptions::ByteSizeLong(const MessageLite& base) {
          const GPUOptions_Experimental_StreamMergeOptions& this_ = static_cast<const GPUOptions_Experimental_StreamMergeOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t GPUOptions_Experimental_StreamMergeOptions::ByteSizeLong() const {
          const GPUOptions_Experimental_StreamMergeOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // bool merge_host_to_device_stream = 1;
            if (this_._internal_merge_host_to_device_stream() != 0) {
              total_size += 2;
            }
            // bool merge_device_to_host_stream = 2;
            if (this_._internal_merge_device_to_host_stream() != 0) {
              total_size += 2;
            }
            // bool merge_device_to_device_stream = 3;
            if (this_._internal_merge_device_to_device_stream() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void GPUOptions_Experimental_StreamMergeOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<GPUOptions_Experimental_StreamMergeOptions*>(&to_msg);
  auto& from = static_cast<const GPUOptions_Experimental_StreamMergeOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_merge_host_to_device_stream() != 0) {
    _this->_impl_.merge_host_to_device_stream_ = from._impl_.merge_host_to_device_stream_;
  }
  if (from._internal_merge_device_to_host_stream() != 0) {
    _this->_impl_.merge_device_to_host_stream_ = from._impl_.merge_device_to_host_stream_;
  }
  if (from._internal_merge_device_to_device_stream() != 0) {
    _this->_impl_.merge_device_to_device_stream_ = from._impl_.merge_device_to_device_stream_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void GPUOptions_Experimental_StreamMergeOptions::CopyFrom(const GPUOptions_Experimental_StreamMergeOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GPUOptions.Experimental.StreamMergeOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void GPUOptions_Experimental_StreamMergeOptions::InternalSwap(GPUOptions_Experimental_StreamMergeOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_device_to_device_stream_)
      + sizeof(GPUOptions_Experimental_StreamMergeOptions::_impl_.merge_device_to_device_stream_)
      - PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental_StreamMergeOptions, _impl_.merge_host_to_device_stream_)>(
          reinterpret_cast<char*>(&_impl_.merge_host_to_device_stream_),
          reinterpret_cast<char*>(&other->_impl_.merge_host_to_device_stream_));
}

::google::protobuf::Metadata GPUOptions_Experimental_StreamMergeOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class GPUOptions_Experimental::_Internal {
 public:
  using HasBits =
      decltype(std::declval<GPUOptions_Experimental>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_._has_bits_);
};

GPUOptions_Experimental::GPUOptions_Experimental(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GPUOptions.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::GPUOptions_Experimental& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        virtual_devices_{visibility, arena, from.virtual_devices_},
        collective_ring_order_(arena, from.collective_ring_order_) {}

GPUOptions_Experimental::GPUOptions_Experimental(
    ::google::protobuf::Arena* arena,
    const GPUOptions_Experimental& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  GPUOptions_Experimental* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.stream_merge_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions_Experimental_StreamMergeOptions>(
                              arena, *from._impl_.stream_merge_options_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, num_dev_to_dev_copy_streams_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, num_dev_to_dev_copy_streams_),
           offsetof(Impl_, node_id_) -
               offsetof(Impl_, num_dev_to_dev_copy_streams_) +
               sizeof(Impl_::node_id_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        virtual_devices_{visibility, arena},
        collective_ring_order_(arena) {}

inline void GPUOptions_Experimental::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, stream_merge_options_),
           0,
           offsetof(Impl_, node_id_) -
               offsetof(Impl_, stream_merge_options_) +
               sizeof(Impl_::node_id_));
}
GPUOptions_Experimental::~GPUOptions_Experimental() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions.Experimental)
  SharedDtor(*this);
}
inline void GPUOptions_Experimental::SharedDtor(MessageLite& self) {
  GPUOptions_Experimental& this_ = static_cast<GPUOptions_Experimental&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.collective_ring_order_.Destroy();
  delete this_._impl_.stream_merge_options_;
  this_._impl_.~Impl_();
}

inline void* GPUOptions_Experimental::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) GPUOptions_Experimental(arena);
}
constexpr auto GPUOptions_Experimental::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.virtual_devices_) +
          decltype(GPUOptions_Experimental::_impl_.virtual_devices_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(GPUOptions_Experimental), alignof(GPUOptions_Experimental), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&GPUOptions_Experimental::PlacementNew_,
                                 sizeof(GPUOptions_Experimental),
                                 alignof(GPUOptions_Experimental));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull GPUOptions_Experimental::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_GPUOptions_Experimental_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &GPUOptions_Experimental::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<GPUOptions_Experimental>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &GPUOptions_Experimental::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<GPUOptions_Experimental>(), &GPUOptions_Experimental::ByteSizeLong,
            &GPUOptions_Experimental::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_._cached_size_),
        false,
    },
    &GPUOptions_Experimental::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* GPUOptions_Experimental::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 18, 2, 80, 2> GPUOptions_Experimental::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_._has_bits_),
    0, // no _extensions_
    19, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294443040,  // skipmap
    offsetof(decltype(_table_), field_entries),
    18,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.virtual_devices_)}},
    // bool use_unified_memory = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental, _impl_.use_unified_memory_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.use_unified_memory_)}},
    // int32 num_dev_to_dev_copy_streams = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions_Experimental, _impl_.num_dev_to_dev_copy_streams_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.num_dev_to_dev_copy_streams_)}},
    // string collective_ring_order = 4;
    {::_pbi::TcParser::FastUS1,
     {34, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.collective_ring_order_)}},
    // bool timestamped_allocator = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental, _impl_.timestamped_allocator_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.timestamped_allocator_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // int32 kernel_tracker_max_interval = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions_Experimental, _impl_.kernel_tracker_max_interval_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_interval_)}},
    // int32 kernel_tracker_max_bytes = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions_Experimental, _impl_.kernel_tracker_max_bytes_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_bytes_)}},
    // int32 kernel_tracker_max_pending = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions_Experimental, _impl_.kernel_tracker_max_pending_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_pending_)}},
    // double internal_fragmentation_fraction = 10;
    {::_pbi::TcParser::FastF64S1,
     {81, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.internal_fragmentation_fraction_)}},
    // bool use_cuda_malloc_async = 11;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental, _impl_.use_cuda_malloc_async_), 63>(),
     {88, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.use_cuda_malloc_async_)}},
    // bool disallow_retry_on_allocation_failure = 12;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental, _impl_.disallow_retry_on_allocation_failure_), 63>(),
     {96, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.disallow_retry_on_allocation_failure_)}},
    // float gpu_host_mem_limit_in_mb = 13;
    {::_pbi::TcParser::FastF32S1,
     {109, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_host_mem_limit_in_mb_)}},
    // bool gpu_host_mem_disallow_growth = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions_Experimental, _impl_.gpu_host_mem_disallow_growth_), 63>(),
     {112, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_host_mem_disallow_growth_)}},
    // int32 num_virtual_devices_per_gpu = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions_Experimental, _impl_.num_virtual_devices_per_gpu_), 63>(),
     {120, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.num_virtual_devices_per_gpu_)}},
    // int32 gpu_system_memory_size_in_mb = 16;
    {::_pbi::TcParser::FastV32S2,
     {384, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_system_memory_size_in_mb_)}},
    // bool populate_pjrt_gpu_client_creation_info = 17;
    {::_pbi::TcParser::FastV8S2,
     {392, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.populate_pjrt_gpu_client_creation_info_)}},
    // int32 node_id = 18;
    {::_pbi::TcParser::FastV32S2,
     {400, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.node_id_)}},
    // .tensorflow.GPUOptions.Experimental.StreamMergeOptions stream_merge_options = 19;
    {::_pbi::TcParser::FastMtS2,
     {410, 0, 1, PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.stream_merge_options_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.virtual_devices_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool use_unified_memory = 2;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.use_unified_memory_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 num_dev_to_dev_copy_streams = 3;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.num_dev_to_dev_copy_streams_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string collective_ring_order = 4;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.collective_ring_order_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // bool timestamped_allocator = 5;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.timestamped_allocator_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 kernel_tracker_max_interval = 7;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_interval_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 kernel_tracker_max_bytes = 8;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_bytes_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 kernel_tracker_max_pending = 9;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.kernel_tracker_max_pending_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // double internal_fragmentation_fraction = 10;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.internal_fragmentation_fraction_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // bool use_cuda_malloc_async = 11;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.use_cuda_malloc_async_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool disallow_retry_on_allocation_failure = 12;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.disallow_retry_on_allocation_failure_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // float gpu_host_mem_limit_in_mb = 13;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_host_mem_limit_in_mb_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kFloat)},
    // bool gpu_host_mem_disallow_growth = 14;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_host_mem_disallow_growth_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 num_virtual_devices_per_gpu = 15;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.num_virtual_devices_per_gpu_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 gpu_system_memory_size_in_mb = 16;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.gpu_system_memory_size_in_mb_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool populate_pjrt_gpu_client_creation_info = 17;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.populate_pjrt_gpu_client_creation_info_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 node_id = 18;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.node_id_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // .tensorflow.GPUOptions.Experimental.StreamMergeOptions stream_merge_options = 19;
    {PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.stream_merge_options_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental_VirtualDevices>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental_StreamMergeOptions>()},
  }}, {{
    "\42\0\0\0\25\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"
    "tensorflow.GPUOptions.Experimental"
    "collective_ring_order"
  }},
};

PROTOBUF_NOINLINE void GPUOptions_Experimental::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GPUOptions.Experimental)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.virtual_devices_.Clear();
  _impl_.collective_ring_order_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.stream_merge_options_ != nullptr);
    _impl_.stream_merge_options_->Clear();
  }
  ::memset(&_impl_.num_dev_to_dev_copy_streams_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.node_id_) -
      reinterpret_cast<char*>(&_impl_.num_dev_to_dev_copy_streams_)) + sizeof(_impl_.node_id_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* GPUOptions_Experimental::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const GPUOptions_Experimental& this_ = static_cast<const GPUOptions_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* GPUOptions_Experimental::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const GPUOptions_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions.Experimental)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_virtual_devices_size());
               i < n; i++) {
            const auto& repfield = this_._internal_virtual_devices().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    1, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // bool use_unified_memory = 2;
          if (this_._internal_use_unified_memory() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_use_unified_memory(), target);
          }

          // int32 num_dev_to_dev_copy_streams = 3;
          if (this_._internal_num_dev_to_dev_copy_streams() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<3>(
                    stream, this_._internal_num_dev_to_dev_copy_streams(), target);
          }

          // string collective_ring_order = 4;
          if (!this_._internal_collective_ring_order().empty()) {
            const std::string& _s = this_._internal_collective_ring_order();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.GPUOptions.Experimental.collective_ring_order");
            target = stream->WriteStringMaybeAliased(4, _s, target);
          }

          // bool timestamped_allocator = 5;
          if (this_._internal_timestamped_allocator() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_timestamped_allocator(), target);
          }

          // int32 kernel_tracker_max_interval = 7;
          if (this_._internal_kernel_tracker_max_interval() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<7>(
                    stream, this_._internal_kernel_tracker_max_interval(), target);
          }

          // int32 kernel_tracker_max_bytes = 8;
          if (this_._internal_kernel_tracker_max_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<8>(
                    stream, this_._internal_kernel_tracker_max_bytes(), target);
          }

          // int32 kernel_tracker_max_pending = 9;
          if (this_._internal_kernel_tracker_max_pending() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<9>(
                    stream, this_._internal_kernel_tracker_max_pending(), target);
          }

          // double internal_fragmentation_fraction = 10;
          if (::absl::bit_cast<::uint64_t>(this_._internal_internal_fragmentation_fraction()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteDoubleToArray(
                10, this_._internal_internal_fragmentation_fraction(), target);
          }

          // bool use_cuda_malloc_async = 11;
          if (this_._internal_use_cuda_malloc_async() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                11, this_._internal_use_cuda_malloc_async(), target);
          }

          // bool disallow_retry_on_allocation_failure = 12;
          if (this_._internal_disallow_retry_on_allocation_failure() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                12, this_._internal_disallow_retry_on_allocation_failure(), target);
          }

          // float gpu_host_mem_limit_in_mb = 13;
          if (::absl::bit_cast<::uint32_t>(this_._internal_gpu_host_mem_limit_in_mb()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteFloatToArray(
                13, this_._internal_gpu_host_mem_limit_in_mb(), target);
          }

          // bool gpu_host_mem_disallow_growth = 14;
          if (this_._internal_gpu_host_mem_disallow_growth() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                14, this_._internal_gpu_host_mem_disallow_growth(), target);
          }

          // int32 num_virtual_devices_per_gpu = 15;
          if (this_._internal_num_virtual_devices_per_gpu() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<15>(
                    stream, this_._internal_num_virtual_devices_per_gpu(), target);
          }

          // int32 gpu_system_memory_size_in_mb = 16;
          if (this_._internal_gpu_system_memory_size_in_mb() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt32ToArray(
                16, this_._internal_gpu_system_memory_size_in_mb(), target);
          }

          // bool populate_pjrt_gpu_client_creation_info = 17;
          if (this_._internal_populate_pjrt_gpu_client_creation_info() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                17, this_._internal_populate_pjrt_gpu_client_creation_info(), target);
          }

          // int32 node_id = 18;
          if (this_._internal_node_id() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt32ToArray(
                18, this_._internal_node_id(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.GPUOptions.Experimental.StreamMergeOptions stream_merge_options = 19;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                19, *this_._impl_.stream_merge_options_, this_._impl_.stream_merge_options_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions.Experimental)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t GPUOptions_Experimental::ByteSizeLong(const MessageLite& base) {
          const GPUOptions_Experimental& this_ = static_cast<const GPUOptions_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t GPUOptions_Experimental::ByteSizeLong() const {
          const GPUOptions_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.GPUOptions.Experimental)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.GPUOptions.Experimental.VirtualDevices virtual_devices = 1;
            {
              total_size += 1UL * this_._internal_virtual_devices_size();
              for (const auto& msg : this_._internal_virtual_devices()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
           {
            // string collective_ring_order = 4;
            if (!this_._internal_collective_ring_order().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_collective_ring_order());
            }
          }
           {
            // .tensorflow.GPUOptions.Experimental.StreamMergeOptions stream_merge_options = 19;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.stream_merge_options_);
            }
          }
           {
            // int32 num_dev_to_dev_copy_streams = 3;
            if (this_._internal_num_dev_to_dev_copy_streams() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_num_dev_to_dev_copy_streams());
            }
            // int32 kernel_tracker_max_interval = 7;
            if (this_._internal_kernel_tracker_max_interval() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_kernel_tracker_max_interval());
            }
            // bool use_unified_memory = 2;
            if (this_._internal_use_unified_memory() != 0) {
              total_size += 2;
            }
            // bool timestamped_allocator = 5;
            if (this_._internal_timestamped_allocator() != 0) {
              total_size += 2;
            }
            // bool use_cuda_malloc_async = 11;
            if (this_._internal_use_cuda_malloc_async() != 0) {
              total_size += 2;
            }
            // bool disallow_retry_on_allocation_failure = 12;
            if (this_._internal_disallow_retry_on_allocation_failure() != 0) {
              total_size += 2;
            }
            // int32 kernel_tracker_max_bytes = 8;
            if (this_._internal_kernel_tracker_max_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_kernel_tracker_max_bytes());
            }
            // double internal_fragmentation_fraction = 10;
            if (::absl::bit_cast<::uint64_t>(this_._internal_internal_fragmentation_fraction()) != 0) {
              total_size += 9;
            }
            // int32 kernel_tracker_max_pending = 9;
            if (this_._internal_kernel_tracker_max_pending() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_kernel_tracker_max_pending());
            }
            // float gpu_host_mem_limit_in_mb = 13;
            if (::absl::bit_cast<::uint32_t>(this_._internal_gpu_host_mem_limit_in_mb()) != 0) {
              total_size += 5;
            }
            // int32 num_virtual_devices_per_gpu = 15;
            if (this_._internal_num_virtual_devices_per_gpu() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_num_virtual_devices_per_gpu());
            }
            // bool gpu_host_mem_disallow_growth = 14;
            if (this_._internal_gpu_host_mem_disallow_growth() != 0) {
              total_size += 2;
            }
            // bool populate_pjrt_gpu_client_creation_info = 17;
            if (this_._internal_populate_pjrt_gpu_client_creation_info() != 0) {
              total_size += 3;
            }
            // int32 gpu_system_memory_size_in_mb = 16;
            if (this_._internal_gpu_system_memory_size_in_mb() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int32Size(
                                              this_._internal_gpu_system_memory_size_in_mb());
            }
            // int32 node_id = 18;
            if (this_._internal_node_id() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int32Size(
                                              this_._internal_node_id());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void GPUOptions_Experimental::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<GPUOptions_Experimental*>(&to_msg);
  auto& from = static_cast<const GPUOptions_Experimental&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GPUOptions.Experimental)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_virtual_devices()->MergeFrom(
      from._internal_virtual_devices());
  if (!from._internal_collective_ring_order().empty()) {
    _this->_internal_set_collective_ring_order(from._internal_collective_ring_order());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.stream_merge_options_ != nullptr);
    if (_this->_impl_.stream_merge_options_ == nullptr) {
      _this->_impl_.stream_merge_options_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions_Experimental_StreamMergeOptions>(arena, *from._impl_.stream_merge_options_);
    } else {
      _this->_impl_.stream_merge_options_->MergeFrom(*from._impl_.stream_merge_options_);
    }
  }
  if (from._internal_num_dev_to_dev_copy_streams() != 0) {
    _this->_impl_.num_dev_to_dev_copy_streams_ = from._impl_.num_dev_to_dev_copy_streams_;
  }
  if (from._internal_kernel_tracker_max_interval() != 0) {
    _this->_impl_.kernel_tracker_max_interval_ = from._impl_.kernel_tracker_max_interval_;
  }
  if (from._internal_use_unified_memory() != 0) {
    _this->_impl_.use_unified_memory_ = from._impl_.use_unified_memory_;
  }
  if (from._internal_timestamped_allocator() != 0) {
    _this->_impl_.timestamped_allocator_ = from._impl_.timestamped_allocator_;
  }
  if (from._internal_use_cuda_malloc_async() != 0) {
    _this->_impl_.use_cuda_malloc_async_ = from._impl_.use_cuda_malloc_async_;
  }
  if (from._internal_disallow_retry_on_allocation_failure() != 0) {
    _this->_impl_.disallow_retry_on_allocation_failure_ = from._impl_.disallow_retry_on_allocation_failure_;
  }
  if (from._internal_kernel_tracker_max_bytes() != 0) {
    _this->_impl_.kernel_tracker_max_bytes_ = from._impl_.kernel_tracker_max_bytes_;
  }
  if (::absl::bit_cast<::uint64_t>(from._internal_internal_fragmentation_fraction()) != 0) {
    _this->_impl_.internal_fragmentation_fraction_ = from._impl_.internal_fragmentation_fraction_;
  }
  if (from._internal_kernel_tracker_max_pending() != 0) {
    _this->_impl_.kernel_tracker_max_pending_ = from._impl_.kernel_tracker_max_pending_;
  }
  if (::absl::bit_cast<::uint32_t>(from._internal_gpu_host_mem_limit_in_mb()) != 0) {
    _this->_impl_.gpu_host_mem_limit_in_mb_ = from._impl_.gpu_host_mem_limit_in_mb_;
  }
  if (from._internal_num_virtual_devices_per_gpu() != 0) {
    _this->_impl_.num_virtual_devices_per_gpu_ = from._impl_.num_virtual_devices_per_gpu_;
  }
  if (from._internal_gpu_host_mem_disallow_growth() != 0) {
    _this->_impl_.gpu_host_mem_disallow_growth_ = from._impl_.gpu_host_mem_disallow_growth_;
  }
  if (from._internal_populate_pjrt_gpu_client_creation_info() != 0) {
    _this->_impl_.populate_pjrt_gpu_client_creation_info_ = from._impl_.populate_pjrt_gpu_client_creation_info_;
  }
  if (from._internal_gpu_system_memory_size_in_mb() != 0) {
    _this->_impl_.gpu_system_memory_size_in_mb_ = from._impl_.gpu_system_memory_size_in_mb_;
  }
  if (from._internal_node_id() != 0) {
    _this->_impl_.node_id_ = from._impl_.node_id_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void GPUOptions_Experimental::CopyFrom(const GPUOptions_Experimental& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GPUOptions.Experimental)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void GPUOptions_Experimental::InternalSwap(GPUOptions_Experimental* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.virtual_devices_.InternalSwap(&other->_impl_.virtual_devices_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.collective_ring_order_, &other->_impl_.collective_ring_order_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.node_id_)
      + sizeof(GPUOptions_Experimental::_impl_.node_id_)
      - PROTOBUF_FIELD_OFFSET(GPUOptions_Experimental, _impl_.stream_merge_options_)>(
          reinterpret_cast<char*>(&_impl_.stream_merge_options_),
          reinterpret_cast<char*>(&other->_impl_.stream_merge_options_));
}

::google::protobuf::Metadata GPUOptions_Experimental::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class GPUOptions::_Internal {
 public:
  using HasBits =
      decltype(std::declval<GPUOptions>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_._has_bits_);
};

GPUOptions::GPUOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GPUOptions)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::GPUOptions& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        allocator_type_(arena, from.allocator_type_),
        visible_device_list_(arena, from.visible_device_list_) {}

GPUOptions::GPUOptions(
    ::google::protobuf::Arena* arena,
    const GPUOptions& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  GPUOptions* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.experimental_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions_Experimental>(
                              arena, *from._impl_.experimental_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, per_process_gpu_memory_fraction_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, per_process_gpu_memory_fraction_),
           offsetof(Impl_, polling_inactive_delay_msecs_) -
               offsetof(Impl_, per_process_gpu_memory_fraction_) +
               sizeof(Impl_::polling_inactive_delay_msecs_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.GPUOptions)
}
inline PROTOBUF_NDEBUG_INLINE GPUOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        allocator_type_(arena),
        visible_device_list_(arena) {}

inline void GPUOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, experimental_),
           0,
           offsetof(Impl_, polling_inactive_delay_msecs_) -
               offsetof(Impl_, experimental_) +
               sizeof(Impl_::polling_inactive_delay_msecs_));
}
GPUOptions::~GPUOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GPUOptions)
  SharedDtor(*this);
}
inline void GPUOptions::SharedDtor(MessageLite& self) {
  GPUOptions& this_ = static_cast<GPUOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.allocator_type_.Destroy();
  this_._impl_.visible_device_list_.Destroy();
  delete this_._impl_.experimental_;
  this_._impl_.~Impl_();
}

inline void* GPUOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) GPUOptions(arena);
}
constexpr auto GPUOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(GPUOptions),
                                            alignof(GPUOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull GPUOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_GPUOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &GPUOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<GPUOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &GPUOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<GPUOptions>(), &GPUOptions::ByteSizeLong,
            &GPUOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_._cached_size_),
        false,
    },
    &GPUOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* GPUOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<4, 9, 1, 71, 2> GPUOptions::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_._has_bits_),
    0, // no _extensions_
    9, 120,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966784,  // skipmap
    offsetof(decltype(_table_), field_entries),
    9,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::GPUOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // double per_process_gpu_memory_fraction = 1;
    {::_pbi::TcParser::FastF64S1,
     {9, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.per_process_gpu_memory_fraction_)}},
    // string allocator_type = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.allocator_type_)}},
    // int64 deferred_deletion_bytes = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(GPUOptions, _impl_.deferred_deletion_bytes_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.deferred_deletion_bytes_)}},
    // bool allow_growth = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions, _impl_.allow_growth_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.allow_growth_)}},
    // string visible_device_list = 5;
    {::_pbi::TcParser::FastUS1,
     {42, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.visible_device_list_)}},
    // int32 polling_active_delay_usecs = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions, _impl_.polling_active_delay_usecs_), 63>(),
     {48, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.polling_active_delay_usecs_)}},
    // int32 polling_inactive_delay_msecs = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GPUOptions, _impl_.polling_inactive_delay_msecs_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.polling_inactive_delay_msecs_)}},
    // bool force_gpu_compatible = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GPUOptions, _impl_.force_gpu_compatible_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.force_gpu_compatible_)}},
    // .tensorflow.GPUOptions.Experimental experimental = 9;
    {::_pbi::TcParser::FastMtS1,
     {74, 0, 0, PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.experimental_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // double per_process_gpu_memory_fraction = 1;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.per_process_gpu_memory_fraction_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kDouble)},
    // string allocator_type = 2;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.allocator_type_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int64 deferred_deletion_bytes = 3;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.deferred_deletion_bytes_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // bool allow_growth = 4;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.allow_growth_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // string visible_device_list = 5;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.visible_device_list_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 polling_active_delay_usecs = 6;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.polling_active_delay_usecs_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 polling_inactive_delay_msecs = 7;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.polling_inactive_delay_msecs_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool force_gpu_compatible = 8;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.force_gpu_compatible_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.GPUOptions.Experimental experimental = 9;
    {PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.experimental_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::GPUOptions_Experimental>()},
  }}, {{
    "\25\0\16\0\0\23\0\0\0\0\0\0\0\0\0\0"
    "tensorflow.GPUOptions"
    "allocator_type"
    "visible_device_list"
  }},
};

PROTOBUF_NOINLINE void GPUOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GPUOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.allocator_type_.ClearToEmpty();
  _impl_.visible_device_list_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.experimental_ != nullptr);
    _impl_.experimental_->Clear();
  }
  ::memset(&_impl_.per_process_gpu_memory_fraction_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.polling_inactive_delay_msecs_) -
      reinterpret_cast<char*>(&_impl_.per_process_gpu_memory_fraction_)) + sizeof(_impl_.polling_inactive_delay_msecs_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* GPUOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const GPUOptions& this_ = static_cast<const GPUOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* GPUOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const GPUOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GPUOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // double per_process_gpu_memory_fraction = 1;
          if (::absl::bit_cast<::uint64_t>(this_._internal_per_process_gpu_memory_fraction()) != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteDoubleToArray(
                1, this_._internal_per_process_gpu_memory_fraction(), target);
          }

          // string allocator_type = 2;
          if (!this_._internal_allocator_type().empty()) {
            const std::string& _s = this_._internal_allocator_type();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.GPUOptions.allocator_type");
            target = stream->WriteStringMaybeAliased(2, _s, target);
          }

          // int64 deferred_deletion_bytes = 3;
          if (this_._internal_deferred_deletion_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<3>(
                    stream, this_._internal_deferred_deletion_bytes(), target);
          }

          // bool allow_growth = 4;
          if (this_._internal_allow_growth() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                4, this_._internal_allow_growth(), target);
          }

          // string visible_device_list = 5;
          if (!this_._internal_visible_device_list().empty()) {
            const std::string& _s = this_._internal_visible_device_list();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.GPUOptions.visible_device_list");
            target = stream->WriteStringMaybeAliased(5, _s, target);
          }

          // int32 polling_active_delay_usecs = 6;
          if (this_._internal_polling_active_delay_usecs() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<6>(
                    stream, this_._internal_polling_active_delay_usecs(), target);
          }

          // int32 polling_inactive_delay_msecs = 7;
          if (this_._internal_polling_inactive_delay_msecs() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<7>(
                    stream, this_._internal_polling_inactive_delay_msecs(), target);
          }

          // bool force_gpu_compatible = 8;
          if (this_._internal_force_gpu_compatible() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                8, this_._internal_force_gpu_compatible(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.GPUOptions.Experimental experimental = 9;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                9, *this_._impl_.experimental_, this_._impl_.experimental_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GPUOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t GPUOptions::ByteSizeLong(const MessageLite& base) {
          const GPUOptions& this_ = static_cast<const GPUOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t GPUOptions::ByteSizeLong() const {
          const GPUOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.GPUOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string allocator_type = 2;
            if (!this_._internal_allocator_type().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_allocator_type());
            }
            // string visible_device_list = 5;
            if (!this_._internal_visible_device_list().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_visible_device_list());
            }
          }
           {
            // .tensorflow.GPUOptions.Experimental experimental = 9;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.experimental_);
            }
          }
           {
            // double per_process_gpu_memory_fraction = 1;
            if (::absl::bit_cast<::uint64_t>(this_._internal_per_process_gpu_memory_fraction()) != 0) {
              total_size += 9;
            }
            // int64 deferred_deletion_bytes = 3;
            if (this_._internal_deferred_deletion_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_deferred_deletion_bytes());
            }
            // int32 polling_active_delay_usecs = 6;
            if (this_._internal_polling_active_delay_usecs() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_polling_active_delay_usecs());
            }
            // bool allow_growth = 4;
            if (this_._internal_allow_growth() != 0) {
              total_size += 2;
            }
            // bool force_gpu_compatible = 8;
            if (this_._internal_force_gpu_compatible() != 0) {
              total_size += 2;
            }
            // int32 polling_inactive_delay_msecs = 7;
            if (this_._internal_polling_inactive_delay_msecs() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_polling_inactive_delay_msecs());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void GPUOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<GPUOptions*>(&to_msg);
  auto& from = static_cast<const GPUOptions&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GPUOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_allocator_type().empty()) {
    _this->_internal_set_allocator_type(from._internal_allocator_type());
  }
  if (!from._internal_visible_device_list().empty()) {
    _this->_internal_set_visible_device_list(from._internal_visible_device_list());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.experimental_ != nullptr);
    if (_this->_impl_.experimental_ == nullptr) {
      _this->_impl_.experimental_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions_Experimental>(arena, *from._impl_.experimental_);
    } else {
      _this->_impl_.experimental_->MergeFrom(*from._impl_.experimental_);
    }
  }
  if (::absl::bit_cast<::uint64_t>(from._internal_per_process_gpu_memory_fraction()) != 0) {
    _this->_impl_.per_process_gpu_memory_fraction_ = from._impl_.per_process_gpu_memory_fraction_;
  }
  if (from._internal_deferred_deletion_bytes() != 0) {
    _this->_impl_.deferred_deletion_bytes_ = from._impl_.deferred_deletion_bytes_;
  }
  if (from._internal_polling_active_delay_usecs() != 0) {
    _this->_impl_.polling_active_delay_usecs_ = from._impl_.polling_active_delay_usecs_;
  }
  if (from._internal_allow_growth() != 0) {
    _this->_impl_.allow_growth_ = from._impl_.allow_growth_;
  }
  if (from._internal_force_gpu_compatible() != 0) {
    _this->_impl_.force_gpu_compatible_ = from._impl_.force_gpu_compatible_;
  }
  if (from._internal_polling_inactive_delay_msecs() != 0) {
    _this->_impl_.polling_inactive_delay_msecs_ = from._impl_.polling_inactive_delay_msecs_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void GPUOptions::CopyFrom(const GPUOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GPUOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void GPUOptions::InternalSwap(GPUOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.allocator_type_, &other->_impl_.allocator_type_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.visible_device_list_, &other->_impl_.visible_device_list_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.polling_inactive_delay_msecs_)
      + sizeof(GPUOptions::_impl_.polling_inactive_delay_msecs_)
      - PROTOBUF_FIELD_OFFSET(GPUOptions, _impl_.experimental_)>(
          reinterpret_cast<char*>(&_impl_.experimental_),
          reinterpret_cast<char*>(&other->_impl_.experimental_));
}

::google::protobuf::Metadata GPUOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class OptimizerOptions::_Internal {
 public:
};

OptimizerOptions::OptimizerOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.OptimizerOptions)
}
OptimizerOptions::OptimizerOptions(
    ::google::protobuf::Arena* arena, const OptimizerOptions& from)
    : OptimizerOptions(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE OptimizerOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void OptimizerOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, opt_level_),
           0,
           offsetof(Impl_, global_jit_level_) -
               offsetof(Impl_, opt_level_) +
               sizeof(Impl_::global_jit_level_));
}
OptimizerOptions::~OptimizerOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.OptimizerOptions)
  SharedDtor(*this);
}
inline void OptimizerOptions::SharedDtor(MessageLite& self) {
  OptimizerOptions& this_ = static_cast<OptimizerOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* OptimizerOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) OptimizerOptions(arena);
}
constexpr auto OptimizerOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(OptimizerOptions),
                                            alignof(OptimizerOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull OptimizerOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_OptimizerOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &OptimizerOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<OptimizerOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &OptimizerOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<OptimizerOptions>(), &OptimizerOptions::ByteSizeLong,
            &OptimizerOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_._cached_size_),
        false,
    },
    &OptimizerOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* OptimizerOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 7, 0, 0, 2> OptimizerOptions::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    7, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967168,  // skipmap
    offsetof(decltype(_table_), field_entries),
    7,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::OptimizerOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // bool do_common_subexpression_elimination = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(OptimizerOptions, _impl_.do_common_subexpression_elimination_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_common_subexpression_elimination_)}},
    // bool do_constant_folding = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(OptimizerOptions, _impl_.do_constant_folding_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_constant_folding_)}},
    // .tensorflow.OptimizerOptions.Level opt_level = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(OptimizerOptions, _impl_.opt_level_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.opt_level_)}},
    // bool do_function_inlining = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(OptimizerOptions, _impl_.do_function_inlining_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_function_inlining_)}},
    // .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(OptimizerOptions, _impl_.global_jit_level_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.global_jit_level_)}},
    // int64 max_folded_constant_in_bytes = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(OptimizerOptions, _impl_.max_folded_constant_in_bytes_), 63>(),
     {48, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.max_folded_constant_in_bytes_)}},
    // bool cpu_global_jit = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(OptimizerOptions, _impl_.cpu_global_jit_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.cpu_global_jit_)}},
  }}, {{
    65535, 65535
  }}, {{
    // bool do_common_subexpression_elimination = 1;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_common_subexpression_elimination_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool do_constant_folding = 2;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_constant_folding_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.OptimizerOptions.Level opt_level = 3;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.opt_level_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // bool do_function_inlining = 4;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.do_function_inlining_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.global_jit_level_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // int64 max_folded_constant_in_bytes = 6;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.max_folded_constant_in_bytes_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // bool cpu_global_jit = 7;
    {PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.cpu_global_jit_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void OptimizerOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.OptimizerOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.opt_level_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.global_jit_level_) -
      reinterpret_cast<char*>(&_impl_.opt_level_)) + sizeof(_impl_.global_jit_level_));
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* OptimizerOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const OptimizerOptions& this_ = static_cast<const OptimizerOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* OptimizerOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const OptimizerOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.OptimizerOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // bool do_common_subexpression_elimination = 1;
          if (this_._internal_do_common_subexpression_elimination() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                1, this_._internal_do_common_subexpression_elimination(), target);
          }

          // bool do_constant_folding = 2;
          if (this_._internal_do_constant_folding() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_do_constant_folding(), target);
          }

          // .tensorflow.OptimizerOptions.Level opt_level = 3;
          if (this_._internal_opt_level() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                3, this_._internal_opt_level(), target);
          }

          // bool do_function_inlining = 4;
          if (this_._internal_do_function_inlining() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                4, this_._internal_do_function_inlining(), target);
          }

          // .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;
          if (this_._internal_global_jit_level() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                5, this_._internal_global_jit_level(), target);
          }

          // int64 max_folded_constant_in_bytes = 6;
          if (this_._internal_max_folded_constant_in_bytes() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<6>(
                    stream, this_._internal_max_folded_constant_in_bytes(), target);
          }

          // bool cpu_global_jit = 7;
          if (this_._internal_cpu_global_jit() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                7, this_._internal_cpu_global_jit(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.OptimizerOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t OptimizerOptions::ByteSizeLong(const MessageLite& base) {
          const OptimizerOptions& this_ = static_cast<const OptimizerOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t OptimizerOptions::ByteSizeLong() const {
          const OptimizerOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.OptimizerOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // .tensorflow.OptimizerOptions.Level opt_level = 3;
            if (this_._internal_opt_level() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_opt_level());
            }
            // bool do_common_subexpression_elimination = 1;
            if (this_._internal_do_common_subexpression_elimination() != 0) {
              total_size += 2;
            }
            // bool do_constant_folding = 2;
            if (this_._internal_do_constant_folding() != 0) {
              total_size += 2;
            }
            // bool do_function_inlining = 4;
            if (this_._internal_do_function_inlining() != 0) {
              total_size += 2;
            }
            // bool cpu_global_jit = 7;
            if (this_._internal_cpu_global_jit() != 0) {
              total_size += 2;
            }
            // int64 max_folded_constant_in_bytes = 6;
            if (this_._internal_max_folded_constant_in_bytes() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_max_folded_constant_in_bytes());
            }
            // .tensorflow.OptimizerOptions.GlobalJitLevel global_jit_level = 5;
            if (this_._internal_global_jit_level() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_global_jit_level());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void OptimizerOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<OptimizerOptions*>(&to_msg);
  auto& from = static_cast<const OptimizerOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.OptimizerOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_opt_level() != 0) {
    _this->_impl_.opt_level_ = from._impl_.opt_level_;
  }
  if (from._internal_do_common_subexpression_elimination() != 0) {
    _this->_impl_.do_common_subexpression_elimination_ = from._impl_.do_common_subexpression_elimination_;
  }
  if (from._internal_do_constant_folding() != 0) {
    _this->_impl_.do_constant_folding_ = from._impl_.do_constant_folding_;
  }
  if (from._internal_do_function_inlining() != 0) {
    _this->_impl_.do_function_inlining_ = from._impl_.do_function_inlining_;
  }
  if (from._internal_cpu_global_jit() != 0) {
    _this->_impl_.cpu_global_jit_ = from._impl_.cpu_global_jit_;
  }
  if (from._internal_max_folded_constant_in_bytes() != 0) {
    _this->_impl_.max_folded_constant_in_bytes_ = from._impl_.max_folded_constant_in_bytes_;
  }
  if (from._internal_global_jit_level() != 0) {
    _this->_impl_.global_jit_level_ = from._impl_.global_jit_level_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void OptimizerOptions::CopyFrom(const OptimizerOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.OptimizerOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void OptimizerOptions::InternalSwap(OptimizerOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.global_jit_level_)
      + sizeof(OptimizerOptions::_impl_.global_jit_level_)
      - PROTOBUF_FIELD_OFFSET(OptimizerOptions, _impl_.opt_level_)>(
          reinterpret_cast<char*>(&_impl_.opt_level_),
          reinterpret_cast<char*>(&other->_impl_.opt_level_));
}

::google::protobuf::Metadata OptimizerOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class GraphOptions::_Internal {
 public:
  using HasBits =
      decltype(std::declval<GraphOptions>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_._has_bits_);
};

void GraphOptions::clear_rewrite_options() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.rewrite_options_ != nullptr) _impl_.rewrite_options_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
GraphOptions::GraphOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.GraphOptions)
}
inline PROTOBUF_NDEBUG_INLINE GraphOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::GraphOptions& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

GraphOptions::GraphOptions(
    ::google::protobuf::Arena* arena,
    const GraphOptions& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  GraphOptions* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.optimizer_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::OptimizerOptions>(
                              arena, *from._impl_.optimizer_options_)
                        : nullptr;
  _impl_.rewrite_options_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::RewriterConfig>(
                              arena, *from._impl_.rewrite_options_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, build_cost_model_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, build_cost_model_),
           offsetof(Impl_, build_cost_model_after_) -
               offsetof(Impl_, build_cost_model_) +
               sizeof(Impl_::build_cost_model_after_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.GraphOptions)
}
inline PROTOBUF_NDEBUG_INLINE GraphOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void GraphOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, optimizer_options_),
           0,
           offsetof(Impl_, build_cost_model_after_) -
               offsetof(Impl_, optimizer_options_) +
               sizeof(Impl_::build_cost_model_after_));
}
GraphOptions::~GraphOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.GraphOptions)
  SharedDtor(*this);
}
inline void GraphOptions::SharedDtor(MessageLite& self) {
  GraphOptions& this_ = static_cast<GraphOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.optimizer_options_;
  delete this_._impl_.rewrite_options_;
  this_._impl_.~Impl_();
}

inline void* GraphOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) GraphOptions(arena);
}
constexpr auto GraphOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(GraphOptions),
                                            alignof(GraphOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull GraphOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_GraphOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &GraphOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<GraphOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &GraphOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<GraphOptions>(), &GraphOptions::ByteSizeLong,
            &GraphOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_._cached_size_),
        false,
    },
    &GraphOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* GraphOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<4, 9, 2, 0, 2> GraphOptions::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_._has_bits_),
    0, // no _extensions_
    10, 120,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294966273,  // skipmap
    offsetof(decltype(_table_), field_entries),
    9,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::GraphOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool enable_recv_scheduling = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GraphOptions, _impl_.enable_recv_scheduling_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.enable_recv_scheduling_)}},
    // .tensorflow.OptimizerOptions optimizer_options = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.optimizer_options_)}},
    // int64 build_cost_model = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(GraphOptions, _impl_.build_cost_model_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.build_cost_model_)}},
    // bool infer_shapes = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GraphOptions, _impl_.infer_shapes_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.infer_shapes_)}},
    // bool place_pruned_graph = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GraphOptions, _impl_.place_pruned_graph_), 63>(),
     {48, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.place_pruned_graph_)}},
    // bool enable_bfloat16_sendrecv = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(GraphOptions, _impl_.enable_bfloat16_sendrecv_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.enable_bfloat16_sendrecv_)}},
    // int32 timeline_step = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(GraphOptions, _impl_.timeline_step_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.timeline_step_)}},
    // int64 build_cost_model_after = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(GraphOptions, _impl_.build_cost_model_after_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.build_cost_model_after_)}},
    // .tensorflow.RewriterConfig rewrite_options = 10;
    {::_pbi::TcParser::FastMtS1,
     {82, 1, 1, PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.rewrite_options_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // bool enable_recv_scheduling = 2;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.enable_recv_scheduling_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.OptimizerOptions optimizer_options = 3;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.optimizer_options_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 build_cost_model = 4;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.build_cost_model_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // bool infer_shapes = 5;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.infer_shapes_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool place_pruned_graph = 6;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.place_pruned_graph_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_bfloat16_sendrecv = 7;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.enable_bfloat16_sendrecv_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 timeline_step = 8;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.timeline_step_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int64 build_cost_model_after = 9;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.build_cost_model_after_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // .tensorflow.RewriterConfig rewrite_options = 10;
    {PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.rewrite_options_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::OptimizerOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::RewriterConfig>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void GraphOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.GraphOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.optimizer_options_ != nullptr);
      _impl_.optimizer_options_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.rewrite_options_ != nullptr);
      _impl_.rewrite_options_->Clear();
    }
  }
  ::memset(&_impl_.build_cost_model_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.build_cost_model_after_) -
      reinterpret_cast<char*>(&_impl_.build_cost_model_)) + sizeof(_impl_.build_cost_model_after_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* GraphOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const GraphOptions& this_ = static_cast<const GraphOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* GraphOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const GraphOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.GraphOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // bool enable_recv_scheduling = 2;
          if (this_._internal_enable_recv_scheduling() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_enable_recv_scheduling(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.OptimizerOptions optimizer_options = 3;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.optimizer_options_, this_._impl_.optimizer_options_->GetCachedSize(), target,
                stream);
          }

          // int64 build_cost_model = 4;
          if (this_._internal_build_cost_model() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<4>(
                    stream, this_._internal_build_cost_model(), target);
          }

          // bool infer_shapes = 5;
          if (this_._internal_infer_shapes() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_infer_shapes(), target);
          }

          // bool place_pruned_graph = 6;
          if (this_._internal_place_pruned_graph() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                6, this_._internal_place_pruned_graph(), target);
          }

          // bool enable_bfloat16_sendrecv = 7;
          if (this_._internal_enable_bfloat16_sendrecv() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                7, this_._internal_enable_bfloat16_sendrecv(), target);
          }

          // int32 timeline_step = 8;
          if (this_._internal_timeline_step() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<8>(
                    stream, this_._internal_timeline_step(), target);
          }

          // int64 build_cost_model_after = 9;
          if (this_._internal_build_cost_model_after() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<9>(
                    stream, this_._internal_build_cost_model_after(), target);
          }

          // .tensorflow.RewriterConfig rewrite_options = 10;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                10, *this_._impl_.rewrite_options_, this_._impl_.rewrite_options_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.GraphOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t GraphOptions::ByteSizeLong(const MessageLite& base) {
          const GraphOptions& this_ = static_cast<const GraphOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t GraphOptions::ByteSizeLong() const {
          const GraphOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.GraphOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .tensorflow.OptimizerOptions optimizer_options = 3;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.optimizer_options_);
            }
            // .tensorflow.RewriterConfig rewrite_options = 10;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.rewrite_options_);
            }
          }
           {
            // int64 build_cost_model = 4;
            if (this_._internal_build_cost_model() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_build_cost_model());
            }
            // bool enable_recv_scheduling = 2;
            if (this_._internal_enable_recv_scheduling() != 0) {
              total_size += 2;
            }
            // bool infer_shapes = 5;
            if (this_._internal_infer_shapes() != 0) {
              total_size += 2;
            }
            // bool place_pruned_graph = 6;
            if (this_._internal_place_pruned_graph() != 0) {
              total_size += 2;
            }
            // bool enable_bfloat16_sendrecv = 7;
            if (this_._internal_enable_bfloat16_sendrecv() != 0) {
              total_size += 2;
            }
            // int32 timeline_step = 8;
            if (this_._internal_timeline_step() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_timeline_step());
            }
            // int64 build_cost_model_after = 9;
            if (this_._internal_build_cost_model_after() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_build_cost_model_after());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void GraphOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<GraphOptions*>(&to_msg);
  auto& from = static_cast<const GraphOptions&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.GraphOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.optimizer_options_ != nullptr);
      if (_this->_impl_.optimizer_options_ == nullptr) {
        _this->_impl_.optimizer_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::OptimizerOptions>(arena, *from._impl_.optimizer_options_);
      } else {
        _this->_impl_.optimizer_options_->MergeFrom(*from._impl_.optimizer_options_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.rewrite_options_ != nullptr);
      if (_this->_impl_.rewrite_options_ == nullptr) {
        _this->_impl_.rewrite_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::RewriterConfig>(arena, *from._impl_.rewrite_options_);
      } else {
        _this->_impl_.rewrite_options_->MergeFrom(*from._impl_.rewrite_options_);
      }
    }
  }
  if (from._internal_build_cost_model() != 0) {
    _this->_impl_.build_cost_model_ = from._impl_.build_cost_model_;
  }
  if (from._internal_enable_recv_scheduling() != 0) {
    _this->_impl_.enable_recv_scheduling_ = from._impl_.enable_recv_scheduling_;
  }
  if (from._internal_infer_shapes() != 0) {
    _this->_impl_.infer_shapes_ = from._impl_.infer_shapes_;
  }
  if (from._internal_place_pruned_graph() != 0) {
    _this->_impl_.place_pruned_graph_ = from._impl_.place_pruned_graph_;
  }
  if (from._internal_enable_bfloat16_sendrecv() != 0) {
    _this->_impl_.enable_bfloat16_sendrecv_ = from._impl_.enable_bfloat16_sendrecv_;
  }
  if (from._internal_timeline_step() != 0) {
    _this->_impl_.timeline_step_ = from._impl_.timeline_step_;
  }
  if (from._internal_build_cost_model_after() != 0) {
    _this->_impl_.build_cost_model_after_ = from._impl_.build_cost_model_after_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void GraphOptions::CopyFrom(const GraphOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.GraphOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void GraphOptions::InternalSwap(GraphOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.build_cost_model_after_)
      + sizeof(GraphOptions::_impl_.build_cost_model_after_)
      - PROTOBUF_FIELD_OFFSET(GraphOptions, _impl_.optimizer_options_)>(
          reinterpret_cast<char*>(&_impl_.optimizer_options_),
          reinterpret_cast<char*>(&other->_impl_.optimizer_options_));
}

::google::protobuf::Metadata GraphOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class ThreadPoolOptionProto::_Internal {
 public:
};

ThreadPoolOptionProto::ThreadPoolOptionProto(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ThreadPoolOptionProto)
}
inline PROTOBUF_NDEBUG_INLINE ThreadPoolOptionProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::ThreadPoolOptionProto& from_msg)
      : global_name_(arena, from.global_name_),
        _cached_size_{0} {}

ThreadPoolOptionProto::ThreadPoolOptionProto(
    ::google::protobuf::Arena* arena,
    const ThreadPoolOptionProto& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  ThreadPoolOptionProto* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.num_threads_ = from._impl_.num_threads_;

  // @@protoc_insertion_point(copy_constructor:tensorflow.ThreadPoolOptionProto)
}
inline PROTOBUF_NDEBUG_INLINE ThreadPoolOptionProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : global_name_(arena),
        _cached_size_{0} {}

inline void ThreadPoolOptionProto::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.num_threads_ = {};
}
ThreadPoolOptionProto::~ThreadPoolOptionProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ThreadPoolOptionProto)
  SharedDtor(*this);
}
inline void ThreadPoolOptionProto::SharedDtor(MessageLite& self) {
  ThreadPoolOptionProto& this_ = static_cast<ThreadPoolOptionProto&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.global_name_.Destroy();
  this_._impl_.~Impl_();
}

inline void* ThreadPoolOptionProto::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) ThreadPoolOptionProto(arena);
}
constexpr auto ThreadPoolOptionProto::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(ThreadPoolOptionProto),
                                            alignof(ThreadPoolOptionProto));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull ThreadPoolOptionProto::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_ThreadPoolOptionProto_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &ThreadPoolOptionProto::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<ThreadPoolOptionProto>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &ThreadPoolOptionProto::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<ThreadPoolOptionProto>(), &ThreadPoolOptionProto::ByteSizeLong,
            &ThreadPoolOptionProto::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(ThreadPoolOptionProto, _impl_._cached_size_),
        false,
    },
    &ThreadPoolOptionProto::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* ThreadPoolOptionProto::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 52, 2> ThreadPoolOptionProto::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::ThreadPoolOptionProto>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string global_name = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(ThreadPoolOptionProto, _impl_.global_name_)}},
    // int32 num_threads = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ThreadPoolOptionProto, _impl_.num_threads_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(ThreadPoolOptionProto, _impl_.num_threads_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int32 num_threads = 1;
    {PROTOBUF_FIELD_OFFSET(ThreadPoolOptionProto, _impl_.num_threads_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // string global_name = 2;
    {PROTOBUF_FIELD_OFFSET(ThreadPoolOptionProto, _impl_.global_name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\40\0\13\0\0\0\0\0"
    "tensorflow.ThreadPoolOptionProto"
    "global_name"
  }},
};

PROTOBUF_NOINLINE void ThreadPoolOptionProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ThreadPoolOptionProto)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.global_name_.ClearToEmpty();
  _impl_.num_threads_ = 0;
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* ThreadPoolOptionProto::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const ThreadPoolOptionProto& this_ = static_cast<const ThreadPoolOptionProto&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* ThreadPoolOptionProto::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const ThreadPoolOptionProto& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ThreadPoolOptionProto)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int32 num_threads = 1;
          if (this_._internal_num_threads() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<1>(
                    stream, this_._internal_num_threads(), target);
          }

          // string global_name = 2;
          if (!this_._internal_global_name().empty()) {
            const std::string& _s = this_._internal_global_name();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ThreadPoolOptionProto.global_name");
            target = stream->WriteStringMaybeAliased(2, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ThreadPoolOptionProto)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t ThreadPoolOptionProto::ByteSizeLong(const MessageLite& base) {
          const ThreadPoolOptionProto& this_ = static_cast<const ThreadPoolOptionProto&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t ThreadPoolOptionProto::ByteSizeLong() const {
          const ThreadPoolOptionProto& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.ThreadPoolOptionProto)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string global_name = 2;
            if (!this_._internal_global_name().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_global_name());
            }
            // int32 num_threads = 1;
            if (this_._internal_num_threads() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_num_threads());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void ThreadPoolOptionProto::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<ThreadPoolOptionProto*>(&to_msg);
  auto& from = static_cast<const ThreadPoolOptionProto&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ThreadPoolOptionProto)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_global_name().empty()) {
    _this->_internal_set_global_name(from._internal_global_name());
  }
  if (from._internal_num_threads() != 0) {
    _this->_impl_.num_threads_ = from._impl_.num_threads_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void ThreadPoolOptionProto::CopyFrom(const ThreadPoolOptionProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ThreadPoolOptionProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void ThreadPoolOptionProto::InternalSwap(ThreadPoolOptionProto* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.global_name_, &other->_impl_.global_name_, arena);
        swap(_impl_.num_threads_, other->_impl_.num_threads_);
}

::google::protobuf::Metadata ThreadPoolOptionProto::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class SessionMetadata::_Internal {
 public:
};

SessionMetadata::SessionMetadata(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.SessionMetadata)
}
inline PROTOBUF_NDEBUG_INLINE SessionMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::SessionMetadata& from_msg)
      : name_(arena, from.name_),
        _cached_size_{0} {}

SessionMetadata::SessionMetadata(
    ::google::protobuf::Arena* arena,
    const SessionMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SessionMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  _impl_.version_ = from._impl_.version_;

  // @@protoc_insertion_point(copy_constructor:tensorflow.SessionMetadata)
}
inline PROTOBUF_NDEBUG_INLINE SessionMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : name_(arena),
        _cached_size_{0} {}

inline void SessionMetadata::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.version_ = {};
}
SessionMetadata::~SessionMetadata() {
  // @@protoc_insertion_point(destructor:tensorflow.SessionMetadata)
  SharedDtor(*this);
}
inline void SessionMetadata::SharedDtor(MessageLite& self) {
  SessionMetadata& this_ = static_cast<SessionMetadata&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.name_.Destroy();
  this_._impl_.~Impl_();
}

inline void* SessionMetadata::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) SessionMetadata(arena);
}
constexpr auto SessionMetadata::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(SessionMetadata),
                                            alignof(SessionMetadata));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull SessionMetadata::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_SessionMetadata_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &SessionMetadata::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<SessionMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &SessionMetadata::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<SessionMetadata>(), &SessionMetadata::ByteSizeLong,
            &SessionMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(SessionMetadata, _impl_._cached_size_),
        false,
    },
    &SessionMetadata::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* SessionMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 39, 2> SessionMetadata::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::SessionMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int64 version = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(SessionMetadata, _impl_.version_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(SessionMetadata, _impl_.version_)}},
    // string name = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(SessionMetadata, _impl_.name_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string name = 1;
    {PROTOBUF_FIELD_OFFSET(SessionMetadata, _impl_.name_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int64 version = 2;
    {PROTOBUF_FIELD_OFFSET(SessionMetadata, _impl_.version_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }},
  // no aux_entries
  {{
    "\32\4\0\0\0\0\0\0"
    "tensorflow.SessionMetadata"
    "name"
  }},
};

PROTOBUF_NOINLINE void SessionMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.SessionMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.name_.ClearToEmpty();
  _impl_.version_ = ::int64_t{0};
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* SessionMetadata::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const SessionMetadata& this_ = static_cast<const SessionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* SessionMetadata::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const SessionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.SessionMetadata)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string name = 1;
          if (!this_._internal_name().empty()) {
            const std::string& _s = this_._internal_name();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.SessionMetadata.name");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // int64 version = 2;
          if (this_._internal_version() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_version(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.SessionMetadata)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t SessionMetadata::ByteSizeLong(const MessageLite& base) {
          const SessionMetadata& this_ = static_cast<const SessionMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t SessionMetadata::ByteSizeLong() const {
          const SessionMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.SessionMetadata)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string name = 1;
            if (!this_._internal_name().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_name());
            }
            // int64 version = 2;
            if (this_._internal_version() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_version());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void SessionMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<SessionMetadata*>(&to_msg);
  auto& from = static_cast<const SessionMetadata&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.SessionMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_name().empty()) {
    _this->_internal_set_name(from._internal_name());
  }
  if (from._internal_version() != 0) {
    _this->_impl_.version_ = from._impl_.version_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void SessionMetadata::CopyFrom(const SessionMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.SessionMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void SessionMetadata::InternalSwap(SessionMetadata* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.name_, &other->_impl_.name_, arena);
        swap(_impl_.version_, other->_impl_.version_);
}

::google::protobuf::Metadata SessionMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

#if defined(PROTOBUF_CUSTOM_VTABLE)
              ConfigProto_DeviceCountEntry_DoNotUse::ConfigProto_DeviceCountEntry_DoNotUse() : SuperType(_class_data_.base()) {}
              ConfigProto_DeviceCountEntry_DoNotUse::ConfigProto_DeviceCountEntry_DoNotUse(::google::protobuf::Arena* arena)
                  : SuperType(arena, _class_data_.base()) {}
#else   // PROTOBUF_CUSTOM_VTABLE
              ConfigProto_DeviceCountEntry_DoNotUse::ConfigProto_DeviceCountEntry_DoNotUse() : SuperType() {}
              ConfigProto_DeviceCountEntry_DoNotUse::ConfigProto_DeviceCountEntry_DoNotUse(::google::protobuf::Arena* arena) : SuperType(arena) {}
#endif  // PROTOBUF_CUSTOM_VTABLE
              inline void* ConfigProto_DeviceCountEntry_DoNotUse::PlacementNew_(const void*, void* mem,
                                                      ::google::protobuf::Arena* arena) {
                return ::new (mem) ConfigProto_DeviceCountEntry_DoNotUse(arena);
              }
              constexpr auto ConfigProto_DeviceCountEntry_DoNotUse::InternalNewImpl_() {
                return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(ConfigProto_DeviceCountEntry_DoNotUse),
                                                          alignof(ConfigProto_DeviceCountEntry_DoNotUse));
              }
              PROTOBUF_CONSTINIT
              PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
              const ::google::protobuf::internal::ClassDataFull ConfigProto_DeviceCountEntry_DoNotUse::_class_data_ = {
                  ::google::protobuf::internal::ClassData{
                      &_ConfigProto_DeviceCountEntry_DoNotUse_default_instance_._instance,
                      &_table_.header,
                      nullptr,  // OnDemandRegisterArenaDtor
                      nullptr,  // IsInitialized
                      &ConfigProto_DeviceCountEntry_DoNotUse::MergeImpl,
                      ::google::protobuf::Message::GetNewImpl<ConfigProto_DeviceCountEntry_DoNotUse>(),
              #if defined(PROTOBUF_CUSTOM_VTABLE)
                      &ConfigProto_DeviceCountEntry_DoNotUse::SharedDtor,
                      static_cast<void (::google::protobuf::MessageLite::*)()>(
                          &ConfigProto_DeviceCountEntry_DoNotUse::ClearImpl),
                          ::google::protobuf::Message::ByteSizeLongImpl, ::google::protobuf::Message::_InternalSerializeImpl
                          ,
              #endif  // PROTOBUF_CUSTOM_VTABLE
                      PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_._cached_size_),
                      false,
                  },
                  &ConfigProto_DeviceCountEntry_DoNotUse::kDescriptorMethods,
                  &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
                  nullptr,  // tracker
              };
              const ::google::protobuf::internal::ClassData* ConfigProto_DeviceCountEntry_DoNotUse::GetClassData() const {
                ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
                ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
                return _class_data_.base();
              }
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 51, 2> ConfigProto_DeviceCountEntry_DoNotUse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::DiscardEverythingFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::ConfigProto_DeviceCountEntry_DoNotUse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int32 value = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ConfigProto_DeviceCountEntry_DoNotUse, _impl_.value_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_.value_)}},
    // string key = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_.key_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string key = 1;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_.key_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 value = 2;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_DeviceCountEntry_DoNotUse, _impl_.value_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
  }},
  // no aux_entries
  {{
    "\47\3\0\0\0\0\0\0"
    "tensorflow.ConfigProto.DeviceCountEntry"
    "key"
  }},
};

// ===================================================================

class ConfigProto_Experimental::_Internal {
 public:
  using HasBits =
      decltype(std::declval<ConfigProto_Experimental>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_._has_bits_);
};

void ConfigProto_Experimental::clear_coordination_config() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.coordination_config_ != nullptr) _impl_.coordination_config_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
ConfigProto_Experimental::ConfigProto_Experimental(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ConfigProto.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE ConfigProto_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::ConfigProto_Experimental& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        collective_group_leader_(arena, from.collective_group_leader_),
        executor_type_(arena, from.executor_type_) {}

ConfigProto_Experimental::ConfigProto_Experimental(
    ::google::protobuf::Arena* arena,
    const ConfigProto_Experimental& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  ConfigProto_Experimental* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.session_metadata_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::SessionMetadata>(
                              arena, *from._impl_.session_metadata_)
                        : nullptr;
  _impl_.coordination_config_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::CoordinationServiceConfig>(
                              arena, *from._impl_.coordination_config_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, recv_buf_max_chunk_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, recv_buf_max_chunk_),
           offsetof(Impl_, stream_merge_threshold_) -
               offsetof(Impl_, recv_buf_max_chunk_) +
               sizeof(Impl_::stream_merge_threshold_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.ConfigProto.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE ConfigProto_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        collective_group_leader_(arena),
        executor_type_(arena) {}

inline void ConfigProto_Experimental::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, session_metadata_),
           0,
           offsetof(Impl_, stream_merge_threshold_) -
               offsetof(Impl_, session_metadata_) +
               sizeof(Impl_::stream_merge_threshold_));
}
ConfigProto_Experimental::~ConfigProto_Experimental() {
  // @@protoc_insertion_point(destructor:tensorflow.ConfigProto.Experimental)
  SharedDtor(*this);
}
inline void ConfigProto_Experimental::SharedDtor(MessageLite& self) {
  ConfigProto_Experimental& this_ = static_cast<ConfigProto_Experimental&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.collective_group_leader_.Destroy();
  this_._impl_.executor_type_.Destroy();
  delete this_._impl_.session_metadata_;
  delete this_._impl_.coordination_config_;
  this_._impl_.~Impl_();
}

inline void* ConfigProto_Experimental::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) ConfigProto_Experimental(arena);
}
constexpr auto ConfigProto_Experimental::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(ConfigProto_Experimental),
                                            alignof(ConfigProto_Experimental));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull ConfigProto_Experimental::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_ConfigProto_Experimental_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &ConfigProto_Experimental::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<ConfigProto_Experimental>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &ConfigProto_Experimental::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<ConfigProto_Experimental>(), &ConfigProto_Experimental::ByteSizeLong,
            &ConfigProto_Experimental::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_._cached_size_),
        false,
    },
    &ConfigProto_Experimental::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* ConfigProto_Experimental::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 28, 2, 104, 2> ConfigProto_Experimental::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_._has_bits_),
    0, // no _extensions_
    32, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    17563650,  // skipmap
    offsetof(decltype(_table_), field_entries),
    28,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::ConfigProto_Experimental>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // string collective_group_leader = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_group_leader_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // string executor_type = 3;
    {::_pbi::TcParser::FastUS1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.executor_type_)}},
    // int32 recv_buf_max_chunk = 4;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ConfigProto_Experimental, _impl_.recv_buf_max_chunk_), 63>(),
     {32, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.recv_buf_max_chunk_)}},
    // bool use_numa_affinity = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.use_numa_affinity_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.use_numa_affinity_)}},
    // bool collective_deterministic_sequential_execution = 6;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.collective_deterministic_sequential_execution_), 63>(),
     {48, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_deterministic_sequential_execution_)}},
    // bool collective_nccl = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.collective_nccl_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_nccl_)}},
    // bool share_session_state_in_clusterspec_propagation = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.share_session_state_in_clusterspec_propagation_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.share_session_state_in_clusterspec_propagation_)}},
    // bool disable_thread_spinning = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.disable_thread_spinning_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_thread_spinning_)}},
    // bool share_cluster_devices_in_session = 10;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.share_cluster_devices_in_session_), 63>(),
     {80, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.share_cluster_devices_in_session_)}},
    // .tensorflow.SessionMetadata session_metadata = 11;
    {::_pbi::TcParser::FastMtS1,
     {90, 0, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.session_metadata_)}},
    // bool optimize_for_static_graph = 12;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.optimize_for_static_graph_), 63>(),
     {96, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.optimize_for_static_graph_)}},
    // bool enable_mlir_bridge = 13;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.enable_mlir_bridge_), 63>(),
     {104, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_mlir_bridge_)}},
    // bool disable_output_partition_graphs = 14;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto_Experimental, _impl_.disable_output_partition_graphs_), 63>(),
     {112, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_output_partition_graphs_)}},
    // int64 xla_fusion_autotuner_thresh = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(ConfigProto_Experimental, _impl_.xla_fusion_autotuner_thresh_), 63>(),
     {120, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.xla_fusion_autotuner_thresh_)}},
    // bool enable_mlir_graph_optimization = 16;
    {::_pbi::TcParser::FastV8S2,
     {384, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_mlir_graph_optimization_)}},
    // .tensorflow.ConfigProto.Experimental.MlirBridgeRollout mlir_bridge_rollout = 17;
    {::_pbi::TcParser::FastV32S2,
     {392, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.mlir_bridge_rollout_)}},
    // bool use_tfrt = 18;
    {::_pbi::TcParser::FastV8S2,
     {400, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.use_tfrt_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool disable_functional_ops_lowering = 21;
    {::_pbi::TcParser::FastV8S2,
     {424, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_functional_ops_lowering_)}},
    // bool xla_prefer_single_graph_cluster = 22;
    {::_pbi::TcParser::FastV8S2,
     {432, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.xla_prefer_single_graph_cluster_)}},
    // .tensorflow.CoordinationServiceConfig coordination_config = 23;
    {::_pbi::TcParser::FastMtS2,
     {442, 1, 1, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.coordination_config_)}},
    // bool disable_optimize_for_static_graph = 24;
    {::_pbi::TcParser::FastV8S2,
     {448, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_optimize_for_static_graph_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool disable_eager_executor_streaming_enqueue = 26;
    {::_pbi::TcParser::FastV8S2,
     {464, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_eager_executor_streaming_enqueue_)}},
    // bool enable_multi_host = 27;
    {::_pbi::TcParser::FastV8S2,
     {472, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_multi_host_)}},
    // int32 backend_server_port = 28;
    {::_pbi::TcParser::FastV32S2,
     {480, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.backend_server_port_)}},
    // bool target_tpu = 29;
    {::_pbi::TcParser::FastV8S2,
     {488, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.target_tpu_)}},
    // bool target_gpu = 30;
    {::_pbi::TcParser::FastV8S2,
     {496, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.target_gpu_)}},
    // int32 stream_merge_threshold = 31;
    {::_pbi::TcParser::FastV32S2,
     {504, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.stream_merge_threshold_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string collective_group_leader = 1;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_group_leader_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string executor_type = 3;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.executor_type_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // int32 recv_buf_max_chunk = 4;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.recv_buf_max_chunk_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool use_numa_affinity = 5;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.use_numa_affinity_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool collective_deterministic_sequential_execution = 6;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_deterministic_sequential_execution_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool collective_nccl = 7;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.collective_nccl_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool share_session_state_in_clusterspec_propagation = 8;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.share_session_state_in_clusterspec_propagation_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool disable_thread_spinning = 9;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_thread_spinning_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool share_cluster_devices_in_session = 10;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.share_cluster_devices_in_session_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.SessionMetadata session_metadata = 11;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.session_metadata_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool optimize_for_static_graph = 12;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.optimize_for_static_graph_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_mlir_bridge = 13;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_mlir_bridge_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool disable_output_partition_graphs = 14;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_output_partition_graphs_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int64 xla_fusion_autotuner_thresh = 15;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.xla_fusion_autotuner_thresh_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // bool enable_mlir_graph_optimization = 16;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_mlir_graph_optimization_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.ConfigProto.Experimental.MlirBridgeRollout mlir_bridge_rollout = 17;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.mlir_bridge_rollout_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // bool use_tfrt = 18;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.use_tfrt_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool disable_functional_ops_lowering = 21;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_functional_ops_lowering_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool xla_prefer_single_graph_cluster = 22;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.xla_prefer_single_graph_cluster_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.CoordinationServiceConfig coordination_config = 23;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.coordination_config_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool disable_optimize_for_static_graph = 24;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_optimize_for_static_graph_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool disable_eager_executor_streaming_enqueue = 26;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.disable_eager_executor_streaming_enqueue_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool enable_multi_host = 27;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.enable_multi_host_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 backend_server_port = 28;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.backend_server_port_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool target_tpu = 29;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.target_tpu_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool target_gpu = 30;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.target_gpu_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // int32 stream_merge_threshold = 31;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.stream_merge_threshold_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool tfrt_use_ifrt = 32;
    {PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.tfrt_use_ifrt_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::SessionMetadata>()},
    {::_pbi::TcParser::GetTable<::tensorflow::CoordinationServiceConfig>()},
  }}, {{
    "\43\27\15\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"
    "tensorflow.ConfigProto.Experimental"
    "collective_group_leader"
    "executor_type"
  }},
};

PROTOBUF_NOINLINE void ConfigProto_Experimental::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ConfigProto.Experimental)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.collective_group_leader_.ClearToEmpty();
  _impl_.executor_type_.ClearToEmpty();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.session_metadata_ != nullptr);
      _impl_.session_metadata_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.coordination_config_ != nullptr);
      _impl_.coordination_config_->Clear();
    }
  }
  ::memset(&_impl_.recv_buf_max_chunk_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.stream_merge_threshold_) -
      reinterpret_cast<char*>(&_impl_.recv_buf_max_chunk_)) + sizeof(_impl_.stream_merge_threshold_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* ConfigProto_Experimental::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const ConfigProto_Experimental& this_ = static_cast<const ConfigProto_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* ConfigProto_Experimental::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const ConfigProto_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ConfigProto.Experimental)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string collective_group_leader = 1;
          if (!this_._internal_collective_group_leader().empty()) {
            const std::string& _s = this_._internal_collective_group_leader();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ConfigProto.Experimental.collective_group_leader");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // string executor_type = 3;
          if (!this_._internal_executor_type().empty()) {
            const std::string& _s = this_._internal_executor_type();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ConfigProto.Experimental.executor_type");
            target = stream->WriteStringMaybeAliased(3, _s, target);
          }

          // int32 recv_buf_max_chunk = 4;
          if (this_._internal_recv_buf_max_chunk() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<4>(
                    stream, this_._internal_recv_buf_max_chunk(), target);
          }

          // bool use_numa_affinity = 5;
          if (this_._internal_use_numa_affinity() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_use_numa_affinity(), target);
          }

          // bool collective_deterministic_sequential_execution = 6;
          if (this_._internal_collective_deterministic_sequential_execution() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                6, this_._internal_collective_deterministic_sequential_execution(), target);
          }

          // bool collective_nccl = 7;
          if (this_._internal_collective_nccl() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                7, this_._internal_collective_nccl(), target);
          }

          // bool share_session_state_in_clusterspec_propagation = 8;
          if (this_._internal_share_session_state_in_clusterspec_propagation() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                8, this_._internal_share_session_state_in_clusterspec_propagation(), target);
          }

          // bool disable_thread_spinning = 9;
          if (this_._internal_disable_thread_spinning() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                9, this_._internal_disable_thread_spinning(), target);
          }

          // bool share_cluster_devices_in_session = 10;
          if (this_._internal_share_cluster_devices_in_session() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                10, this_._internal_share_cluster_devices_in_session(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.SessionMetadata session_metadata = 11;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                11, *this_._impl_.session_metadata_, this_._impl_.session_metadata_->GetCachedSize(), target,
                stream);
          }

          // bool optimize_for_static_graph = 12;
          if (this_._internal_optimize_for_static_graph() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                12, this_._internal_optimize_for_static_graph(), target);
          }

          // bool enable_mlir_bridge = 13;
          if (this_._internal_enable_mlir_bridge() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                13, this_._internal_enable_mlir_bridge(), target);
          }

          // bool disable_output_partition_graphs = 14;
          if (this_._internal_disable_output_partition_graphs() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                14, this_._internal_disable_output_partition_graphs(), target);
          }

          // int64 xla_fusion_autotuner_thresh = 15;
          if (this_._internal_xla_fusion_autotuner_thresh() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<15>(
                    stream, this_._internal_xla_fusion_autotuner_thresh(), target);
          }

          // bool enable_mlir_graph_optimization = 16;
          if (this_._internal_enable_mlir_graph_optimization() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                16, this_._internal_enable_mlir_graph_optimization(), target);
          }

          // .tensorflow.ConfigProto.Experimental.MlirBridgeRollout mlir_bridge_rollout = 17;
          if (this_._internal_mlir_bridge_rollout() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                17, this_._internal_mlir_bridge_rollout(), target);
          }

          // bool use_tfrt = 18;
          if (this_._internal_use_tfrt() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                18, this_._internal_use_tfrt(), target);
          }

          // bool disable_functional_ops_lowering = 21;
          if (this_._internal_disable_functional_ops_lowering() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                21, this_._internal_disable_functional_ops_lowering(), target);
          }

          // bool xla_prefer_single_graph_cluster = 22;
          if (this_._internal_xla_prefer_single_graph_cluster() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                22, this_._internal_xla_prefer_single_graph_cluster(), target);
          }

          // .tensorflow.CoordinationServiceConfig coordination_config = 23;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                23, *this_._impl_.coordination_config_, this_._impl_.coordination_config_->GetCachedSize(), target,
                stream);
          }

          // bool disable_optimize_for_static_graph = 24;
          if (this_._internal_disable_optimize_for_static_graph() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                24, this_._internal_disable_optimize_for_static_graph(), target);
          }

          // bool disable_eager_executor_streaming_enqueue = 26;
          if (this_._internal_disable_eager_executor_streaming_enqueue() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                26, this_._internal_disable_eager_executor_streaming_enqueue(), target);
          }

          // bool enable_multi_host = 27;
          if (this_._internal_enable_multi_host() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                27, this_._internal_enable_multi_host(), target);
          }

          // int32 backend_server_port = 28;
          if (this_._internal_backend_server_port() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt32ToArray(
                28, this_._internal_backend_server_port(), target);
          }

          // bool target_tpu = 29;
          if (this_._internal_target_tpu() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                29, this_._internal_target_tpu(), target);
          }

          // bool target_gpu = 30;
          if (this_._internal_target_gpu() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                30, this_._internal_target_gpu(), target);
          }

          // int32 stream_merge_threshold = 31;
          if (this_._internal_stream_merge_threshold() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteInt32ToArray(
                31, this_._internal_stream_merge_threshold(), target);
          }

          // bool tfrt_use_ifrt = 32;
          if (this_._internal_tfrt_use_ifrt() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                32, this_._internal_tfrt_use_ifrt(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ConfigProto.Experimental)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t ConfigProto_Experimental::ByteSizeLong(const MessageLite& base) {
          const ConfigProto_Experimental& this_ = static_cast<const ConfigProto_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t ConfigProto_Experimental::ByteSizeLong() const {
          const ConfigProto_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.ConfigProto.Experimental)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string collective_group_leader = 1;
            if (!this_._internal_collective_group_leader().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_collective_group_leader());
            }
            // string executor_type = 3;
            if (!this_._internal_executor_type().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_executor_type());
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .tensorflow.SessionMetadata session_metadata = 11;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.session_metadata_);
            }
            // .tensorflow.CoordinationServiceConfig coordination_config = 23;
            if (cached_has_bits & 0x00000002u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.coordination_config_);
            }
          }
           {
            // int32 recv_buf_max_chunk = 4;
            if (this_._internal_recv_buf_max_chunk() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_recv_buf_max_chunk());
            }
            // bool use_numa_affinity = 5;
            if (this_._internal_use_numa_affinity() != 0) {
              total_size += 2;
            }
            // bool collective_deterministic_sequential_execution = 6;
            if (this_._internal_collective_deterministic_sequential_execution() != 0) {
              total_size += 2;
            }
            // bool collective_nccl = 7;
            if (this_._internal_collective_nccl() != 0) {
              total_size += 2;
            }
            // bool share_session_state_in_clusterspec_propagation = 8;
            if (this_._internal_share_session_state_in_clusterspec_propagation() != 0) {
              total_size += 2;
            }
            // bool disable_thread_spinning = 9;
            if (this_._internal_disable_thread_spinning() != 0) {
              total_size += 2;
            }
            // bool share_cluster_devices_in_session = 10;
            if (this_._internal_share_cluster_devices_in_session() != 0) {
              total_size += 2;
            }
            // bool optimize_for_static_graph = 12;
            if (this_._internal_optimize_for_static_graph() != 0) {
              total_size += 2;
            }
            // bool enable_mlir_bridge = 13;
            if (this_._internal_enable_mlir_bridge() != 0) {
              total_size += 2;
            }
            // .tensorflow.ConfigProto.Experimental.MlirBridgeRollout mlir_bridge_rollout = 17;
            if (this_._internal_mlir_bridge_rollout() != 0) {
              total_size += 2 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_mlir_bridge_rollout());
            }
            // int64 xla_fusion_autotuner_thresh = 15;
            if (this_._internal_xla_fusion_autotuner_thresh() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_xla_fusion_autotuner_thresh());
            }
            // bool enable_mlir_graph_optimization = 16;
            if (this_._internal_enable_mlir_graph_optimization() != 0) {
              total_size += 3;
            }
            // bool disable_output_partition_graphs = 14;
            if (this_._internal_disable_output_partition_graphs() != 0) {
              total_size += 2;
            }
            // bool use_tfrt = 18;
            if (this_._internal_use_tfrt() != 0) {
              total_size += 3;
            }
            // bool enable_multi_host = 27;
            if (this_._internal_enable_multi_host() != 0) {
              total_size += 3;
            }
            // bool xla_prefer_single_graph_cluster = 22;
            if (this_._internal_xla_prefer_single_graph_cluster() != 0) {
              total_size += 3;
            }
            // bool disable_optimize_for_static_graph = 24;
            if (this_._internal_disable_optimize_for_static_graph() != 0) {
              total_size += 3;
            }
            // bool disable_eager_executor_streaming_enqueue = 26;
            if (this_._internal_disable_eager_executor_streaming_enqueue() != 0) {
              total_size += 3;
            }
            // int32 backend_server_port = 28;
            if (this_._internal_backend_server_port() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int32Size(
                                              this_._internal_backend_server_port());
            }
            // bool tfrt_use_ifrt = 32;
            if (this_._internal_tfrt_use_ifrt() != 0) {
              total_size += 3;
            }
            // bool target_tpu = 29;
            if (this_._internal_target_tpu() != 0) {
              total_size += 3;
            }
            // bool target_gpu = 30;
            if (this_._internal_target_gpu() != 0) {
              total_size += 3;
            }
            // bool disable_functional_ops_lowering = 21;
            if (this_._internal_disable_functional_ops_lowering() != 0) {
              total_size += 3;
            }
            // int32 stream_merge_threshold = 31;
            if (this_._internal_stream_merge_threshold() != 0) {
              total_size += 2 + ::_pbi::WireFormatLite::Int32Size(
                                              this_._internal_stream_merge_threshold());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void ConfigProto_Experimental::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<ConfigProto_Experimental*>(&to_msg);
  auto& from = static_cast<const ConfigProto_Experimental&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ConfigProto.Experimental)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_collective_group_leader().empty()) {
    _this->_internal_set_collective_group_leader(from._internal_collective_group_leader());
  }
  if (!from._internal_executor_type().empty()) {
    _this->_internal_set_executor_type(from._internal_executor_type());
  }
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.session_metadata_ != nullptr);
      if (_this->_impl_.session_metadata_ == nullptr) {
        _this->_impl_.session_metadata_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::SessionMetadata>(arena, *from._impl_.session_metadata_);
      } else {
        _this->_impl_.session_metadata_->MergeFrom(*from._impl_.session_metadata_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.coordination_config_ != nullptr);
      if (_this->_impl_.coordination_config_ == nullptr) {
        _this->_impl_.coordination_config_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::CoordinationServiceConfig>(arena, *from._impl_.coordination_config_);
      } else {
        _this->_impl_.coordination_config_->MergeFrom(*from._impl_.coordination_config_);
      }
    }
  }
  if (from._internal_recv_buf_max_chunk() != 0) {
    _this->_impl_.recv_buf_max_chunk_ = from._impl_.recv_buf_max_chunk_;
  }
  if (from._internal_use_numa_affinity() != 0) {
    _this->_impl_.use_numa_affinity_ = from._impl_.use_numa_affinity_;
  }
  if (from._internal_collective_deterministic_sequential_execution() != 0) {
    _this->_impl_.collective_deterministic_sequential_execution_ = from._impl_.collective_deterministic_sequential_execution_;
  }
  if (from._internal_collective_nccl() != 0) {
    _this->_impl_.collective_nccl_ = from._impl_.collective_nccl_;
  }
  if (from._internal_share_session_state_in_clusterspec_propagation() != 0) {
    _this->_impl_.share_session_state_in_clusterspec_propagation_ = from._impl_.share_session_state_in_clusterspec_propagation_;
  }
  if (from._internal_disable_thread_spinning() != 0) {
    _this->_impl_.disable_thread_spinning_ = from._impl_.disable_thread_spinning_;
  }
  if (from._internal_share_cluster_devices_in_session() != 0) {
    _this->_impl_.share_cluster_devices_in_session_ = from._impl_.share_cluster_devices_in_session_;
  }
  if (from._internal_optimize_for_static_graph() != 0) {
    _this->_impl_.optimize_for_static_graph_ = from._impl_.optimize_for_static_graph_;
  }
  if (from._internal_enable_mlir_bridge() != 0) {
    _this->_impl_.enable_mlir_bridge_ = from._impl_.enable_mlir_bridge_;
  }
  if (from._internal_mlir_bridge_rollout() != 0) {
    _this->_impl_.mlir_bridge_rollout_ = from._impl_.mlir_bridge_rollout_;
  }
  if (from._internal_xla_fusion_autotuner_thresh() != 0) {
    _this->_impl_.xla_fusion_autotuner_thresh_ = from._impl_.xla_fusion_autotuner_thresh_;
  }
  if (from._internal_enable_mlir_graph_optimization() != 0) {
    _this->_impl_.enable_mlir_graph_optimization_ = from._impl_.enable_mlir_graph_optimization_;
  }
  if (from._internal_disable_output_partition_graphs() != 0) {
    _this->_impl_.disable_output_partition_graphs_ = from._impl_.disable_output_partition_graphs_;
  }
  if (from._internal_use_tfrt() != 0) {
    _this->_impl_.use_tfrt_ = from._impl_.use_tfrt_;
  }
  if (from._internal_enable_multi_host() != 0) {
    _this->_impl_.enable_multi_host_ = from._impl_.enable_multi_host_;
  }
  if (from._internal_xla_prefer_single_graph_cluster() != 0) {
    _this->_impl_.xla_prefer_single_graph_cluster_ = from._impl_.xla_prefer_single_graph_cluster_;
  }
  if (from._internal_disable_optimize_for_static_graph() != 0) {
    _this->_impl_.disable_optimize_for_static_graph_ = from._impl_.disable_optimize_for_static_graph_;
  }
  if (from._internal_disable_eager_executor_streaming_enqueue() != 0) {
    _this->_impl_.disable_eager_executor_streaming_enqueue_ = from._impl_.disable_eager_executor_streaming_enqueue_;
  }
  if (from._internal_backend_server_port() != 0) {
    _this->_impl_.backend_server_port_ = from._impl_.backend_server_port_;
  }
  if (from._internal_tfrt_use_ifrt() != 0) {
    _this->_impl_.tfrt_use_ifrt_ = from._impl_.tfrt_use_ifrt_;
  }
  if (from._internal_target_tpu() != 0) {
    _this->_impl_.target_tpu_ = from._impl_.target_tpu_;
  }
  if (from._internal_target_gpu() != 0) {
    _this->_impl_.target_gpu_ = from._impl_.target_gpu_;
  }
  if (from._internal_disable_functional_ops_lowering() != 0) {
    _this->_impl_.disable_functional_ops_lowering_ = from._impl_.disable_functional_ops_lowering_;
  }
  if (from._internal_stream_merge_threshold() != 0) {
    _this->_impl_.stream_merge_threshold_ = from._impl_.stream_merge_threshold_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void ConfigProto_Experimental::CopyFrom(const ConfigProto_Experimental& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ConfigProto.Experimental)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void ConfigProto_Experimental::InternalSwap(ConfigProto_Experimental* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.collective_group_leader_, &other->_impl_.collective_group_leader_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.executor_type_, &other->_impl_.executor_type_, arena);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.stream_merge_threshold_)
      + sizeof(ConfigProto_Experimental::_impl_.stream_merge_threshold_)
      - PROTOBUF_FIELD_OFFSET(ConfigProto_Experimental, _impl_.session_metadata_)>(
          reinterpret_cast<char*>(&_impl_.session_metadata_),
          reinterpret_cast<char*>(&other->_impl_.session_metadata_));
}

::google::protobuf::Metadata ConfigProto_Experimental::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class ConfigProto::_Internal {
 public:
  using HasBits =
      decltype(std::declval<ConfigProto>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_._has_bits_);
};

void ConfigProto::clear_rpc_options() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.rpc_options_ != nullptr) _impl_.rpc_options_->Clear();
  _impl_._has_bits_[0] &= ~0x00000004u;
}
void ConfigProto::clear_cluster_def() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.cluster_def_ != nullptr) _impl_.cluster_def_->Clear();
  _impl_._has_bits_[0] &= ~0x00000008u;
}
ConfigProto::ConfigProto(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.ConfigProto)
}
inline PROTOBUF_NDEBUG_INLINE ConfigProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::ConfigProto& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        device_count_{visibility, arena, from.device_count_},
        device_filters_{visibility, arena, from.device_filters_},
        session_inter_op_thread_pool_{visibility, arena, from.session_inter_op_thread_pool_} {}

ConfigProto::ConfigProto(
    ::google::protobuf::Arena* arena,
    const ConfigProto& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  ConfigProto* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.gpu_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions>(
                              arena, *from._impl_.gpu_options_)
                        : nullptr;
  _impl_.graph_options_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphOptions>(
                              arena, *from._impl_.graph_options_)
                        : nullptr;
  _impl_.rpc_options_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::RPCOptions>(
                              arena, *from._impl_.rpc_options_)
                        : nullptr;
  _impl_.cluster_def_ = (cached_has_bits & 0x00000008u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::ClusterDef>(
                              arena, *from._impl_.cluster_def_)
                        : nullptr;
  _impl_.experimental_ = (cached_has_bits & 0x00000010u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::ConfigProto_Experimental>(
                              arena, *from._impl_.experimental_)
                        : nullptr;
  _impl_.pluggable_device_options_ = (cached_has_bits & 0x00000020u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions>(
                              arena, *from._impl_.pluggable_device_options_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, intra_op_parallelism_threads_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, intra_op_parallelism_threads_),
           offsetof(Impl_, share_cluster_devices_in_session_) -
               offsetof(Impl_, intra_op_parallelism_threads_) +
               sizeof(Impl_::share_cluster_devices_in_session_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.ConfigProto)
}
inline PROTOBUF_NDEBUG_INLINE ConfigProto::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        device_count_{visibility, arena},
        device_filters_{visibility, arena},
        session_inter_op_thread_pool_{visibility, arena} {}

inline void ConfigProto::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, gpu_options_),
           0,
           offsetof(Impl_, share_cluster_devices_in_session_) -
               offsetof(Impl_, gpu_options_) +
               sizeof(Impl_::share_cluster_devices_in_session_));
}
ConfigProto::~ConfigProto() {
  // @@protoc_insertion_point(destructor:tensorflow.ConfigProto)
  SharedDtor(*this);
}
inline void ConfigProto::SharedDtor(MessageLite& self) {
  ConfigProto& this_ = static_cast<ConfigProto&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.gpu_options_;
  delete this_._impl_.graph_options_;
  delete this_._impl_.rpc_options_;
  delete this_._impl_.cluster_def_;
  delete this_._impl_.experimental_;
  delete this_._impl_.pluggable_device_options_;
  this_._impl_.~Impl_();
}

inline void* ConfigProto::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) ConfigProto(arena);
}
constexpr auto ConfigProto::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_count_) +
          decltype(ConfigProto::_impl_.device_count_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_count_) +
          decltype(ConfigProto::_impl_.device_count_)::
              InternalGetArenaOffsetAlt(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.session_inter_op_thread_pool_) +
          decltype(ConfigProto::_impl_.session_inter_op_thread_pool_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_filters_) +
          decltype(ConfigProto::_impl_.device_filters_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(ConfigProto), alignof(ConfigProto), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&ConfigProto::PlacementNew_,
                                 sizeof(ConfigProto),
                                 alignof(ConfigProto));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull ConfigProto::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_ConfigProto_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &ConfigProto::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<ConfigProto>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &ConfigProto::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<ConfigProto>(), &ConfigProto::ByteSizeLong,
            &ConfigProto::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_._cached_size_),
        false,
    },
    &ConfigProto::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* ConfigProto::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<5, 18, 8, 73, 2> ConfigProto::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_._has_bits_),
    0, // no _extensions_
    18, 248,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294705152,  // skipmap
    offsetof(decltype(_table_), field_entries),
    18,  // num_field_entries
    8,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::ConfigProto>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    // int32 intra_op_parallelism_threads = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ConfigProto, _impl_.intra_op_parallelism_threads_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.intra_op_parallelism_threads_)}},
    // int32 placement_period = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ConfigProto, _impl_.placement_period_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.placement_period_)}},
    // repeated string device_filters = 4;
    {::_pbi::TcParser::FastUR1,
     {34, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_filters_)}},
    // int32 inter_op_parallelism_threads = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(ConfigProto, _impl_.inter_op_parallelism_threads_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.inter_op_parallelism_threads_)}},
    // .tensorflow.GPUOptions gpu_options = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 0, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.gpu_options_)}},
    // bool allow_soft_placement = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto, _impl_.allow_soft_placement_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.allow_soft_placement_)}},
    // bool log_device_placement = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto, _impl_.log_device_placement_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.log_device_placement_)}},
    // bool use_per_session_threads = 9;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto, _impl_.use_per_session_threads_), 63>(),
     {72, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.use_per_session_threads_)}},
    // .tensorflow.GraphOptions graph_options = 10;
    {::_pbi::TcParser::FastMtS1,
     {82, 1, 1, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.graph_options_)}},
    // int64 operation_timeout_in_ms = 11;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(ConfigProto, _impl_.operation_timeout_in_ms_), 63>(),
     {88, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.operation_timeout_in_ms_)}},
    // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
    {::_pbi::TcParser::FastMtR1,
     {98, 63, 2, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.session_inter_op_thread_pool_)}},
    // .tensorflow.RPCOptions rpc_options = 13;
    {::_pbi::TcParser::FastMtS1,
     {106, 2, 3, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.rpc_options_)}},
    // .tensorflow.ClusterDef cluster_def = 14;
    {::_pbi::TcParser::FastMtS1,
     {114, 3, 4, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.cluster_def_)}},
    // bool isolate_session_state = 15;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(ConfigProto, _impl_.isolate_session_state_), 63>(),
     {120, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.isolate_session_state_)}},
    // .tensorflow.ConfigProto.Experimental experimental = 16;
    {::_pbi::TcParser::FastMtS2,
     {386, 4, 5, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.experimental_)}},
    // bool share_cluster_devices_in_session = 17;
    {::_pbi::TcParser::FastV8S2,
     {392, 63, 0, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.share_cluster_devices_in_session_)}},
    // .tensorflow.GPUOptions pluggable_device_options = 18;
    {::_pbi::TcParser::FastMtS2,
     {402, 5, 6, PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.pluggable_device_options_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // map<string, int32> device_count = 1;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_count_), -1, 7,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
    // int32 intra_op_parallelism_threads = 2;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.intra_op_parallelism_threads_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // int32 placement_period = 3;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.placement_period_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // repeated string device_filters = 4;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.device_filters_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // int32 inter_op_parallelism_threads = 5;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.inter_op_parallelism_threads_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // .tensorflow.GPUOptions gpu_options = 6;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.gpu_options_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool allow_soft_placement = 7;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.allow_soft_placement_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool log_device_placement = 8;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.log_device_placement_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // bool use_per_session_threads = 9;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.use_per_session_threads_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.GraphOptions graph_options = 10;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.graph_options_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // int64 operation_timeout_in_ms = 11;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.operation_timeout_in_ms_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.session_inter_op_thread_pool_), -1, 2,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.RPCOptions rpc_options = 13;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.rpc_options_), _Internal::kHasBitsOffset + 2, 3,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.ClusterDef cluster_def = 14;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.cluster_def_), _Internal::kHasBitsOffset + 3, 4,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool isolate_session_state = 15;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.isolate_session_state_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.ConfigProto.Experimental experimental = 16;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.experimental_), _Internal::kHasBitsOffset + 4, 5,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool share_cluster_devices_in_session = 17;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.share_cluster_devices_in_session_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.GPUOptions pluggable_device_options = 18;
    {PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.pluggable_device_options_), _Internal::kHasBitsOffset + 5, 6,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::GPUOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GraphOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::ThreadPoolOptionProto>()},
    {::_pbi::TcParser::GetTable<::tensorflow::RPCOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::ClusterDef>()},
    {::_pbi::TcParser::GetTable<::tensorflow::ConfigProto_Experimental>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GPUOptions>()},
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(ConfigProto()._impl_.device_count_)>(
        1, 0, 0, 9,
        5)},
  }}, {{
    "\26\14\0\0\16\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"
    "tensorflow.ConfigProto"
    "device_count"
    "device_filters"
  }},
};

PROTOBUF_NOINLINE void ConfigProto::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.ConfigProto)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.device_count_.Clear();
  _impl_.device_filters_.Clear();
  _impl_.session_inter_op_thread_pool_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.gpu_options_ != nullptr);
      _impl_.gpu_options_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.graph_options_ != nullptr);
      _impl_.graph_options_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.rpc_options_ != nullptr);
      _impl_.rpc_options_->Clear();
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(_impl_.cluster_def_ != nullptr);
      _impl_.cluster_def_->Clear();
    }
    if (cached_has_bits & 0x00000010u) {
      ABSL_DCHECK(_impl_.experimental_ != nullptr);
      _impl_.experimental_->Clear();
    }
    if (cached_has_bits & 0x00000020u) {
      ABSL_DCHECK(_impl_.pluggable_device_options_ != nullptr);
      _impl_.pluggable_device_options_->Clear();
    }
  }
  ::memset(&_impl_.intra_op_parallelism_threads_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.share_cluster_devices_in_session_) -
      reinterpret_cast<char*>(&_impl_.intra_op_parallelism_threads_)) + sizeof(_impl_.share_cluster_devices_in_session_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* ConfigProto::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const ConfigProto& this_ = static_cast<const ConfigProto&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* ConfigProto::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const ConfigProto& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.ConfigProto)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // map<string, int32> device_count = 1;
          if (!this_._internal_device_count().empty()) {
            using MapType = ::google::protobuf::Map<std::string, ::int32_t>;
            using WireHelper = _pbi::MapEntryFuncs<std::string, ::int32_t,
                                           _pbi::WireFormatLite::TYPE_STRING,
                                           _pbi::WireFormatLite::TYPE_INT32>;
            const auto& field = this_._internal_device_count();

            if (stream->IsSerializationDeterministic() && field.size() > 1) {
              for (const auto& entry : ::google::protobuf::internal::MapSorterPtr<MapType>(field)) {
                target = WireHelper::InternalSerialize(
                    1, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ConfigProto.device_count");
              }
            } else {
              for (const auto& entry : field) {
                target = WireHelper::InternalSerialize(
                    1, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ConfigProto.device_count");
              }
            }
          }

          // int32 intra_op_parallelism_threads = 2;
          if (this_._internal_intra_op_parallelism_threads() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<2>(
                    stream, this_._internal_intra_op_parallelism_threads(), target);
          }

          // int32 placement_period = 3;
          if (this_._internal_placement_period() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<3>(
                    stream, this_._internal_placement_period(), target);
          }

          // repeated string device_filters = 4;
          for (int i = 0, n = this_._internal_device_filters_size(); i < n; ++i) {
            const auto& s = this_._internal_device_filters().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.ConfigProto.device_filters");
            target = stream->WriteString(4, s, target);
          }

          // int32 inter_op_parallelism_threads = 5;
          if (this_._internal_inter_op_parallelism_threads() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<5>(
                    stream, this_._internal_inter_op_parallelism_threads(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.GPUOptions gpu_options = 6;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                6, *this_._impl_.gpu_options_, this_._impl_.gpu_options_->GetCachedSize(), target,
                stream);
          }

          // bool allow_soft_placement = 7;
          if (this_._internal_allow_soft_placement() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                7, this_._internal_allow_soft_placement(), target);
          }

          // bool log_device_placement = 8;
          if (this_._internal_log_device_placement() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                8, this_._internal_log_device_placement(), target);
          }

          // bool use_per_session_threads = 9;
          if (this_._internal_use_per_session_threads() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                9, this_._internal_use_per_session_threads(), target);
          }

          // .tensorflow.GraphOptions graph_options = 10;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                10, *this_._impl_.graph_options_, this_._impl_.graph_options_->GetCachedSize(), target,
                stream);
          }

          // int64 operation_timeout_in_ms = 11;
          if (this_._internal_operation_timeout_in_ms() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<11>(
                    stream, this_._internal_operation_timeout_in_ms(), target);
          }

          // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_session_inter_op_thread_pool_size());
               i < n; i++) {
            const auto& repfield = this_._internal_session_inter_op_thread_pool().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    12, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // .tensorflow.RPCOptions rpc_options = 13;
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                13, *this_._impl_.rpc_options_, this_._impl_.rpc_options_->GetCachedSize(), target,
                stream);
          }

          // .tensorflow.ClusterDef cluster_def = 14;
          if (cached_has_bits & 0x00000008u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                14, *this_._impl_.cluster_def_, this_._impl_.cluster_def_->GetCachedSize(), target,
                stream);
          }

          // bool isolate_session_state = 15;
          if (this_._internal_isolate_session_state() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                15, this_._internal_isolate_session_state(), target);
          }

          // .tensorflow.ConfigProto.Experimental experimental = 16;
          if (cached_has_bits & 0x00000010u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                16, *this_._impl_.experimental_, this_._impl_.experimental_->GetCachedSize(), target,
                stream);
          }

          // bool share_cluster_devices_in_session = 17;
          if (this_._internal_share_cluster_devices_in_session() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                17, this_._internal_share_cluster_devices_in_session(), target);
          }

          // .tensorflow.GPUOptions pluggable_device_options = 18;
          if (cached_has_bits & 0x00000020u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                18, *this_._impl_.pluggable_device_options_, this_._impl_.pluggable_device_options_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.ConfigProto)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t ConfigProto::ByteSizeLong(const MessageLite& base) {
          const ConfigProto& this_ = static_cast<const ConfigProto&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t ConfigProto::ByteSizeLong() const {
          const ConfigProto& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.ConfigProto)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // map<string, int32> device_count = 1;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_device_count_size());
              for (const auto& entry : this_._internal_device_count()) {
                total_size += _pbi::MapEntryFuncs<std::string, ::int32_t,
                                               _pbi::WireFormatLite::TYPE_STRING,
                                               _pbi::WireFormatLite::TYPE_INT32>::ByteSizeLong(entry.first, entry.second);
              }
            }
            // repeated string device_filters = 4;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_device_filters().size());
              for (int i = 0, n = this_._internal_device_filters().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_device_filters().Get(i));
              }
            }
            // repeated .tensorflow.ThreadPoolOptionProto session_inter_op_thread_pool = 12;
            {
              total_size += 1UL * this_._internal_session_inter_op_thread_pool_size();
              for (const auto& msg : this_._internal_session_inter_op_thread_pool()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x0000003fu) {
            // .tensorflow.GPUOptions gpu_options = 6;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.gpu_options_);
            }
            // .tensorflow.GraphOptions graph_options = 10;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.graph_options_);
            }
            // .tensorflow.RPCOptions rpc_options = 13;
            if (cached_has_bits & 0x00000004u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.rpc_options_);
            }
            // .tensorflow.ClusterDef cluster_def = 14;
            if (cached_has_bits & 0x00000008u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.cluster_def_);
            }
            // .tensorflow.ConfigProto.Experimental experimental = 16;
            if (cached_has_bits & 0x00000010u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.experimental_);
            }
            // .tensorflow.GPUOptions pluggable_device_options = 18;
            if (cached_has_bits & 0x00000020u) {
              total_size += 2 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.pluggable_device_options_);
            }
          }
           {
            // int32 intra_op_parallelism_threads = 2;
            if (this_._internal_intra_op_parallelism_threads() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_intra_op_parallelism_threads());
            }
            // int32 placement_period = 3;
            if (this_._internal_placement_period() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_placement_period());
            }
            // int32 inter_op_parallelism_threads = 5;
            if (this_._internal_inter_op_parallelism_threads() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_inter_op_parallelism_threads());
            }
            // bool use_per_session_threads = 9;
            if (this_._internal_use_per_session_threads() != 0) {
              total_size += 2;
            }
            // bool allow_soft_placement = 7;
            if (this_._internal_allow_soft_placement() != 0) {
              total_size += 2;
            }
            // bool log_device_placement = 8;
            if (this_._internal_log_device_placement() != 0) {
              total_size += 2;
            }
            // bool isolate_session_state = 15;
            if (this_._internal_isolate_session_state() != 0) {
              total_size += 2;
            }
            // int64 operation_timeout_in_ms = 11;
            if (this_._internal_operation_timeout_in_ms() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_operation_timeout_in_ms());
            }
            // bool share_cluster_devices_in_session = 17;
            if (this_._internal_share_cluster_devices_in_session() != 0) {
              total_size += 3;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void ConfigProto::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<ConfigProto*>(&to_msg);
  auto& from = static_cast<const ConfigProto&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.ConfigProto)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.device_count_.MergeFrom(from._impl_.device_count_);
  _this->_internal_mutable_device_filters()->MergeFrom(from._internal_device_filters());
  _this->_internal_mutable_session_inter_op_thread_pool()->MergeFrom(
      from._internal_session_inter_op_thread_pool());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x0000003fu) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.gpu_options_ != nullptr);
      if (_this->_impl_.gpu_options_ == nullptr) {
        _this->_impl_.gpu_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions>(arena, *from._impl_.gpu_options_);
      } else {
        _this->_impl_.gpu_options_->MergeFrom(*from._impl_.gpu_options_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.graph_options_ != nullptr);
      if (_this->_impl_.graph_options_ == nullptr) {
        _this->_impl_.graph_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphOptions>(arena, *from._impl_.graph_options_);
      } else {
        _this->_impl_.graph_options_->MergeFrom(*from._impl_.graph_options_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.rpc_options_ != nullptr);
      if (_this->_impl_.rpc_options_ == nullptr) {
        _this->_impl_.rpc_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::RPCOptions>(arena, *from._impl_.rpc_options_);
      } else {
        _this->_impl_.rpc_options_->MergeFrom(*from._impl_.rpc_options_);
      }
    }
    if (cached_has_bits & 0x00000008u) {
      ABSL_DCHECK(from._impl_.cluster_def_ != nullptr);
      if (_this->_impl_.cluster_def_ == nullptr) {
        _this->_impl_.cluster_def_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::ClusterDef>(arena, *from._impl_.cluster_def_);
      } else {
        _this->_impl_.cluster_def_->MergeFrom(*from._impl_.cluster_def_);
      }
    }
    if (cached_has_bits & 0x00000010u) {
      ABSL_DCHECK(from._impl_.experimental_ != nullptr);
      if (_this->_impl_.experimental_ == nullptr) {
        _this->_impl_.experimental_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::ConfigProto_Experimental>(arena, *from._impl_.experimental_);
      } else {
        _this->_impl_.experimental_->MergeFrom(*from._impl_.experimental_);
      }
    }
    if (cached_has_bits & 0x00000020u) {
      ABSL_DCHECK(from._impl_.pluggable_device_options_ != nullptr);
      if (_this->_impl_.pluggable_device_options_ == nullptr) {
        _this->_impl_.pluggable_device_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::GPUOptions>(arena, *from._impl_.pluggable_device_options_);
      } else {
        _this->_impl_.pluggable_device_options_->MergeFrom(*from._impl_.pluggable_device_options_);
      }
    }
  }
  if (from._internal_intra_op_parallelism_threads() != 0) {
    _this->_impl_.intra_op_parallelism_threads_ = from._impl_.intra_op_parallelism_threads_;
  }
  if (from._internal_placement_period() != 0) {
    _this->_impl_.placement_period_ = from._impl_.placement_period_;
  }
  if (from._internal_inter_op_parallelism_threads() != 0) {
    _this->_impl_.inter_op_parallelism_threads_ = from._impl_.inter_op_parallelism_threads_;
  }
  if (from._internal_use_per_session_threads() != 0) {
    _this->_impl_.use_per_session_threads_ = from._impl_.use_per_session_threads_;
  }
  if (from._internal_allow_soft_placement() != 0) {
    _this->_impl_.allow_soft_placement_ = from._impl_.allow_soft_placement_;
  }
  if (from._internal_log_device_placement() != 0) {
    _this->_impl_.log_device_placement_ = from._impl_.log_device_placement_;
  }
  if (from._internal_isolate_session_state() != 0) {
    _this->_impl_.isolate_session_state_ = from._impl_.isolate_session_state_;
  }
  if (from._internal_operation_timeout_in_ms() != 0) {
    _this->_impl_.operation_timeout_in_ms_ = from._impl_.operation_timeout_in_ms_;
  }
  if (from._internal_share_cluster_devices_in_session() != 0) {
    _this->_impl_.share_cluster_devices_in_session_ = from._impl_.share_cluster_devices_in_session_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void ConfigProto::CopyFrom(const ConfigProto& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.ConfigProto)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void ConfigProto::InternalSwap(ConfigProto* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.device_count_.InternalSwap(&other->_impl_.device_count_);
  _impl_.device_filters_.InternalSwap(&other->_impl_.device_filters_);
  _impl_.session_inter_op_thread_pool_.InternalSwap(&other->_impl_.session_inter_op_thread_pool_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.share_cluster_devices_in_session_)
      + sizeof(ConfigProto::_impl_.share_cluster_devices_in_session_)
      - PROTOBUF_FIELD_OFFSET(ConfigProto, _impl_.gpu_options_)>(
          reinterpret_cast<char*>(&_impl_.gpu_options_),
          reinterpret_cast<char*>(&other->_impl_.gpu_options_));
}

::google::protobuf::Metadata ConfigProto::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RunOptions_Experimental_RunHandlerPoolOptions::_Internal {
 public:
};

RunOptions_Experimental_RunHandlerPoolOptions::RunOptions_Experimental_RunHandlerPoolOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
}
RunOptions_Experimental_RunHandlerPoolOptions::RunOptions_Experimental_RunHandlerPoolOptions(
    ::google::protobuf::Arena* arena, const RunOptions_Experimental_RunHandlerPoolOptions& from)
    : RunOptions_Experimental_RunHandlerPoolOptions(arena) {
  MergeFrom(from);
}
inline PROTOBUF_NDEBUG_INLINE RunOptions_Experimental_RunHandlerPoolOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void RunOptions_Experimental_RunHandlerPoolOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  _impl_.priority_ = {};
}
RunOptions_Experimental_RunHandlerPoolOptions::~RunOptions_Experimental_RunHandlerPoolOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
  SharedDtor(*this);
}
inline void RunOptions_Experimental_RunHandlerPoolOptions::SharedDtor(MessageLite& self) {
  RunOptions_Experimental_RunHandlerPoolOptions& this_ = static_cast<RunOptions_Experimental_RunHandlerPoolOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.~Impl_();
}

inline void* RunOptions_Experimental_RunHandlerPoolOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RunOptions_Experimental_RunHandlerPoolOptions(arena);
}
constexpr auto RunOptions_Experimental_RunHandlerPoolOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RunOptions_Experimental_RunHandlerPoolOptions),
                                            alignof(RunOptions_Experimental_RunHandlerPoolOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RunOptions_Experimental_RunHandlerPoolOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RunOptions_Experimental_RunHandlerPoolOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RunOptions_Experimental_RunHandlerPoolOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RunOptions_Experimental_RunHandlerPoolOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RunOptions_Experimental_RunHandlerPoolOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RunOptions_Experimental_RunHandlerPoolOptions>(), &RunOptions_Experimental_RunHandlerPoolOptions::ByteSizeLong,
            &RunOptions_Experimental_RunHandlerPoolOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RunOptions_Experimental_RunHandlerPoolOptions, _impl_._cached_size_),
        false,
    },
    &RunOptions_Experimental_RunHandlerPoolOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RunOptions_Experimental_RunHandlerPoolOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<0, 1, 0, 0, 2> RunOptions_Experimental_RunHandlerPoolOptions::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    1, 0,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967294,  // skipmap
    offsetof(decltype(_table_), field_entries),
    1,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // int64 priority = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(RunOptions_Experimental_RunHandlerPoolOptions, _impl_.priority_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions_Experimental_RunHandlerPoolOptions, _impl_.priority_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int64 priority = 1;
    {PROTOBUF_FIELD_OFFSET(RunOptions_Experimental_RunHandlerPoolOptions, _impl_.priority_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
  }},
  // no aux_entries
  {{
  }},
};

PROTOBUF_NOINLINE void RunOptions_Experimental_RunHandlerPoolOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.priority_ = ::int64_t{0};
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RunOptions_Experimental_RunHandlerPoolOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RunOptions_Experimental_RunHandlerPoolOptions& this_ = static_cast<const RunOptions_Experimental_RunHandlerPoolOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RunOptions_Experimental_RunHandlerPoolOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RunOptions_Experimental_RunHandlerPoolOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int64 priority = 1;
          if (this_._internal_priority() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<1>(
                    stream, this_._internal_priority(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RunOptions_Experimental_RunHandlerPoolOptions::ByteSizeLong(const MessageLite& base) {
          const RunOptions_Experimental_RunHandlerPoolOptions& this_ = static_cast<const RunOptions_Experimental_RunHandlerPoolOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RunOptions_Experimental_RunHandlerPoolOptions::ByteSizeLong() const {
          const RunOptions_Experimental_RunHandlerPoolOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

           {
            // int64 priority = 1;
            if (this_._internal_priority() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_priority());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RunOptions_Experimental_RunHandlerPoolOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RunOptions_Experimental_RunHandlerPoolOptions*>(&to_msg);
  auto& from = static_cast<const RunOptions_Experimental_RunHandlerPoolOptions&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_priority() != 0) {
    _this->_impl_.priority_ = from._impl_.priority_;
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RunOptions_Experimental_RunHandlerPoolOptions::CopyFrom(const RunOptions_Experimental_RunHandlerPoolOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunOptions.Experimental.RunHandlerPoolOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RunOptions_Experimental_RunHandlerPoolOptions::InternalSwap(RunOptions_Experimental_RunHandlerPoolOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
        swap(_impl_.priority_, other->_impl_.priority_);
}

::google::protobuf::Metadata RunOptions_Experimental_RunHandlerPoolOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RunOptions_Experimental::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RunOptions_Experimental>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_._has_bits_);
};

RunOptions_Experimental::RunOptions_Experimental(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunOptions.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE RunOptions_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::RunOptions_Experimental& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

RunOptions_Experimental::RunOptions_Experimental(
    ::google::protobuf::Arena* arena,
    const RunOptions_Experimental& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RunOptions_Experimental* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.run_handler_pool_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions>(
                              arena, *from._impl_.run_handler_pool_options_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, collective_graph_key_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, collective_graph_key_),
           offsetof(Impl_, use_run_handler_pool_) -
               offsetof(Impl_, collective_graph_key_) +
               sizeof(Impl_::use_run_handler_pool_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.RunOptions.Experimental)
}
inline PROTOBUF_NDEBUG_INLINE RunOptions_Experimental::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void RunOptions_Experimental::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, run_handler_pool_options_),
           0,
           offsetof(Impl_, use_run_handler_pool_) -
               offsetof(Impl_, run_handler_pool_options_) +
               sizeof(Impl_::use_run_handler_pool_));
}
RunOptions_Experimental::~RunOptions_Experimental() {
  // @@protoc_insertion_point(destructor:tensorflow.RunOptions.Experimental)
  SharedDtor(*this);
}
inline void RunOptions_Experimental::SharedDtor(MessageLite& self) {
  RunOptions_Experimental& this_ = static_cast<RunOptions_Experimental&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.run_handler_pool_options_;
  this_._impl_.~Impl_();
}

inline void* RunOptions_Experimental::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RunOptions_Experimental(arena);
}
constexpr auto RunOptions_Experimental::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RunOptions_Experimental),
                                            alignof(RunOptions_Experimental));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RunOptions_Experimental::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RunOptions_Experimental_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RunOptions_Experimental::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RunOptions_Experimental>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RunOptions_Experimental::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RunOptions_Experimental>(), &RunOptions_Experimental::ByteSizeLong,
            &RunOptions_Experimental::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_._cached_size_),
        false,
    },
    &RunOptions_Experimental::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RunOptions_Experimental::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 1, 0, 2> RunOptions_Experimental::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_._has_bits_),
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    1,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::RunOptions_Experimental>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // int64 collective_graph_key = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(RunOptions_Experimental, _impl_.collective_graph_key_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.collective_graph_key_)}},
    // bool use_run_handler_pool = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RunOptions_Experimental, _impl_.use_run_handler_pool_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.use_run_handler_pool_)}},
    // .tensorflow.RunOptions.Experimental.RunHandlerPoolOptions run_handler_pool_options = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 0, 0, PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.run_handler_pool_options_)}},
  }}, {{
    65535, 65535
  }}, {{
    // int64 collective_graph_key = 1;
    {PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.collective_graph_key_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // bool use_run_handler_pool = 2;
    {PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.use_run_handler_pool_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.RunOptions.Experimental.RunHandlerPoolOptions run_handler_pool_options = 3;
    {PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.run_handler_pool_options_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RunOptions_Experimental::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunOptions.Experimental)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.run_handler_pool_options_ != nullptr);
    _impl_.run_handler_pool_options_->Clear();
  }
  ::memset(&_impl_.collective_graph_key_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.use_run_handler_pool_) -
      reinterpret_cast<char*>(&_impl_.collective_graph_key_)) + sizeof(_impl_.use_run_handler_pool_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RunOptions_Experimental::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RunOptions_Experimental& this_ = static_cast<const RunOptions_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RunOptions_Experimental::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RunOptions_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunOptions.Experimental)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // int64 collective_graph_key = 1;
          if (this_._internal_collective_graph_key() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<1>(
                    stream, this_._internal_collective_graph_key(), target);
          }

          // bool use_run_handler_pool = 2;
          if (this_._internal_use_run_handler_pool() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                2, this_._internal_use_run_handler_pool(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.RunOptions.Experimental.RunHandlerPoolOptions run_handler_pool_options = 3;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.run_handler_pool_options_, this_._impl_.run_handler_pool_options_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunOptions.Experimental)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RunOptions_Experimental::ByteSizeLong(const MessageLite& base) {
          const RunOptions_Experimental& this_ = static_cast<const RunOptions_Experimental&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RunOptions_Experimental::ByteSizeLong() const {
          const RunOptions_Experimental& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.RunOptions.Experimental)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // .tensorflow.RunOptions.Experimental.RunHandlerPoolOptions run_handler_pool_options = 3;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.run_handler_pool_options_);
            }
          }
           {
            // int64 collective_graph_key = 1;
            if (this_._internal_collective_graph_key() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_collective_graph_key());
            }
            // bool use_run_handler_pool = 2;
            if (this_._internal_use_run_handler_pool() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RunOptions_Experimental::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RunOptions_Experimental*>(&to_msg);
  auto& from = static_cast<const RunOptions_Experimental&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunOptions.Experimental)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.run_handler_pool_options_ != nullptr);
    if (_this->_impl_.run_handler_pool_options_ == nullptr) {
      _this->_impl_.run_handler_pool_options_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions_Experimental_RunHandlerPoolOptions>(arena, *from._impl_.run_handler_pool_options_);
    } else {
      _this->_impl_.run_handler_pool_options_->MergeFrom(*from._impl_.run_handler_pool_options_);
    }
  }
  if (from._internal_collective_graph_key() != 0) {
    _this->_impl_.collective_graph_key_ = from._impl_.collective_graph_key_;
  }
  if (from._internal_use_run_handler_pool() != 0) {
    _this->_impl_.use_run_handler_pool_ = from._impl_.use_run_handler_pool_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RunOptions_Experimental::CopyFrom(const RunOptions_Experimental& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunOptions.Experimental)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RunOptions_Experimental::InternalSwap(RunOptions_Experimental* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.use_run_handler_pool_)
      + sizeof(RunOptions_Experimental::_impl_.use_run_handler_pool_)
      - PROTOBUF_FIELD_OFFSET(RunOptions_Experimental, _impl_.run_handler_pool_options_)>(
          reinterpret_cast<char*>(&_impl_.run_handler_pool_options_),
          reinterpret_cast<char*>(&other->_impl_.run_handler_pool_options_));
}

::google::protobuf::Metadata RunOptions_Experimental::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RunOptions::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RunOptions>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RunOptions, _impl_._has_bits_);
};

void RunOptions::clear_debug_options() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.debug_options_ != nullptr) _impl_.debug_options_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
RunOptions::RunOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunOptions)
}
inline PROTOBUF_NDEBUG_INLINE RunOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::RunOptions& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0} {}

RunOptions::RunOptions(
    ::google::protobuf::Arena* arena,
    const RunOptions& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RunOptions* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.debug_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::DebugOptions>(
                              arena, *from._impl_.debug_options_)
                        : nullptr;
  _impl_.experimental_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions_Experimental>(
                              arena, *from._impl_.experimental_)
                        : nullptr;
  ::memcpy(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, timeout_in_ms_),
           reinterpret_cast<const char *>(&from._impl_) +
               offsetof(Impl_, timeout_in_ms_),
           offsetof(Impl_, report_tensor_allocations_upon_oom_) -
               offsetof(Impl_, timeout_in_ms_) +
               sizeof(Impl_::report_tensor_allocations_upon_oom_));

  // @@protoc_insertion_point(copy_constructor:tensorflow.RunOptions)
}
inline PROTOBUF_NDEBUG_INLINE RunOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0} {}

inline void RunOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, debug_options_),
           0,
           offsetof(Impl_, report_tensor_allocations_upon_oom_) -
               offsetof(Impl_, debug_options_) +
               sizeof(Impl_::report_tensor_allocations_upon_oom_));
}
RunOptions::~RunOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.RunOptions)
  SharedDtor(*this);
}
inline void RunOptions::SharedDtor(MessageLite& self) {
  RunOptions& this_ = static_cast<RunOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.debug_options_;
  delete this_._impl_.experimental_;
  this_._impl_.~Impl_();
}

inline void* RunOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RunOptions(arena);
}
constexpr auto RunOptions::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::ZeroInit(sizeof(RunOptions),
                                            alignof(RunOptions));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RunOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RunOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RunOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RunOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RunOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RunOptions>(), &RunOptions::ByteSizeLong,
            &RunOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RunOptions, _impl_._cached_size_),
        false,
    },
    &RunOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RunOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 7, 2, 0, 2> RunOptions::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RunOptions, _impl_._has_bits_),
    0, // no _extensions_
    8, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967048,  // skipmap
    offsetof(decltype(_table_), field_entries),
    7,  // num_field_entries
    2,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::RunOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // .tensorflow.RunOptions.Experimental experimental = 8;
    {::_pbi::TcParser::FastMtS1,
     {66, 1, 1, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.experimental_)}},
    // .tensorflow.RunOptions.TraceLevel trace_level = 1;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RunOptions, _impl_.trace_level_), 63>(),
     {8, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.trace_level_)}},
    // int64 timeout_in_ms = 2;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint64_t, offsetof(RunOptions, _impl_.timeout_in_ms_), 63>(),
     {16, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.timeout_in_ms_)}},
    // int32 inter_op_thread_pool = 3;
    {::_pbi::TcParser::SingularVarintNoZag1<::uint32_t, offsetof(RunOptions, _impl_.inter_op_thread_pool_), 63>(),
     {24, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.inter_op_thread_pool_)}},
    {::_pbi::TcParser::MiniParse, {}},
    // bool output_partition_graphs = 5;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RunOptions, _impl_.output_partition_graphs_), 63>(),
     {40, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.output_partition_graphs_)}},
    // .tensorflow.DebugOptions debug_options = 6;
    {::_pbi::TcParser::FastMtS1,
     {50, 0, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.debug_options_)}},
    // bool report_tensor_allocations_upon_oom = 7;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(RunOptions, _impl_.report_tensor_allocations_upon_oom_), 63>(),
     {56, 63, 0, PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.report_tensor_allocations_upon_oom_)}},
  }}, {{
    65535, 65535
  }}, {{
    // .tensorflow.RunOptions.TraceLevel trace_level = 1;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.trace_level_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kOpenEnum)},
    // int64 timeout_in_ms = 2;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.timeout_in_ms_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt64)},
    // int32 inter_op_thread_pool = 3;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.inter_op_thread_pool_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kInt32)},
    // bool output_partition_graphs = 5;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.output_partition_graphs_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.DebugOptions debug_options = 6;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.debug_options_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // bool report_tensor_allocations_upon_oom = 7;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.report_tensor_allocations_upon_oom_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
    // .tensorflow.RunOptions.Experimental experimental = 8;
    {PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.experimental_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::DebugOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::RunOptions_Experimental>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RunOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.debug_options_ != nullptr);
      _impl_.debug_options_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.experimental_ != nullptr);
      _impl_.experimental_->Clear();
    }
  }
  ::memset(&_impl_.timeout_in_ms_, 0, static_cast<::size_t>(
      reinterpret_cast<char*>(&_impl_.report_tensor_allocations_upon_oom_) -
      reinterpret_cast<char*>(&_impl_.timeout_in_ms_)) + sizeof(_impl_.report_tensor_allocations_upon_oom_));
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RunOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RunOptions& this_ = static_cast<const RunOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RunOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RunOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // .tensorflow.RunOptions.TraceLevel trace_level = 1;
          if (this_._internal_trace_level() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteEnumToArray(
                1, this_._internal_trace_level(), target);
          }

          // int64 timeout_in_ms = 2;
          if (this_._internal_timeout_in_ms() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt64ToArrayWithField<2>(
                    stream, this_._internal_timeout_in_ms(), target);
          }

          // int32 inter_op_thread_pool = 3;
          if (this_._internal_inter_op_thread_pool() != 0) {
            target = ::google::protobuf::internal::WireFormatLite::
                WriteInt32ToArrayWithField<3>(
                    stream, this_._internal_inter_op_thread_pool(), target);
          }

          // bool output_partition_graphs = 5;
          if (this_._internal_output_partition_graphs() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                5, this_._internal_output_partition_graphs(), target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.DebugOptions debug_options = 6;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                6, *this_._impl_.debug_options_, this_._impl_.debug_options_->GetCachedSize(), target,
                stream);
          }

          // bool report_tensor_allocations_upon_oom = 7;
          if (this_._internal_report_tensor_allocations_upon_oom() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                7, this_._internal_report_tensor_allocations_upon_oom(), target);
          }

          // .tensorflow.RunOptions.Experimental experimental = 8;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                8, *this_._impl_.experimental_, this_._impl_.experimental_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RunOptions::ByteSizeLong(const MessageLite& base) {
          const RunOptions& this_ = static_cast<const RunOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RunOptions::ByteSizeLong() const {
          const RunOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.RunOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .tensorflow.DebugOptions debug_options = 6;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.debug_options_);
            }
            // .tensorflow.RunOptions.Experimental experimental = 8;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.experimental_);
            }
          }
           {
            // int64 timeout_in_ms = 2;
            if (this_._internal_timeout_in_ms() != 0) {
              total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(
                  this_._internal_timeout_in_ms());
            }
            // .tensorflow.RunOptions.TraceLevel trace_level = 1;
            if (this_._internal_trace_level() != 0) {
              total_size += 1 +
                            ::_pbi::WireFormatLite::EnumSize(this_._internal_trace_level());
            }
            // int32 inter_op_thread_pool = 3;
            if (this_._internal_inter_op_thread_pool() != 0) {
              total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(
                  this_._internal_inter_op_thread_pool());
            }
            // bool output_partition_graphs = 5;
            if (this_._internal_output_partition_graphs() != 0) {
              total_size += 2;
            }
            // bool report_tensor_allocations_upon_oom = 7;
            if (this_._internal_report_tensor_allocations_upon_oom() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RunOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RunOptions*>(&to_msg);
  auto& from = static_cast<const RunOptions&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.debug_options_ != nullptr);
      if (_this->_impl_.debug_options_ == nullptr) {
        _this->_impl_.debug_options_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::DebugOptions>(arena, *from._impl_.debug_options_);
      } else {
        _this->_impl_.debug_options_->MergeFrom(*from._impl_.debug_options_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.experimental_ != nullptr);
      if (_this->_impl_.experimental_ == nullptr) {
        _this->_impl_.experimental_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions_Experimental>(arena, *from._impl_.experimental_);
      } else {
        _this->_impl_.experimental_->MergeFrom(*from._impl_.experimental_);
      }
    }
  }
  if (from._internal_timeout_in_ms() != 0) {
    _this->_impl_.timeout_in_ms_ = from._impl_.timeout_in_ms_;
  }
  if (from._internal_trace_level() != 0) {
    _this->_impl_.trace_level_ = from._impl_.trace_level_;
  }
  if (from._internal_inter_op_thread_pool() != 0) {
    _this->_impl_.inter_op_thread_pool_ = from._impl_.inter_op_thread_pool_;
  }
  if (from._internal_output_partition_graphs() != 0) {
    _this->_impl_.output_partition_graphs_ = from._impl_.output_partition_graphs_;
  }
  if (from._internal_report_tensor_allocations_upon_oom() != 0) {
    _this->_impl_.report_tensor_allocations_upon_oom_ = from._impl_.report_tensor_allocations_upon_oom_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RunOptions::CopyFrom(const RunOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RunOptions::InternalSwap(RunOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.report_tensor_allocations_upon_oom_)
      + sizeof(RunOptions::_impl_.report_tensor_allocations_upon_oom_)
      - PROTOBUF_FIELD_OFFSET(RunOptions, _impl_.debug_options_)>(
          reinterpret_cast<char*>(&_impl_.debug_options_),
          reinterpret_cast<char*>(&other->_impl_.debug_options_));
}

::google::protobuf::Metadata RunOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RunMetadata_FunctionGraphs::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RunMetadata_FunctionGraphs>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_._has_bits_);
};

void RunMetadata_FunctionGraphs::clear_partition_graphs() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.partition_graphs_.Clear();
}
void RunMetadata_FunctionGraphs::clear_pre_optimization_graph() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.pre_optimization_graph_ != nullptr) _impl_.pre_optimization_graph_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void RunMetadata_FunctionGraphs::clear_post_optimization_graph() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.post_optimization_graph_ != nullptr) _impl_.post_optimization_graph_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
RunMetadata_FunctionGraphs::RunMetadata_FunctionGraphs(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunMetadata.FunctionGraphs)
}
inline PROTOBUF_NDEBUG_INLINE RunMetadata_FunctionGraphs::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::RunMetadata_FunctionGraphs& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        partition_graphs_{visibility, arena, from.partition_graphs_} {}

RunMetadata_FunctionGraphs::RunMetadata_FunctionGraphs(
    ::google::protobuf::Arena* arena,
    const RunMetadata_FunctionGraphs& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RunMetadata_FunctionGraphs* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.pre_optimization_graph_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphDef>(
                              arena, *from._impl_.pre_optimization_graph_)
                        : nullptr;
  _impl_.post_optimization_graph_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphDef>(
                              arena, *from._impl_.post_optimization_graph_)
                        : nullptr;

  // @@protoc_insertion_point(copy_constructor:tensorflow.RunMetadata.FunctionGraphs)
}
inline PROTOBUF_NDEBUG_INLINE RunMetadata_FunctionGraphs::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        partition_graphs_{visibility, arena} {}

inline void RunMetadata_FunctionGraphs::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, pre_optimization_graph_),
           0,
           offsetof(Impl_, post_optimization_graph_) -
               offsetof(Impl_, pre_optimization_graph_) +
               sizeof(Impl_::post_optimization_graph_));
}
RunMetadata_FunctionGraphs::~RunMetadata_FunctionGraphs() {
  // @@protoc_insertion_point(destructor:tensorflow.RunMetadata.FunctionGraphs)
  SharedDtor(*this);
}
inline void RunMetadata_FunctionGraphs::SharedDtor(MessageLite& self) {
  RunMetadata_FunctionGraphs& this_ = static_cast<RunMetadata_FunctionGraphs&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.pre_optimization_graph_;
  delete this_._impl_.post_optimization_graph_;
  this_._impl_.~Impl_();
}

inline void* RunMetadata_FunctionGraphs::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RunMetadata_FunctionGraphs(arena);
}
constexpr auto RunMetadata_FunctionGraphs::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.partition_graphs_) +
          decltype(RunMetadata_FunctionGraphs::_impl_.partition_graphs_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(RunMetadata_FunctionGraphs), alignof(RunMetadata_FunctionGraphs), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RunMetadata_FunctionGraphs::PlacementNew_,
                                 sizeof(RunMetadata_FunctionGraphs),
                                 alignof(RunMetadata_FunctionGraphs));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RunMetadata_FunctionGraphs::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RunMetadata_FunctionGraphs_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RunMetadata_FunctionGraphs::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RunMetadata_FunctionGraphs>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RunMetadata_FunctionGraphs::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RunMetadata_FunctionGraphs>(), &RunMetadata_FunctionGraphs::ByteSizeLong,
            &RunMetadata_FunctionGraphs::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_._cached_size_),
        false,
    },
    &RunMetadata_FunctionGraphs::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RunMetadata_FunctionGraphs::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<2, 3, 3, 0, 2> RunMetadata_FunctionGraphs::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_._has_bits_),
    0, // no _extensions_
    3, 24,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967288,  // skipmap
    offsetof(decltype(_table_), field_entries),
    3,  // num_field_entries
    3,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::RunMetadata_FunctionGraphs>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // repeated .tensorflow.GraphDef partition_graphs = 1;
    {::_pbi::TcParser::FastMtR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.partition_graphs_)}},
    // .tensorflow.GraphDef pre_optimization_graph = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 0, 1, PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.pre_optimization_graph_)}},
    // .tensorflow.GraphDef post_optimization_graph = 3;
    {::_pbi::TcParser::FastMtS1,
     {26, 1, 2, PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.post_optimization_graph_)}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated .tensorflow.GraphDef partition_graphs = 1;
    {PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.partition_graphs_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.GraphDef pre_optimization_graph = 2;
    {PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.pre_optimization_graph_), _Internal::kHasBitsOffset + 0, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.GraphDef post_optimization_graph = 3;
    {PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.post_optimization_graph_), _Internal::kHasBitsOffset + 1, 2,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::GraphDef>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GraphDef>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GraphDef>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RunMetadata_FunctionGraphs::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunMetadata.FunctionGraphs)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.partition_graphs_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.pre_optimization_graph_ != nullptr);
      _impl_.pre_optimization_graph_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.post_optimization_graph_ != nullptr);
      _impl_.post_optimization_graph_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RunMetadata_FunctionGraphs::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RunMetadata_FunctionGraphs& this_ = static_cast<const RunMetadata_FunctionGraphs&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RunMetadata_FunctionGraphs::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RunMetadata_FunctionGraphs& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunMetadata.FunctionGraphs)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated .tensorflow.GraphDef partition_graphs = 1;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_partition_graphs_size());
               i < n; i++) {
            const auto& repfield = this_._internal_partition_graphs().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    1, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.GraphDef pre_optimization_graph = 2;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.pre_optimization_graph_, this_._impl_.pre_optimization_graph_->GetCachedSize(), target,
                stream);
          }

          // .tensorflow.GraphDef post_optimization_graph = 3;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                3, *this_._impl_.post_optimization_graph_, this_._impl_.post_optimization_graph_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunMetadata.FunctionGraphs)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RunMetadata_FunctionGraphs::ByteSizeLong(const MessageLite& base) {
          const RunMetadata_FunctionGraphs& this_ = static_cast<const RunMetadata_FunctionGraphs&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RunMetadata_FunctionGraphs::ByteSizeLong() const {
          const RunMetadata_FunctionGraphs& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.RunMetadata.FunctionGraphs)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.GraphDef partition_graphs = 1;
            {
              total_size += 1UL * this_._internal_partition_graphs_size();
              for (const auto& msg : this_._internal_partition_graphs()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000003u) {
            // .tensorflow.GraphDef pre_optimization_graph = 2;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.pre_optimization_graph_);
            }
            // .tensorflow.GraphDef post_optimization_graph = 3;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.post_optimization_graph_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RunMetadata_FunctionGraphs::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RunMetadata_FunctionGraphs*>(&to_msg);
  auto& from = static_cast<const RunMetadata_FunctionGraphs&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunMetadata.FunctionGraphs)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_partition_graphs()->MergeFrom(
      from._internal_partition_graphs());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.pre_optimization_graph_ != nullptr);
      if (_this->_impl_.pre_optimization_graph_ == nullptr) {
        _this->_impl_.pre_optimization_graph_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphDef>(arena, *from._impl_.pre_optimization_graph_);
      } else {
        _this->_impl_.pre_optimization_graph_->MergeFrom(*from._impl_.pre_optimization_graph_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.post_optimization_graph_ != nullptr);
      if (_this->_impl_.post_optimization_graph_ == nullptr) {
        _this->_impl_.post_optimization_graph_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::GraphDef>(arena, *from._impl_.post_optimization_graph_);
      } else {
        _this->_impl_.post_optimization_graph_->MergeFrom(*from._impl_.post_optimization_graph_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RunMetadata_FunctionGraphs::CopyFrom(const RunMetadata_FunctionGraphs& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunMetadata.FunctionGraphs)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RunMetadata_FunctionGraphs::InternalSwap(RunMetadata_FunctionGraphs* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.partition_graphs_.InternalSwap(&other->_impl_.partition_graphs_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.post_optimization_graph_)
      + sizeof(RunMetadata_FunctionGraphs::_impl_.post_optimization_graph_)
      - PROTOBUF_FIELD_OFFSET(RunMetadata_FunctionGraphs, _impl_.pre_optimization_graph_)>(
          reinterpret_cast<char*>(&_impl_.pre_optimization_graph_),
          reinterpret_cast<char*>(&other->_impl_.pre_optimization_graph_));
}

::google::protobuf::Metadata RunMetadata_FunctionGraphs::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class RunMetadata::_Internal {
 public:
  using HasBits =
      decltype(std::declval<RunMetadata>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_._has_bits_);
};

void RunMetadata::clear_step_stats() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.step_stats_ != nullptr) _impl_.step_stats_->Clear();
  _impl_._has_bits_[0] &= ~0x00000001u;
}
void RunMetadata::clear_cost_graph() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.cost_graph_ != nullptr) _impl_.cost_graph_->Clear();
  _impl_._has_bits_[0] &= ~0x00000002u;
}
void RunMetadata::clear_partition_graphs() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  _impl_.partition_graphs_.Clear();
}
RunMetadata::RunMetadata(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.RunMetadata)
}
inline PROTOBUF_NDEBUG_INLINE RunMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::RunMetadata& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        partition_graphs_{visibility, arena, from.partition_graphs_},
        function_graphs_{visibility, arena, from.function_graphs_} {}

RunMetadata::RunMetadata(
    ::google::protobuf::Arena* arena,
    const RunMetadata& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  RunMetadata* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.step_stats_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::StepStats>(
                              arena, *from._impl_.step_stats_)
                        : nullptr;
  _impl_.cost_graph_ = (cached_has_bits & 0x00000002u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::CostGraphDef>(
                              arena, *from._impl_.cost_graph_)
                        : nullptr;
  _impl_.session_metadata_ = (cached_has_bits & 0x00000004u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::SessionMetadata>(
                              arena, *from._impl_.session_metadata_)
                        : nullptr;

  // @@protoc_insertion_point(copy_constructor:tensorflow.RunMetadata)
}
inline PROTOBUF_NDEBUG_INLINE RunMetadata::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        partition_graphs_{visibility, arena},
        function_graphs_{visibility, arena} {}

inline void RunMetadata::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, step_stats_),
           0,
           offsetof(Impl_, session_metadata_) -
               offsetof(Impl_, step_stats_) +
               sizeof(Impl_::session_metadata_));
}
RunMetadata::~RunMetadata() {
  // @@protoc_insertion_point(destructor:tensorflow.RunMetadata)
  SharedDtor(*this);
}
inline void RunMetadata::SharedDtor(MessageLite& self) {
  RunMetadata& this_ = static_cast<RunMetadata&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.step_stats_;
  delete this_._impl_.cost_graph_;
  delete this_._impl_.session_metadata_;
  this_._impl_.~Impl_();
}

inline void* RunMetadata::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) RunMetadata(arena);
}
constexpr auto RunMetadata::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.partition_graphs_) +
          decltype(RunMetadata::_impl_.partition_graphs_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.function_graphs_) +
          decltype(RunMetadata::_impl_.function_graphs_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::ZeroInit(
        sizeof(RunMetadata), alignof(RunMetadata), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&RunMetadata::PlacementNew_,
                                 sizeof(RunMetadata),
                                 alignof(RunMetadata));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull RunMetadata::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_RunMetadata_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &RunMetadata::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<RunMetadata>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &RunMetadata::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<RunMetadata>(), &RunMetadata::ByteSizeLong,
            &RunMetadata::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_._cached_size_),
        false,
    },
    &RunMetadata::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* RunMetadata::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 5, 5, 0, 2> RunMetadata::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_._has_bits_),
    0, // no _extensions_
    5, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967264,  // skipmap
    offsetof(decltype(_table_), field_entries),
    5,  // num_field_entries
    5,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::RunMetadata>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    {::_pbi::TcParser::MiniParse, {}},
    // .tensorflow.StepStats step_stats = 1;
    {::_pbi::TcParser::FastMtS1,
     {10, 0, 0, PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.step_stats_)}},
    // .tensorflow.CostGraphDef cost_graph = 2;
    {::_pbi::TcParser::FastMtS1,
     {18, 1, 1, PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.cost_graph_)}},
    // repeated .tensorflow.GraphDef partition_graphs = 3;
    {::_pbi::TcParser::FastMtR1,
     {26, 63, 2, PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.partition_graphs_)}},
    // repeated .tensorflow.RunMetadata.FunctionGraphs function_graphs = 4;
    {::_pbi::TcParser::FastMtR1,
     {34, 63, 3, PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.function_graphs_)}},
    // .tensorflow.SessionMetadata session_metadata = 5;
    {::_pbi::TcParser::FastMtS1,
     {42, 2, 4, PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.session_metadata_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // .tensorflow.StepStats step_stats = 1;
    {PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.step_stats_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.CostGraphDef cost_graph = 2;
    {PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.cost_graph_), _Internal::kHasBitsOffset + 1, 1,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .tensorflow.GraphDef partition_graphs = 3;
    {PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.partition_graphs_), -1, 2,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .tensorflow.RunMetadata.FunctionGraphs function_graphs = 4;
    {PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.function_graphs_), -1, 3,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // .tensorflow.SessionMetadata session_metadata = 5;
    {PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.session_metadata_), _Internal::kHasBitsOffset + 2, 4,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::StepStats>()},
    {::_pbi::TcParser::GetTable<::tensorflow::CostGraphDef>()},
    {::_pbi::TcParser::GetTable<::tensorflow::GraphDef>()},
    {::_pbi::TcParser::GetTable<::tensorflow::RunMetadata_FunctionGraphs>()},
    {::_pbi::TcParser::GetTable<::tensorflow::SessionMetadata>()},
  }}, {{
  }},
};

PROTOBUF_NOINLINE void RunMetadata::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.RunMetadata)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.partition_graphs_.Clear();
  _impl_.function_graphs_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(_impl_.step_stats_ != nullptr);
      _impl_.step_stats_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(_impl_.cost_graph_ != nullptr);
      _impl_.cost_graph_->Clear();
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(_impl_.session_metadata_ != nullptr);
      _impl_.session_metadata_->Clear();
    }
  }
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* RunMetadata::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const RunMetadata& this_ = static_cast<const RunMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* RunMetadata::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const RunMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.RunMetadata)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.StepStats step_stats = 1;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                1, *this_._impl_.step_stats_, this_._impl_.step_stats_->GetCachedSize(), target,
                stream);
          }

          // .tensorflow.CostGraphDef cost_graph = 2;
          if (cached_has_bits & 0x00000002u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                2, *this_._impl_.cost_graph_, this_._impl_.cost_graph_->GetCachedSize(), target,
                stream);
          }

          // repeated .tensorflow.GraphDef partition_graphs = 3;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_partition_graphs_size());
               i < n; i++) {
            const auto& repfield = this_._internal_partition_graphs().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    3, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // repeated .tensorflow.RunMetadata.FunctionGraphs function_graphs = 4;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_function_graphs_size());
               i < n; i++) {
            const auto& repfield = this_._internal_function_graphs().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    4, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // .tensorflow.SessionMetadata session_metadata = 5;
          if (cached_has_bits & 0x00000004u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                5, *this_._impl_.session_metadata_, this_._impl_.session_metadata_->GetCachedSize(), target,
                stream);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.RunMetadata)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t RunMetadata::ByteSizeLong(const MessageLite& base) {
          const RunMetadata& this_ = static_cast<const RunMetadata&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t RunMetadata::ByteSizeLong() const {
          const RunMetadata& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.RunMetadata)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated .tensorflow.GraphDef partition_graphs = 3;
            {
              total_size += 1UL * this_._internal_partition_graphs_size();
              for (const auto& msg : this_._internal_partition_graphs()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // repeated .tensorflow.RunMetadata.FunctionGraphs function_graphs = 4;
            {
              total_size += 1UL * this_._internal_function_graphs_size();
              for (const auto& msg : this_._internal_function_graphs()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
          }
          cached_has_bits = this_._impl_._has_bits_[0];
          if (cached_has_bits & 0x00000007u) {
            // .tensorflow.StepStats step_stats = 1;
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.step_stats_);
            }
            // .tensorflow.CostGraphDef cost_graph = 2;
            if (cached_has_bits & 0x00000002u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.cost_graph_);
            }
            // .tensorflow.SessionMetadata session_metadata = 5;
            if (cached_has_bits & 0x00000004u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.session_metadata_);
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void RunMetadata::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<RunMetadata*>(&to_msg);
  auto& from = static_cast<const RunMetadata&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.RunMetadata)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_partition_graphs()->MergeFrom(
      from._internal_partition_graphs());
  _this->_internal_mutable_function_graphs()->MergeFrom(
      from._internal_function_graphs());
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      ABSL_DCHECK(from._impl_.step_stats_ != nullptr);
      if (_this->_impl_.step_stats_ == nullptr) {
        _this->_impl_.step_stats_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::StepStats>(arena, *from._impl_.step_stats_);
      } else {
        _this->_impl_.step_stats_->MergeFrom(*from._impl_.step_stats_);
      }
    }
    if (cached_has_bits & 0x00000002u) {
      ABSL_DCHECK(from._impl_.cost_graph_ != nullptr);
      if (_this->_impl_.cost_graph_ == nullptr) {
        _this->_impl_.cost_graph_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::CostGraphDef>(arena, *from._impl_.cost_graph_);
      } else {
        _this->_impl_.cost_graph_->MergeFrom(*from._impl_.cost_graph_);
      }
    }
    if (cached_has_bits & 0x00000004u) {
      ABSL_DCHECK(from._impl_.session_metadata_ != nullptr);
      if (_this->_impl_.session_metadata_ == nullptr) {
        _this->_impl_.session_metadata_ =
            ::google::protobuf::Message::CopyConstruct<::tensorflow::SessionMetadata>(arena, *from._impl_.session_metadata_);
      } else {
        _this->_impl_.session_metadata_->MergeFrom(*from._impl_.session_metadata_);
      }
    }
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void RunMetadata::CopyFrom(const RunMetadata& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.RunMetadata)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void RunMetadata::InternalSwap(RunMetadata* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.partition_graphs_.InternalSwap(&other->_impl_.partition_graphs_);
  _impl_.function_graphs_.InternalSwap(&other->_impl_.function_graphs_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.session_metadata_)
      + sizeof(RunMetadata::_impl_.session_metadata_)
      - PROTOBUF_FIELD_OFFSET(RunMetadata, _impl_.step_stats_)>(
          reinterpret_cast<char*>(&_impl_.step_stats_),
          reinterpret_cast<char*>(&other->_impl_.step_stats_));
}

::google::protobuf::Metadata RunMetadata::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

class TensorConnection::_Internal {
 public:
};

TensorConnection::TensorConnection(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.TensorConnection)
}
inline PROTOBUF_NDEBUG_INLINE TensorConnection::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::TensorConnection& from_msg)
      : from_tensor_(arena, from.from_tensor_),
        to_tensor_(arena, from.to_tensor_),
        _cached_size_{0} {}

TensorConnection::TensorConnection(
    ::google::protobuf::Arena* arena,
    const TensorConnection& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  TensorConnection* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);

  // @@protoc_insertion_point(copy_constructor:tensorflow.TensorConnection)
}
inline PROTOBUF_NDEBUG_INLINE TensorConnection::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : from_tensor_(arena),
        to_tensor_(arena),
        _cached_size_{0} {}

inline void TensorConnection::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
}
TensorConnection::~TensorConnection() {
  // @@protoc_insertion_point(destructor:tensorflow.TensorConnection)
  SharedDtor(*this);
}
inline void TensorConnection::SharedDtor(MessageLite& self) {
  TensorConnection& this_ = static_cast<TensorConnection&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  this_._impl_.from_tensor_.Destroy();
  this_._impl_.to_tensor_.Destroy();
  this_._impl_.~Impl_();
}

inline void* TensorConnection::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) TensorConnection(arena);
}
constexpr auto TensorConnection::InternalNewImpl_() {
  return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(TensorConnection),
                                            alignof(TensorConnection));
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull TensorConnection::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_TensorConnection_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &TensorConnection::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<TensorConnection>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &TensorConnection::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<TensorConnection>(), &TensorConnection::ByteSizeLong,
            &TensorConnection::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(TensorConnection, _impl_._cached_size_),
        false,
    },
    &TensorConnection::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* TensorConnection::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 56, 2> TensorConnection::_table_ = {
  {
    0,  // no _has_bits_
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::TensorConnection>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string to_tensor = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(TensorConnection, _impl_.to_tensor_)}},
    // string from_tensor = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(TensorConnection, _impl_.from_tensor_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string from_tensor = 1;
    {PROTOBUF_FIELD_OFFSET(TensorConnection, _impl_.from_tensor_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string to_tensor = 2;
    {PROTOBUF_FIELD_OFFSET(TensorConnection, _impl_.to_tensor_), 0, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\33\13\11\0\0\0\0\0"
    "tensorflow.TensorConnection"
    "from_tensor"
    "to_tensor"
  }},
};

PROTOBUF_NOINLINE void TensorConnection::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.TensorConnection)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.from_tensor_.ClearToEmpty();
  _impl_.to_tensor_.ClearToEmpty();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* TensorConnection::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const TensorConnection& this_ = static_cast<const TensorConnection&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* TensorConnection::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const TensorConnection& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.TensorConnection)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // string from_tensor = 1;
          if (!this_._internal_from_tensor().empty()) {
            const std::string& _s = this_._internal_from_tensor();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.TensorConnection.from_tensor");
            target = stream->WriteStringMaybeAliased(1, _s, target);
          }

          // string to_tensor = 2;
          if (!this_._internal_to_tensor().empty()) {
            const std::string& _s = this_._internal_to_tensor();
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                _s.data(), static_cast<int>(_s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.TensorConnection.to_tensor");
            target = stream->WriteStringMaybeAliased(2, _s, target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.TensorConnection)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t TensorConnection::ByteSizeLong(const MessageLite& base) {
          const TensorConnection& this_ = static_cast<const TensorConnection&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t TensorConnection::ByteSizeLong() const {
          const TensorConnection& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.TensorConnection)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // string from_tensor = 1;
            if (!this_._internal_from_tensor().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_from_tensor());
            }
            // string to_tensor = 2;
            if (!this_._internal_to_tensor().empty()) {
              total_size += 1 + ::google::protobuf::internal::WireFormatLite::StringSize(
                                              this_._internal_to_tensor());
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void TensorConnection::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<TensorConnection*>(&to_msg);
  auto& from = static_cast<const TensorConnection&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.TensorConnection)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (!from._internal_from_tensor().empty()) {
    _this->_internal_set_from_tensor(from._internal_from_tensor());
  }
  if (!from._internal_to_tensor().empty()) {
    _this->_internal_set_to_tensor(from._internal_to_tensor());
  }
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void TensorConnection::CopyFrom(const TensorConnection& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.TensorConnection)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void TensorConnection::InternalSwap(TensorConnection* PROTOBUF_RESTRICT other) {
  using std::swap;
  auto* arena = GetArena();
  ABSL_DCHECK_EQ(arena, other->GetArena());
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.from_tensor_, &other->_impl_.from_tensor_, arena);
  ::_pbi::ArenaStringPtr::InternalSwap(&_impl_.to_tensor_, &other->_impl_.to_tensor_, arena);
}

::google::protobuf::Metadata TensorConnection::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// ===================================================================

#if defined(PROTOBUF_CUSTOM_VTABLE)
              CallableOptions_FeedDevicesEntry_DoNotUse::CallableOptions_FeedDevicesEntry_DoNotUse() : SuperType(_class_data_.base()) {}
              CallableOptions_FeedDevicesEntry_DoNotUse::CallableOptions_FeedDevicesEntry_DoNotUse(::google::protobuf::Arena* arena)
                  : SuperType(arena, _class_data_.base()) {}
#else   // PROTOBUF_CUSTOM_VTABLE
              CallableOptions_FeedDevicesEntry_DoNotUse::CallableOptions_FeedDevicesEntry_DoNotUse() : SuperType() {}
              CallableOptions_FeedDevicesEntry_DoNotUse::CallableOptions_FeedDevicesEntry_DoNotUse(::google::protobuf::Arena* arena) : SuperType(arena) {}
#endif  // PROTOBUF_CUSTOM_VTABLE
              inline void* CallableOptions_FeedDevicesEntry_DoNotUse::PlacementNew_(const void*, void* mem,
                                                      ::google::protobuf::Arena* arena) {
                return ::new (mem) CallableOptions_FeedDevicesEntry_DoNotUse(arena);
              }
              constexpr auto CallableOptions_FeedDevicesEntry_DoNotUse::InternalNewImpl_() {
                return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(CallableOptions_FeedDevicesEntry_DoNotUse),
                                                          alignof(CallableOptions_FeedDevicesEntry_DoNotUse));
              }
              PROTOBUF_CONSTINIT
              PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
              const ::google::protobuf::internal::ClassDataFull CallableOptions_FeedDevicesEntry_DoNotUse::_class_data_ = {
                  ::google::protobuf::internal::ClassData{
                      &_CallableOptions_FeedDevicesEntry_DoNotUse_default_instance_._instance,
                      &_table_.header,
                      nullptr,  // OnDemandRegisterArenaDtor
                      nullptr,  // IsInitialized
                      &CallableOptions_FeedDevicesEntry_DoNotUse::MergeImpl,
                      ::google::protobuf::Message::GetNewImpl<CallableOptions_FeedDevicesEntry_DoNotUse>(),
              #if defined(PROTOBUF_CUSTOM_VTABLE)
                      &CallableOptions_FeedDevicesEntry_DoNotUse::SharedDtor,
                      static_cast<void (::google::protobuf::MessageLite::*)()>(
                          &CallableOptions_FeedDevicesEntry_DoNotUse::ClearImpl),
                          ::google::protobuf::Message::ByteSizeLongImpl, ::google::protobuf::Message::_InternalSerializeImpl
                          ,
              #endif  // PROTOBUF_CUSTOM_VTABLE
                      PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_._cached_size_),
                      false,
                  },
                  &CallableOptions_FeedDevicesEntry_DoNotUse::kDescriptorMethods,
                  &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
                  nullptr,  // tracker
              };
              const ::google::protobuf::internal::ClassData* CallableOptions_FeedDevicesEntry_DoNotUse::GetClassData() const {
                ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
                ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
                return _class_data_.base();
              }
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 60, 2> CallableOptions_FeedDevicesEntry_DoNotUse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::DiscardEverythingFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::CallableOptions_FeedDevicesEntry_DoNotUse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string value = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.value_)}},
    // string key = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.key_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string key = 1;
    {PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.key_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string value = 2;
    {PROTOBUF_FIELD_OFFSET(CallableOptions_FeedDevicesEntry_DoNotUse, _impl_.value_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\53\3\5\0\0\0\0\0"
    "tensorflow.CallableOptions.FeedDevicesEntry"
    "key"
    "value"
  }},
};

// ===================================================================

#if defined(PROTOBUF_CUSTOM_VTABLE)
              CallableOptions_FetchDevicesEntry_DoNotUse::CallableOptions_FetchDevicesEntry_DoNotUse() : SuperType(_class_data_.base()) {}
              CallableOptions_FetchDevicesEntry_DoNotUse::CallableOptions_FetchDevicesEntry_DoNotUse(::google::protobuf::Arena* arena)
                  : SuperType(arena, _class_data_.base()) {}
#else   // PROTOBUF_CUSTOM_VTABLE
              CallableOptions_FetchDevicesEntry_DoNotUse::CallableOptions_FetchDevicesEntry_DoNotUse() : SuperType() {}
              CallableOptions_FetchDevicesEntry_DoNotUse::CallableOptions_FetchDevicesEntry_DoNotUse(::google::protobuf::Arena* arena) : SuperType(arena) {}
#endif  // PROTOBUF_CUSTOM_VTABLE
              inline void* CallableOptions_FetchDevicesEntry_DoNotUse::PlacementNew_(const void*, void* mem,
                                                      ::google::protobuf::Arena* arena) {
                return ::new (mem) CallableOptions_FetchDevicesEntry_DoNotUse(arena);
              }
              constexpr auto CallableOptions_FetchDevicesEntry_DoNotUse::InternalNewImpl_() {
                return ::google::protobuf::internal::MessageCreator::CopyInit(sizeof(CallableOptions_FetchDevicesEntry_DoNotUse),
                                                          alignof(CallableOptions_FetchDevicesEntry_DoNotUse));
              }
              PROTOBUF_CONSTINIT
              PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
              const ::google::protobuf::internal::ClassDataFull CallableOptions_FetchDevicesEntry_DoNotUse::_class_data_ = {
                  ::google::protobuf::internal::ClassData{
                      &_CallableOptions_FetchDevicesEntry_DoNotUse_default_instance_._instance,
                      &_table_.header,
                      nullptr,  // OnDemandRegisterArenaDtor
                      nullptr,  // IsInitialized
                      &CallableOptions_FetchDevicesEntry_DoNotUse::MergeImpl,
                      ::google::protobuf::Message::GetNewImpl<CallableOptions_FetchDevicesEntry_DoNotUse>(),
              #if defined(PROTOBUF_CUSTOM_VTABLE)
                      &CallableOptions_FetchDevicesEntry_DoNotUse::SharedDtor,
                      static_cast<void (::google::protobuf::MessageLite::*)()>(
                          &CallableOptions_FetchDevicesEntry_DoNotUse::ClearImpl),
                          ::google::protobuf::Message::ByteSizeLongImpl, ::google::protobuf::Message::_InternalSerializeImpl
                          ,
              #endif  // PROTOBUF_CUSTOM_VTABLE
                      PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_._cached_size_),
                      false,
                  },
                  &CallableOptions_FetchDevicesEntry_DoNotUse::kDescriptorMethods,
                  &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
                  nullptr,  // tracker
              };
              const ::google::protobuf::internal::ClassData* CallableOptions_FetchDevicesEntry_DoNotUse::GetClassData() const {
                ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
                ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
                return _class_data_.base();
              }
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<1, 2, 0, 61, 2> CallableOptions_FetchDevicesEntry_DoNotUse::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_._has_bits_),
    0, // no _extensions_
    2, 8,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967292,  // skipmap
    offsetof(decltype(_table_), field_entries),
    2,  // num_field_entries
    0,  // num_aux_entries
    offsetof(decltype(_table_), field_names),  // no aux_entries
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::DiscardEverythingFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::CallableOptions_FetchDevicesEntry_DoNotUse>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // string value = 2;
    {::_pbi::TcParser::FastUS1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.value_)}},
    // string key = 1;
    {::_pbi::TcParser::FastUS1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.key_)}},
  }}, {{
    65535, 65535
  }}, {{
    // string key = 1;
    {PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.key_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
    // string value = 2;
    {PROTOBUF_FIELD_OFFSET(CallableOptions_FetchDevicesEntry_DoNotUse, _impl_.value_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kUtf8String | ::_fl::kRepAString)},
  }},
  // no aux_entries
  {{
    "\54\3\5\0\0\0\0\0"
    "tensorflow.CallableOptions.FetchDevicesEntry"
    "key"
    "value"
  }},
};

// ===================================================================

class CallableOptions::_Internal {
 public:
  using HasBits =
      decltype(std::declval<CallableOptions>()._impl_._has_bits_);
  static constexpr ::int32_t kHasBitsOffset =
      8 * PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_._has_bits_);
};

CallableOptions::CallableOptions(::google::protobuf::Arena* arena)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  SharedCtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CallableOptions)
}
inline PROTOBUF_NDEBUG_INLINE CallableOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility, ::google::protobuf::Arena* arena,
    const Impl_& from, const ::tensorflow::CallableOptions& from_msg)
      : _has_bits_{from._has_bits_},
        _cached_size_{0},
        feed_{visibility, arena, from.feed_},
        fetch_{visibility, arena, from.fetch_},
        target_{visibility, arena, from.target_},
        tensor_connection_{visibility, arena, from.tensor_connection_},
        feed_devices_{visibility, arena, from.feed_devices_},
        fetch_devices_{visibility, arena, from.fetch_devices_} {}

CallableOptions::CallableOptions(
    ::google::protobuf::Arena* arena,
    const CallableOptions& from)
#if defined(PROTOBUF_CUSTOM_VTABLE)
    : ::google::protobuf::Message(arena, _class_data_.base()) {
#else   // PROTOBUF_CUSTOM_VTABLE
    : ::google::protobuf::Message(arena) {
#endif  // PROTOBUF_CUSTOM_VTABLE
  CallableOptions* const _this = this;
  (void)_this;
  _internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(
      from._internal_metadata_);
  new (&_impl_) Impl_(internal_visibility(), arena, from._impl_, from);
  ::uint32_t cached_has_bits = _impl_._has_bits_[0];
  _impl_.run_options_ = (cached_has_bits & 0x00000001u) ? ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions>(
                              arena, *from._impl_.run_options_)
                        : nullptr;
  _impl_.fetch_skip_sync_ = from._impl_.fetch_skip_sync_;

  // @@protoc_insertion_point(copy_constructor:tensorflow.CallableOptions)
}
inline PROTOBUF_NDEBUG_INLINE CallableOptions::Impl_::Impl_(
    ::google::protobuf::internal::InternalVisibility visibility,
    ::google::protobuf::Arena* arena)
      : _cached_size_{0},
        feed_{visibility, arena},
        fetch_{visibility, arena},
        target_{visibility, arena},
        tensor_connection_{visibility, arena},
        feed_devices_{visibility, arena},
        fetch_devices_{visibility, arena} {}

inline void CallableOptions::SharedCtor(::_pb::Arena* arena) {
  new (&_impl_) Impl_(internal_visibility(), arena);
  ::memset(reinterpret_cast<char *>(&_impl_) +
               offsetof(Impl_, run_options_),
           0,
           offsetof(Impl_, fetch_skip_sync_) -
               offsetof(Impl_, run_options_) +
               sizeof(Impl_::fetch_skip_sync_));
}
CallableOptions::~CallableOptions() {
  // @@protoc_insertion_point(destructor:tensorflow.CallableOptions)
  SharedDtor(*this);
}
inline void CallableOptions::SharedDtor(MessageLite& self) {
  CallableOptions& this_ = static_cast<CallableOptions&>(self);
  this_._internal_metadata_.Delete<::google::protobuf::UnknownFieldSet>();
  ABSL_DCHECK(this_.GetArena() == nullptr);
  delete this_._impl_.run_options_;
  this_._impl_.~Impl_();
}

inline void* CallableOptions::PlacementNew_(const void*, void* mem,
                                        ::google::protobuf::Arena* arena) {
  return ::new (mem) CallableOptions(arena);
}
constexpr auto CallableOptions::InternalNewImpl_() {
  constexpr auto arena_bits = ::google::protobuf::internal::EncodePlacementArenaOffsets({
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_) +
          decltype(CallableOptions::_impl_.feed_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_) +
          decltype(CallableOptions::_impl_.fetch_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.target_) +
          decltype(CallableOptions::_impl_.target_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.tensor_connection_) +
          decltype(CallableOptions::_impl_.tensor_connection_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_devices_) +
          decltype(CallableOptions::_impl_.feed_devices_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_devices_) +
          decltype(CallableOptions::_impl_.feed_devices_)::
              InternalGetArenaOffsetAlt(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_devices_) +
          decltype(CallableOptions::_impl_.fetch_devices_)::
              InternalGetArenaOffset(
                  ::google::protobuf::Message::internal_visibility()),
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_devices_) +
          decltype(CallableOptions::_impl_.fetch_devices_)::
              InternalGetArenaOffsetAlt(
                  ::google::protobuf::Message::internal_visibility()),
  });
  if (arena_bits.has_value()) {
    return ::google::protobuf::internal::MessageCreator::CopyInit(
        sizeof(CallableOptions), alignof(CallableOptions), *arena_bits);
  } else {
    return ::google::protobuf::internal::MessageCreator(&CallableOptions::PlacementNew_,
                                 sizeof(CallableOptions),
                                 alignof(CallableOptions));
  }
}
PROTOBUF_CONSTINIT
PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::google::protobuf::internal::ClassDataFull CallableOptions::_class_data_ = {
    ::google::protobuf::internal::ClassData{
        &_CallableOptions_default_instance_._instance,
        &_table_.header,
        nullptr,  // OnDemandRegisterArenaDtor
        nullptr,  // IsInitialized
        &CallableOptions::MergeImpl,
        ::google::protobuf::Message::GetNewImpl<CallableOptions>(),
#if defined(PROTOBUF_CUSTOM_VTABLE)
        &CallableOptions::SharedDtor,
        ::google::protobuf::Message::GetClearImpl<CallableOptions>(), &CallableOptions::ByteSizeLong,
            &CallableOptions::_InternalSerialize,
#endif  // PROTOBUF_CUSTOM_VTABLE
        PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_._cached_size_),
        false,
    },
    &CallableOptions::kDescriptorMethods,
    &descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto,
    nullptr,  // tracker
};
const ::google::protobuf::internal::ClassData* CallableOptions::GetClassData() const {
  ::google::protobuf::internal::PrefetchToLocalCache(&_class_data_);
  ::google::protobuf::internal::PrefetchToLocalCache(_class_data_.tc_table);
  return _class_data_.base();
}
PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1
const ::_pbi::TcParseTable<3, 8, 4, 83, 2> CallableOptions::_table_ = {
  {
    PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_._has_bits_),
    0, // no _extensions_
    8, 56,  // max_field_number, fast_idx_mask
    offsetof(decltype(_table_), field_lookup_table),
    4294967040,  // skipmap
    offsetof(decltype(_table_), field_entries),
    8,  // num_field_entries
    4,  // num_aux_entries
    offsetof(decltype(_table_), aux_entries),
    _class_data_.base(),
    nullptr,  // post_loop_handler
    ::_pbi::TcParser::GenericFallback,  // fallback
    #ifdef PROTOBUF_PREFETCH_PARSE_TABLE
    ::_pbi::TcParser::GetTable<::tensorflow::CallableOptions>(),  // to_prefetch
    #endif  // PROTOBUF_PREFETCH_PARSE_TABLE
  }, {{
    // bool fetch_skip_sync = 8;
    {::_pbi::TcParser::SingularVarintNoZag1<bool, offsetof(CallableOptions, _impl_.fetch_skip_sync_), 63>(),
     {64, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_skip_sync_)}},
    // repeated string feed = 1;
    {::_pbi::TcParser::FastUR1,
     {10, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_)}},
    // repeated string fetch = 2;
    {::_pbi::TcParser::FastUR1,
     {18, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_)}},
    // repeated string target = 3;
    {::_pbi::TcParser::FastUR1,
     {26, 63, 0, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.target_)}},
    // .tensorflow.RunOptions run_options = 4;
    {::_pbi::TcParser::FastMtS1,
     {34, 0, 0, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.run_options_)}},
    // repeated .tensorflow.TensorConnection tensor_connection = 5;
    {::_pbi::TcParser::FastMtR1,
     {42, 63, 1, PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.tensor_connection_)}},
    {::_pbi::TcParser::MiniParse, {}},
    {::_pbi::TcParser::MiniParse, {}},
  }}, {{
    65535, 65535
  }}, {{
    // repeated string feed = 1;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // repeated string fetch = 2;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // repeated string target = 3;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.target_), -1, 0,
    (0 | ::_fl::kFcRepeated | ::_fl::kUtf8String | ::_fl::kRepSString)},
    // .tensorflow.RunOptions run_options = 4;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.run_options_), _Internal::kHasBitsOffset + 0, 0,
    (0 | ::_fl::kFcOptional | ::_fl::kMessage | ::_fl::kTvTable)},
    // repeated .tensorflow.TensorConnection tensor_connection = 5;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.tensor_connection_), -1, 1,
    (0 | ::_fl::kFcRepeated | ::_fl::kMessage | ::_fl::kTvTable)},
    // map<string, string> feed_devices = 6;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.feed_devices_), -1, 2,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
    // map<string, string> fetch_devices = 7;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_devices_), -1, 3,
    (0 | ::_fl::kFcRepeated | ::_fl::kMap)},
    // bool fetch_skip_sync = 8;
    {PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_skip_sync_), -1, 0,
    (0 | ::_fl::kFcSingular | ::_fl::kBool)},
  }}, {{
    {::_pbi::TcParser::GetTable<::tensorflow::RunOptions>()},
    {::_pbi::TcParser::GetTable<::tensorflow::TensorConnection>()},
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(CallableOptions()._impl_.feed_devices_)>(
        1, 0, 0, 9,
        9)},
    {::_pbi::TcParser::GetMapAuxInfo<
        decltype(CallableOptions()._impl_.fetch_devices_)>(
        1, 0, 0, 9,
        9)},
  }}, {{
    "\32\4\5\6\0\0\14\15\0\0\0\0\0\0\0\0"
    "tensorflow.CallableOptions"
    "feed"
    "fetch"
    "target"
    "feed_devices"
    "fetch_devices"
  }},
};

PROTOBUF_NOINLINE void CallableOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CallableOptions)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.feed_.Clear();
  _impl_.fetch_.Clear();
  _impl_.target_.Clear();
  _impl_.tensor_connection_.Clear();
  _impl_.feed_devices_.Clear();
  _impl_.fetch_devices_.Clear();
  cached_has_bits = _impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(_impl_.run_options_ != nullptr);
    _impl_.run_options_->Clear();
  }
  _impl_.fetch_skip_sync_ = false;
  _impl_._has_bits_.Clear();
  _internal_metadata_.Clear<::google::protobuf::UnknownFieldSet>();
}

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::uint8_t* CallableOptions::_InternalSerialize(
            const MessageLite& base, ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) {
          const CallableOptions& this_ = static_cast<const CallableOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::uint8_t* CallableOptions::_InternalSerialize(
            ::uint8_t* target,
            ::google::protobuf::io::EpsCopyOutputStream* stream) const {
          const CallableOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CallableOptions)
          ::uint32_t cached_has_bits = 0;
          (void)cached_has_bits;

          // repeated string feed = 1;
          for (int i = 0, n = this_._internal_feed_size(); i < n; ++i) {
            const auto& s = this_._internal_feed().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.feed");
            target = stream->WriteString(1, s, target);
          }

          // repeated string fetch = 2;
          for (int i = 0, n = this_._internal_fetch_size(); i < n; ++i) {
            const auto& s = this_._internal_fetch().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.fetch");
            target = stream->WriteString(2, s, target);
          }

          // repeated string target = 3;
          for (int i = 0, n = this_._internal_target_size(); i < n; ++i) {
            const auto& s = this_._internal_target().Get(i);
            ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                s.data(), static_cast<int>(s.length()), ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.target");
            target = stream->WriteString(3, s, target);
          }

          cached_has_bits = this_._impl_._has_bits_[0];
          // .tensorflow.RunOptions run_options = 4;
          if (cached_has_bits & 0x00000001u) {
            target = ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                4, *this_._impl_.run_options_, this_._impl_.run_options_->GetCachedSize(), target,
                stream);
          }

          // repeated .tensorflow.TensorConnection tensor_connection = 5;
          for (unsigned i = 0, n = static_cast<unsigned>(
                                   this_._internal_tensor_connection_size());
               i < n; i++) {
            const auto& repfield = this_._internal_tensor_connection().Get(i);
            target =
                ::google::protobuf::internal::WireFormatLite::InternalWriteMessage(
                    5, repfield, repfield.GetCachedSize(),
                    target, stream);
          }

          // map<string, string> feed_devices = 6;
          if (!this_._internal_feed_devices().empty()) {
            using MapType = ::google::protobuf::Map<std::string, std::string>;
            using WireHelper = _pbi::MapEntryFuncs<std::string, std::string,
                                           _pbi::WireFormatLite::TYPE_STRING,
                                           _pbi::WireFormatLite::TYPE_STRING>;
            const auto& field = this_._internal_feed_devices();

            if (stream->IsSerializationDeterministic() && field.size() > 1) {
              for (const auto& entry : ::google::protobuf::internal::MapSorterPtr<MapType>(field)) {
                target = WireHelper::InternalSerialize(
                    6, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.feed_devices");
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.feed_devices");
              }
            } else {
              for (const auto& entry : field) {
                target = WireHelper::InternalSerialize(
                    6, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.feed_devices");
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.feed_devices");
              }
            }
          }

          // map<string, string> fetch_devices = 7;
          if (!this_._internal_fetch_devices().empty()) {
            using MapType = ::google::protobuf::Map<std::string, std::string>;
            using WireHelper = _pbi::MapEntryFuncs<std::string, std::string,
                                           _pbi::WireFormatLite::TYPE_STRING,
                                           _pbi::WireFormatLite::TYPE_STRING>;
            const auto& field = this_._internal_fetch_devices();

            if (stream->IsSerializationDeterministic() && field.size() > 1) {
              for (const auto& entry : ::google::protobuf::internal::MapSorterPtr<MapType>(field)) {
                target = WireHelper::InternalSerialize(
                    7, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.fetch_devices");
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.fetch_devices");
              }
            } else {
              for (const auto& entry : field) {
                target = WireHelper::InternalSerialize(
                    7, entry.first, entry.second, target, stream);
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.first.data(), static_cast<int>(entry.first.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.fetch_devices");
                ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
                    entry.second.data(), static_cast<int>(entry.second.length()),
 ::google::protobuf::internal::WireFormatLite::SERIALIZE, "tensorflow.CallableOptions.fetch_devices");
              }
            }
          }

          // bool fetch_skip_sync = 8;
          if (this_._internal_fetch_skip_sync() != 0) {
            target = stream->EnsureSpace(target);
            target = ::_pbi::WireFormatLite::WriteBoolToArray(
                8, this_._internal_fetch_skip_sync(), target);
          }

          if (PROTOBUF_PREDICT_FALSE(this_._internal_metadata_.have_unknown_fields())) {
            target =
                ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
                    this_._internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance), target, stream);
          }
          // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CallableOptions)
          return target;
        }

#if defined(PROTOBUF_CUSTOM_VTABLE)
        ::size_t CallableOptions::ByteSizeLong(const MessageLite& base) {
          const CallableOptions& this_ = static_cast<const CallableOptions&>(base);
#else   // PROTOBUF_CUSTOM_VTABLE
        ::size_t CallableOptions::ByteSizeLong() const {
          const CallableOptions& this_ = *this;
#endif  // PROTOBUF_CUSTOM_VTABLE
          // @@protoc_insertion_point(message_byte_size_start:tensorflow.CallableOptions)
          ::size_t total_size = 0;

          ::uint32_t cached_has_bits = 0;
          // Prevent compiler warnings about cached_has_bits being unused
          (void)cached_has_bits;

          ::_pbi::Prefetch5LinesFrom7Lines(&this_);
           {
            // repeated string feed = 1;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_feed().size());
              for (int i = 0, n = this_._internal_feed().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_feed().Get(i));
              }
            }
            // repeated string fetch = 2;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_fetch().size());
              for (int i = 0, n = this_._internal_fetch().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_fetch().Get(i));
              }
            }
            // repeated string target = 3;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_target().size());
              for (int i = 0, n = this_._internal_target().size(); i < n; ++i) {
                total_size += ::google::protobuf::internal::WireFormatLite::StringSize(
                    this_._internal_target().Get(i));
              }
            }
            // repeated .tensorflow.TensorConnection tensor_connection = 5;
            {
              total_size += 1UL * this_._internal_tensor_connection_size();
              for (const auto& msg : this_._internal_tensor_connection()) {
                total_size += ::google::protobuf::internal::WireFormatLite::MessageSize(msg);
              }
            }
            // map<string, string> feed_devices = 6;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_feed_devices_size());
              for (const auto& entry : this_._internal_feed_devices()) {
                total_size += _pbi::MapEntryFuncs<std::string, std::string,
                                               _pbi::WireFormatLite::TYPE_STRING,
                                               _pbi::WireFormatLite::TYPE_STRING>::ByteSizeLong(entry.first, entry.second);
              }
            }
            // map<string, string> fetch_devices = 7;
            {
              total_size +=
                  1 * ::google::protobuf::internal::FromIntSize(this_._internal_fetch_devices_size());
              for (const auto& entry : this_._internal_fetch_devices()) {
                total_size += _pbi::MapEntryFuncs<std::string, std::string,
                                               _pbi::WireFormatLite::TYPE_STRING,
                                               _pbi::WireFormatLite::TYPE_STRING>::ByteSizeLong(entry.first, entry.second);
              }
            }
          }
           {
            // .tensorflow.RunOptions run_options = 4;
            cached_has_bits = this_._impl_._has_bits_[0];
            if (cached_has_bits & 0x00000001u) {
              total_size += 1 +
                            ::google::protobuf::internal::WireFormatLite::MessageSize(*this_._impl_.run_options_);
            }
          }
           {
            // bool fetch_skip_sync = 8;
            if (this_._internal_fetch_skip_sync() != 0) {
              total_size += 2;
            }
          }
          return this_.MaybeComputeUnknownFieldsSize(total_size,
                                                     &this_._impl_._cached_size_);
        }

void CallableOptions::MergeImpl(::google::protobuf::MessageLite& to_msg, const ::google::protobuf::MessageLite& from_msg) {
  auto* const _this = static_cast<CallableOptions*>(&to_msg);
  auto& from = static_cast<const CallableOptions&>(from_msg);
  ::google::protobuf::Arena* arena = _this->GetArena();
  // @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CallableOptions)
  ABSL_DCHECK_NE(&from, _this);
  ::uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_internal_mutable_feed()->MergeFrom(from._internal_feed());
  _this->_internal_mutable_fetch()->MergeFrom(from._internal_fetch());
  _this->_internal_mutable_target()->MergeFrom(from._internal_target());
  _this->_internal_mutable_tensor_connection()->MergeFrom(
      from._internal_tensor_connection());
  _this->_impl_.feed_devices_.MergeFrom(from._impl_.feed_devices_);
  _this->_impl_.fetch_devices_.MergeFrom(from._impl_.fetch_devices_);
  cached_has_bits = from._impl_._has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    ABSL_DCHECK(from._impl_.run_options_ != nullptr);
    if (_this->_impl_.run_options_ == nullptr) {
      _this->_impl_.run_options_ =
          ::google::protobuf::Message::CopyConstruct<::tensorflow::RunOptions>(arena, *from._impl_.run_options_);
    } else {
      _this->_impl_.run_options_->MergeFrom(*from._impl_.run_options_);
    }
  }
  if (from._internal_fetch_skip_sync() != 0) {
    _this->_impl_.fetch_skip_sync_ = from._impl_.fetch_skip_sync_;
  }
  _this->_impl_._has_bits_[0] |= cached_has_bits;
  _this->_internal_metadata_.MergeFrom<::google::protobuf::UnknownFieldSet>(from._internal_metadata_);
}

void CallableOptions::CopyFrom(const CallableOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CallableOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}


void CallableOptions::InternalSwap(CallableOptions* PROTOBUF_RESTRICT other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
  _impl_.feed_.InternalSwap(&other->_impl_.feed_);
  _impl_.fetch_.InternalSwap(&other->_impl_.fetch_);
  _impl_.target_.InternalSwap(&other->_impl_.target_);
  _impl_.tensor_connection_.InternalSwap(&other->_impl_.tensor_connection_);
  _impl_.feed_devices_.InternalSwap(&other->_impl_.feed_devices_);
  _impl_.fetch_devices_.InternalSwap(&other->_impl_.fetch_devices_);
  ::google::protobuf::internal::memswap<
      PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.fetch_skip_sync_)
      + sizeof(CallableOptions::_impl_.fetch_skip_sync_)
      - PROTOBUF_FIELD_OFFSET(CallableOptions, _impl_.run_options_)>(
          reinterpret_cast<char*>(&_impl_.run_options_),
          reinterpret_cast<char*>(&other->_impl_.run_options_));
}

::google::protobuf::Metadata CallableOptions::GetMetadata() const {
  return ::google::protobuf::Message::GetMetadataImpl(GetClassData()->full());
}
// @@protoc_insertion_point(namespace_scope)
}  // namespace tensorflow
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google
// @@protoc_insertion_point(global_scope)
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::std::false_type
    _static_init2_ PROTOBUF_UNUSED =
        (::_pbi::AddDescriptors(&descriptor_table_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto),
         ::std::false_type{});
#include "google/protobuf/port_undef.inc"
