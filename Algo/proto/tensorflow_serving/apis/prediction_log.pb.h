// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: tensorflow_serving/apis/prediction_log.proto
// Protobuf C++ Version: 5.29.0

#ifndef tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_2epb_2eh
#define tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_2epb_2eh

#include <limits>
#include <string>
#include <type_traits>
#include <utility>

#include "google/protobuf/runtime_version.h"
#if PROTOBUF_VERSION != 5029000
#error "Protobuf C++ gencode is built with an incompatible version of"
#error "Protobuf C++ headers/runtime. See"
#error "https://protobuf.dev/support/cross-version-runtime-guarantee/#cpp"
#endif
#include "google/protobuf/io/coded_stream.h"
#include "google/protobuf/arena.h"
#include "google/protobuf/arenastring.h"
#include "google/protobuf/generated_message_tctable_decl.h"
#include "google/protobuf/generated_message_util.h"
#include "google/protobuf/metadata_lite.h"
#include "google/protobuf/generated_message_reflection.h"
#include "google/protobuf/message.h"
#include "google/protobuf/message_lite.h"
#include "google/protobuf/repeated_field.h"  // IWYU pragma: export
#include "google/protobuf/extension_set.h"  // IWYU pragma: export
#include "google/protobuf/unknown_field_set.h"
#include "tensorflow_serving/apis/classification.pb.h"
#include "tensorflow_serving/apis/inference.pb.h"
#include "tensorflow_serving/apis/logging.pb.h"
#include "tensorflow_serving/apis/predict.pb.h"
#include "tensorflow_serving/apis/regression.pb.h"
#include "tensorflow_serving/apis/session_service.pb.h"
// @@protoc_insertion_point(includes)

// Must be included last.
#include "google/protobuf/port_def.inc"

#define PROTOBUF_INTERNAL_EXPORT_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto

namespace google {
namespace protobuf {
namespace internal {
template <typename T>
::absl::string_view GetAnyMessageName();
}  // namespace internal
}  // namespace protobuf
}  // namespace google

// Internal implementation detail -- do not use these members.
struct TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto {
  static const ::uint32_t offsets[];
};
extern const ::google::protobuf::internal::DescriptorTable
    descriptor_table_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
namespace tensorflow {
namespace serving {
class ClassifyLog;
struct ClassifyLogDefaultTypeInternal;
extern ClassifyLogDefaultTypeInternal _ClassifyLog_default_instance_;
class MultiInferenceLog;
struct MultiInferenceLogDefaultTypeInternal;
extern MultiInferenceLogDefaultTypeInternal _MultiInferenceLog_default_instance_;
class PredictLog;
struct PredictLogDefaultTypeInternal;
extern PredictLogDefaultTypeInternal _PredictLog_default_instance_;
class PredictStreamedLog;
struct PredictStreamedLogDefaultTypeInternal;
extern PredictStreamedLogDefaultTypeInternal _PredictStreamedLog_default_instance_;
class PredictionLog;
struct PredictionLogDefaultTypeInternal;
extern PredictionLogDefaultTypeInternal _PredictionLog_default_instance_;
class RegressLog;
struct RegressLogDefaultTypeInternal;
extern RegressLogDefaultTypeInternal _RegressLog_default_instance_;
class SessionRunLog;
struct SessionRunLogDefaultTypeInternal;
extern SessionRunLogDefaultTypeInternal _SessionRunLog_default_instance_;
}  // namespace serving
}  // namespace tensorflow
namespace google {
namespace protobuf {
}  // namespace protobuf
}  // namespace google

namespace tensorflow {
namespace serving {

// ===================================================================


// -------------------------------------------------------------------

class PredictStreamedLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictStreamedLog) */ {
 public:
  inline PredictStreamedLog() : PredictStreamedLog(nullptr) {}
  ~PredictStreamedLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(PredictStreamedLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(PredictStreamedLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR PredictStreamedLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline PredictStreamedLog(const PredictStreamedLog& from) : PredictStreamedLog(nullptr, from) {}
  inline PredictStreamedLog(PredictStreamedLog&& from) noexcept
      : PredictStreamedLog(nullptr, std::move(from)) {}
  inline PredictStreamedLog& operator=(const PredictStreamedLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictStreamedLog& operator=(PredictStreamedLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictStreamedLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictStreamedLog* internal_default_instance() {
    return reinterpret_cast<const PredictStreamedLog*>(
        &_PredictStreamedLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 3;
  friend void swap(PredictStreamedLog& a, PredictStreamedLog& b) { a.Swap(&b); }
  inline void Swap(PredictStreamedLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictStreamedLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictStreamedLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<PredictStreamedLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const PredictStreamedLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const PredictStreamedLog& from) { PredictStreamedLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(PredictStreamedLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.PredictStreamedLog"; }

 protected:
  explicit PredictStreamedLog(::google::protobuf::Arena* arena);
  PredictStreamedLog(::google::protobuf::Arena* arena, const PredictStreamedLog& from);
  PredictStreamedLog(::google::protobuf::Arena* arena, PredictStreamedLog&& from) noexcept
      : PredictStreamedLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // repeated .tensorflow.serving.PredictRequest request = 1;
  int request_size() const;
  private:
  int _internal_request_size() const;

  public:
  void clear_request() ;
  ::tensorflow::serving::PredictRequest* mutable_request(int index);
  ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>* mutable_request();

  private:
  const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>& _internal_request() const;
  ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>* _internal_mutable_request();
  public:
  const ::tensorflow::serving::PredictRequest& request(int index) const;
  ::tensorflow::serving::PredictRequest* add_request();
  const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>& request() const;
  // repeated .tensorflow.serving.PredictResponse response = 2;
  int response_size() const;
  private:
  int _internal_response_size() const;

  public:
  void clear_response() ;
  ::tensorflow::serving::PredictResponse* mutable_response(int index);
  ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>* mutable_response();

  private:
  const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>& _internal_response() const;
  ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>* _internal_mutable_response();
  public:
  const ::tensorflow::serving::PredictResponse& response(int index) const;
  ::tensorflow::serving::PredictResponse* add_response();
  const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>& response() const;
  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictStreamedLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const PredictStreamedLog& from_msg);
    ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::PredictRequest > request_;
    ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::PredictResponse > response_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class PredictLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictLog) */ {
 public:
  inline PredictLog() : PredictLog(nullptr) {}
  ~PredictLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(PredictLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(PredictLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR PredictLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline PredictLog(const PredictLog& from) : PredictLog(nullptr, from) {}
  inline PredictLog(PredictLog&& from) noexcept
      : PredictLog(nullptr, std::move(from)) {}
  inline PredictLog& operator=(const PredictLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictLog& operator=(PredictLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const PredictLog* internal_default_instance() {
    return reinterpret_cast<const PredictLog*>(
        &_PredictLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 2;
  friend void swap(PredictLog& a, PredictLog& b) { a.Swap(&b); }
  inline void Swap(PredictLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<PredictLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const PredictLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const PredictLog& from) { PredictLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(PredictLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.PredictLog"; }

 protected:
  explicit PredictLog(::google::protobuf::Arena* arena);
  PredictLog(::google::protobuf::Arena* arena, const PredictLog& from);
  PredictLog(::google::protobuf::Arena* arena, PredictLog&& from) noexcept
      : PredictLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.PredictRequest request = 1;
  bool has_request() const;
  void clear_request() ;
  const ::tensorflow::serving::PredictRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictRequest* release_request();
  ::tensorflow::serving::PredictRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::PredictRequest* value);
  void unsafe_arena_set_allocated_request(::tensorflow::serving::PredictRequest* value);
  ::tensorflow::serving::PredictRequest* unsafe_arena_release_request();

  private:
  const ::tensorflow::serving::PredictRequest& _internal_request() const;
  ::tensorflow::serving::PredictRequest* _internal_mutable_request();

  public:
  // .tensorflow.serving.PredictResponse response = 2;
  bool has_response() const;
  void clear_response() ;
  const ::tensorflow::serving::PredictResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictResponse* release_response();
  ::tensorflow::serving::PredictResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::PredictResponse* value);
  void unsafe_arena_set_allocated_response(::tensorflow::serving::PredictResponse* value);
  ::tensorflow::serving::PredictResponse* unsafe_arena_release_response();

  private:
  const ::tensorflow::serving::PredictResponse& _internal_response() const;
  ::tensorflow::serving::PredictResponse* _internal_mutable_response();

  public:
  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const PredictLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::PredictRequest* request_;
    ::tensorflow::serving::PredictResponse* response_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class RegressLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.RegressLog) */ {
 public:
  inline RegressLog() : RegressLog(nullptr) {}
  ~RegressLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(RegressLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(RegressLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR RegressLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline RegressLog(const RegressLog& from) : RegressLog(nullptr, from) {}
  inline RegressLog(RegressLog&& from) noexcept
      : RegressLog(nullptr, std::move(from)) {}
  inline RegressLog& operator=(const RegressLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline RegressLog& operator=(RegressLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const RegressLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const RegressLog* internal_default_instance() {
    return reinterpret_cast<const RegressLog*>(
        &_RegressLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 1;
  friend void swap(RegressLog& a, RegressLog& b) { a.Swap(&b); }
  inline void Swap(RegressLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(RegressLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  RegressLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<RegressLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const RegressLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const RegressLog& from) { RegressLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(RegressLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.RegressLog"; }

 protected:
  explicit RegressLog(::google::protobuf::Arena* arena);
  RegressLog(::google::protobuf::Arena* arena, const RegressLog& from);
  RegressLog(::google::protobuf::Arena* arena, RegressLog&& from) noexcept
      : RegressLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.RegressionRequest request = 1;
  bool has_request() const;
  void clear_request() ;
  const ::tensorflow::serving::RegressionRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressionRequest* release_request();
  ::tensorflow::serving::RegressionRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::RegressionRequest* value);
  void unsafe_arena_set_allocated_request(::tensorflow::serving::RegressionRequest* value);
  ::tensorflow::serving::RegressionRequest* unsafe_arena_release_request();

  private:
  const ::tensorflow::serving::RegressionRequest& _internal_request() const;
  ::tensorflow::serving::RegressionRequest* _internal_mutable_request();

  public:
  // .tensorflow.serving.RegressionResponse response = 2;
  bool has_response() const;
  void clear_response() ;
  const ::tensorflow::serving::RegressionResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressionResponse* release_response();
  ::tensorflow::serving::RegressionResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::RegressionResponse* value);
  void unsafe_arena_set_allocated_response(::tensorflow::serving::RegressionResponse* value);
  ::tensorflow::serving::RegressionResponse* unsafe_arena_release_response();

  private:
  const ::tensorflow::serving::RegressionResponse& _internal_response() const;
  ::tensorflow::serving::RegressionResponse* _internal_mutable_response();

  public:
  // @@protoc_insertion_point(class_scope:tensorflow.serving.RegressLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const RegressLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::RegressionRequest* request_;
    ::tensorflow::serving::RegressionResponse* response_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class MultiInferenceLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.MultiInferenceLog) */ {
 public:
  inline MultiInferenceLog() : MultiInferenceLog(nullptr) {}
  ~MultiInferenceLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(MultiInferenceLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(MultiInferenceLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR MultiInferenceLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline MultiInferenceLog(const MultiInferenceLog& from) : MultiInferenceLog(nullptr, from) {}
  inline MultiInferenceLog(MultiInferenceLog&& from) noexcept
      : MultiInferenceLog(nullptr, std::move(from)) {}
  inline MultiInferenceLog& operator=(const MultiInferenceLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline MultiInferenceLog& operator=(MultiInferenceLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const MultiInferenceLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const MultiInferenceLog* internal_default_instance() {
    return reinterpret_cast<const MultiInferenceLog*>(
        &_MultiInferenceLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 4;
  friend void swap(MultiInferenceLog& a, MultiInferenceLog& b) { a.Swap(&b); }
  inline void Swap(MultiInferenceLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(MultiInferenceLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  MultiInferenceLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<MultiInferenceLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const MultiInferenceLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const MultiInferenceLog& from) { MultiInferenceLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(MultiInferenceLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.MultiInferenceLog"; }

 protected:
  explicit MultiInferenceLog(::google::protobuf::Arena* arena);
  MultiInferenceLog(::google::protobuf::Arena* arena, const MultiInferenceLog& from);
  MultiInferenceLog(::google::protobuf::Arena* arena, MultiInferenceLog&& from) noexcept
      : MultiInferenceLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.MultiInferenceRequest request = 1;
  bool has_request() const;
  void clear_request() ;
  const ::tensorflow::serving::MultiInferenceRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceRequest* release_request();
  ::tensorflow::serving::MultiInferenceRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::MultiInferenceRequest* value);
  void unsafe_arena_set_allocated_request(::tensorflow::serving::MultiInferenceRequest* value);
  ::tensorflow::serving::MultiInferenceRequest* unsafe_arena_release_request();

  private:
  const ::tensorflow::serving::MultiInferenceRequest& _internal_request() const;
  ::tensorflow::serving::MultiInferenceRequest* _internal_mutable_request();

  public:
  // .tensorflow.serving.MultiInferenceResponse response = 2;
  bool has_response() const;
  void clear_response() ;
  const ::tensorflow::serving::MultiInferenceResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceResponse* release_response();
  ::tensorflow::serving::MultiInferenceResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::MultiInferenceResponse* value);
  void unsafe_arena_set_allocated_response(::tensorflow::serving::MultiInferenceResponse* value);
  ::tensorflow::serving::MultiInferenceResponse* unsafe_arena_release_response();

  private:
  const ::tensorflow::serving::MultiInferenceResponse& _internal_response() const;
  ::tensorflow::serving::MultiInferenceResponse* _internal_mutable_response();

  public:
  // @@protoc_insertion_point(class_scope:tensorflow.serving.MultiInferenceLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const MultiInferenceLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::MultiInferenceRequest* request_;
    ::tensorflow::serving::MultiInferenceResponse* response_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class ClassifyLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.ClassifyLog) */ {
 public:
  inline ClassifyLog() : ClassifyLog(nullptr) {}
  ~ClassifyLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(ClassifyLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(ClassifyLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR ClassifyLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline ClassifyLog(const ClassifyLog& from) : ClassifyLog(nullptr, from) {}
  inline ClassifyLog(ClassifyLog&& from) noexcept
      : ClassifyLog(nullptr, std::move(from)) {}
  inline ClassifyLog& operator=(const ClassifyLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline ClassifyLog& operator=(ClassifyLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const ClassifyLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const ClassifyLog* internal_default_instance() {
    return reinterpret_cast<const ClassifyLog*>(
        &_ClassifyLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 0;
  friend void swap(ClassifyLog& a, ClassifyLog& b) { a.Swap(&b); }
  inline void Swap(ClassifyLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(ClassifyLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  ClassifyLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<ClassifyLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const ClassifyLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const ClassifyLog& from) { ClassifyLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(ClassifyLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.ClassifyLog"; }

 protected:
  explicit ClassifyLog(::google::protobuf::Arena* arena);
  ClassifyLog(::google::protobuf::Arena* arena, const ClassifyLog& from);
  ClassifyLog(::google::protobuf::Arena* arena, ClassifyLog&& from) noexcept
      : ClassifyLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.ClassificationRequest request = 1;
  bool has_request() const;
  void clear_request() ;
  const ::tensorflow::serving::ClassificationRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassificationRequest* release_request();
  ::tensorflow::serving::ClassificationRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::ClassificationRequest* value);
  void unsafe_arena_set_allocated_request(::tensorflow::serving::ClassificationRequest* value);
  ::tensorflow::serving::ClassificationRequest* unsafe_arena_release_request();

  private:
  const ::tensorflow::serving::ClassificationRequest& _internal_request() const;
  ::tensorflow::serving::ClassificationRequest* _internal_mutable_request();

  public:
  // .tensorflow.serving.ClassificationResponse response = 2;
  bool has_response() const;
  void clear_response() ;
  const ::tensorflow::serving::ClassificationResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassificationResponse* release_response();
  ::tensorflow::serving::ClassificationResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::ClassificationResponse* value);
  void unsafe_arena_set_allocated_response(::tensorflow::serving::ClassificationResponse* value);
  ::tensorflow::serving::ClassificationResponse* unsafe_arena_release_response();

  private:
  const ::tensorflow::serving::ClassificationResponse& _internal_response() const;
  ::tensorflow::serving::ClassificationResponse* _internal_mutable_response();

  public:
  // @@protoc_insertion_point(class_scope:tensorflow.serving.ClassifyLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const ClassifyLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::ClassificationRequest* request_;
    ::tensorflow::serving::ClassificationResponse* response_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class SessionRunLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.SessionRunLog) */ {
 public:
  inline SessionRunLog() : SessionRunLog(nullptr) {}
  ~SessionRunLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(SessionRunLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(SessionRunLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR SessionRunLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline SessionRunLog(const SessionRunLog& from) : SessionRunLog(nullptr, from) {}
  inline SessionRunLog(SessionRunLog&& from) noexcept
      : SessionRunLog(nullptr, std::move(from)) {}
  inline SessionRunLog& operator=(const SessionRunLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline SessionRunLog& operator=(SessionRunLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const SessionRunLog& default_instance() {
    return *internal_default_instance();
  }
  static inline const SessionRunLog* internal_default_instance() {
    return reinterpret_cast<const SessionRunLog*>(
        &_SessionRunLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 5;
  friend void swap(SessionRunLog& a, SessionRunLog& b) { a.Swap(&b); }
  inline void Swap(SessionRunLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(SessionRunLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  SessionRunLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<SessionRunLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const SessionRunLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const SessionRunLog& from) { SessionRunLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(SessionRunLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.SessionRunLog"; }

 protected:
  explicit SessionRunLog(::google::protobuf::Arena* arena);
  SessionRunLog(::google::protobuf::Arena* arena, const SessionRunLog& from);
  SessionRunLog(::google::protobuf::Arena* arena, SessionRunLog&& from) noexcept
      : SessionRunLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kRequestFieldNumber = 1,
    kResponseFieldNumber = 2,
  };
  // .tensorflow.serving.SessionRunRequest request = 1;
  bool has_request() const;
  void clear_request() ;
  const ::tensorflow::serving::SessionRunRequest& request() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunRequest* release_request();
  ::tensorflow::serving::SessionRunRequest* mutable_request();
  void set_allocated_request(::tensorflow::serving::SessionRunRequest* value);
  void unsafe_arena_set_allocated_request(::tensorflow::serving::SessionRunRequest* value);
  ::tensorflow::serving::SessionRunRequest* unsafe_arena_release_request();

  private:
  const ::tensorflow::serving::SessionRunRequest& _internal_request() const;
  ::tensorflow::serving::SessionRunRequest* _internal_mutable_request();

  public:
  // .tensorflow.serving.SessionRunResponse response = 2;
  bool has_response() const;
  void clear_response() ;
  const ::tensorflow::serving::SessionRunResponse& response() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunResponse* release_response();
  ::tensorflow::serving::SessionRunResponse* mutable_response();
  void set_allocated_response(::tensorflow::serving::SessionRunResponse* value);
  void unsafe_arena_set_allocated_response(::tensorflow::serving::SessionRunResponse* value);
  ::tensorflow::serving::SessionRunResponse* unsafe_arena_release_response();

  private:
  const ::tensorflow::serving::SessionRunResponse& _internal_response() const;
  ::tensorflow::serving::SessionRunResponse* _internal_mutable_response();

  public:
  // @@protoc_insertion_point(class_scope:tensorflow.serving.SessionRunLog)
 private:
  class _Internal;
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      1, 2, 2,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const SessionRunLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::SessionRunRequest* request_;
    ::tensorflow::serving::SessionRunResponse* response_;
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};
// -------------------------------------------------------------------

class PredictionLog final
    : public ::google::protobuf::Message
/* @@protoc_insertion_point(class_definition:tensorflow.serving.PredictionLog) */ {
 public:
  inline PredictionLog() : PredictionLog(nullptr) {}
  ~PredictionLog() PROTOBUF_FINAL;

#if defined(PROTOBUF_CUSTOM_VTABLE)
  void operator delete(PredictionLog* msg, std::destroying_delete_t) {
    SharedDtor(*msg);
    ::google::protobuf::internal::SizedDelete(msg, sizeof(PredictionLog));
  }
#endif

  template <typename = void>
  explicit PROTOBUF_CONSTEXPR PredictionLog(
      ::google::protobuf::internal::ConstantInitialized);

  inline PredictionLog(const PredictionLog& from) : PredictionLog(nullptr, from) {}
  inline PredictionLog(PredictionLog&& from) noexcept
      : PredictionLog(nullptr, std::move(from)) {}
  inline PredictionLog& operator=(const PredictionLog& from) {
    CopyFrom(from);
    return *this;
  }
  inline PredictionLog& operator=(PredictionLog&& from) noexcept {
    if (this == &from) return *this;
    if (::google::protobuf::internal::CanMoveWithInternalSwap(GetArena(), from.GetArena())) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.unknown_fields<::google::protobuf::UnknownFieldSet>(::google::protobuf::UnknownFieldSet::default_instance);
  }
  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields()
      ABSL_ATTRIBUTE_LIFETIME_BOUND {
    return _internal_metadata_.mutable_unknown_fields<::google::protobuf::UnknownFieldSet>();
  }

  static const ::google::protobuf::Descriptor* descriptor() {
    return GetDescriptor();
  }
  static const ::google::protobuf::Descriptor* GetDescriptor() {
    return default_instance().GetMetadata().descriptor;
  }
  static const ::google::protobuf::Reflection* GetReflection() {
    return default_instance().GetMetadata().reflection;
  }
  static const PredictionLog& default_instance() {
    return *internal_default_instance();
  }
  enum LogTypeCase {
    kClassifyLog = 2,
    kRegressLog = 3,
    kPredictLog = 6,
    kPredictStreamedLog = 7,
    kMultiInferenceLog = 4,
    kSessionRunLog = 5,
    LOG_TYPE_NOT_SET = 0,
  };
  static inline const PredictionLog* internal_default_instance() {
    return reinterpret_cast<const PredictionLog*>(
        &_PredictionLog_default_instance_);
  }
  static constexpr int kIndexInFileMessages = 6;
  friend void swap(PredictionLog& a, PredictionLog& b) { a.Swap(&b); }
  inline void Swap(PredictionLog* other) {
    if (other == this) return;
    if (::google::protobuf::internal::CanUseInternalSwap(GetArena(), other->GetArena())) {
      InternalSwap(other);
    } else {
      ::google::protobuf::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(PredictionLog* other) {
    if (other == this) return;
    ABSL_DCHECK(GetArena() == other->GetArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  PredictionLog* New(::google::protobuf::Arena* arena = nullptr) const {
    return ::google::protobuf::Message::DefaultConstruct<PredictionLog>(arena);
  }
  using ::google::protobuf::Message::CopyFrom;
  void CopyFrom(const PredictionLog& from);
  using ::google::protobuf::Message::MergeFrom;
  void MergeFrom(const PredictionLog& from) { PredictionLog::MergeImpl(*this, from); }

  private:
  static void MergeImpl(
      ::google::protobuf::MessageLite& to_msg,
      const ::google::protobuf::MessageLite& from_msg);

  public:
  bool IsInitialized() const {
    return true;
  }
  ABSL_ATTRIBUTE_REINITIALIZES void Clear() PROTOBUF_FINAL;
  #if defined(PROTOBUF_CUSTOM_VTABLE)
  private:
  static ::size_t ByteSizeLong(const ::google::protobuf::MessageLite& msg);
  static ::uint8_t* _InternalSerialize(
      const MessageLite& msg, ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream);

  public:
  ::size_t ByteSizeLong() const { return ByteSizeLong(*this); }
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const {
    return _InternalSerialize(*this, target, stream);
  }
  #else   // PROTOBUF_CUSTOM_VTABLE
  ::size_t ByteSizeLong() const final;
  ::uint8_t* _InternalSerialize(
      ::uint8_t* target,
      ::google::protobuf::io::EpsCopyOutputStream* stream) const final;
  #endif  // PROTOBUF_CUSTOM_VTABLE
  int GetCachedSize() const { return _impl_._cached_size_.Get(); }

  private:
  void SharedCtor(::google::protobuf::Arena* arena);
  static void SharedDtor(MessageLite& self);
  void InternalSwap(PredictionLog* other);
 private:
  template <typename T>
  friend ::absl::string_view(
      ::google::protobuf::internal::GetAnyMessageName)();
  static ::absl::string_view FullMessageName() { return "tensorflow.serving.PredictionLog"; }

 protected:
  explicit PredictionLog(::google::protobuf::Arena* arena);
  PredictionLog(::google::protobuf::Arena* arena, const PredictionLog& from);
  PredictionLog(::google::protobuf::Arena* arena, PredictionLog&& from) noexcept
      : PredictionLog(arena) {
    *this = ::std::move(from);
  }
  const ::google::protobuf::internal::ClassData* GetClassData() const PROTOBUF_FINAL;
  static void* PlacementNew_(const void*, void* mem,
                             ::google::protobuf::Arena* arena);
  static constexpr auto InternalNewImpl_();
  static const ::google::protobuf::internal::ClassDataFull _class_data_;

 public:
  ::google::protobuf::Metadata GetMetadata() const;
  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------
  enum : int {
    kLogMetadataFieldNumber = 1,
    kClassifyLogFieldNumber = 2,
    kRegressLogFieldNumber = 3,
    kPredictLogFieldNumber = 6,
    kPredictStreamedLogFieldNumber = 7,
    kMultiInferenceLogFieldNumber = 4,
    kSessionRunLogFieldNumber = 5,
  };
  // .tensorflow.serving.LogMetadata log_metadata = 1;
  bool has_log_metadata() const;
  void clear_log_metadata() ;
  const ::tensorflow::serving::LogMetadata& log_metadata() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::LogMetadata* release_log_metadata();
  ::tensorflow::serving::LogMetadata* mutable_log_metadata();
  void set_allocated_log_metadata(::tensorflow::serving::LogMetadata* value);
  void unsafe_arena_set_allocated_log_metadata(::tensorflow::serving::LogMetadata* value);
  ::tensorflow::serving::LogMetadata* unsafe_arena_release_log_metadata();

  private:
  const ::tensorflow::serving::LogMetadata& _internal_log_metadata() const;
  ::tensorflow::serving::LogMetadata* _internal_mutable_log_metadata();

  public:
  // .tensorflow.serving.ClassifyLog classify_log = 2;
  bool has_classify_log() const;
  private:
  bool _internal_has_classify_log() const;

  public:
  void clear_classify_log() ;
  const ::tensorflow::serving::ClassifyLog& classify_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::ClassifyLog* release_classify_log();
  ::tensorflow::serving::ClassifyLog* mutable_classify_log();
  void set_allocated_classify_log(::tensorflow::serving::ClassifyLog* value);
  void unsafe_arena_set_allocated_classify_log(::tensorflow::serving::ClassifyLog* value);
  ::tensorflow::serving::ClassifyLog* unsafe_arena_release_classify_log();

  private:
  const ::tensorflow::serving::ClassifyLog& _internal_classify_log() const;
  ::tensorflow::serving::ClassifyLog* _internal_mutable_classify_log();

  public:
  // .tensorflow.serving.RegressLog regress_log = 3;
  bool has_regress_log() const;
  private:
  bool _internal_has_regress_log() const;

  public:
  void clear_regress_log() ;
  const ::tensorflow::serving::RegressLog& regress_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::RegressLog* release_regress_log();
  ::tensorflow::serving::RegressLog* mutable_regress_log();
  void set_allocated_regress_log(::tensorflow::serving::RegressLog* value);
  void unsafe_arena_set_allocated_regress_log(::tensorflow::serving::RegressLog* value);
  ::tensorflow::serving::RegressLog* unsafe_arena_release_regress_log();

  private:
  const ::tensorflow::serving::RegressLog& _internal_regress_log() const;
  ::tensorflow::serving::RegressLog* _internal_mutable_regress_log();

  public:
  // .tensorflow.serving.PredictLog predict_log = 6;
  bool has_predict_log() const;
  private:
  bool _internal_has_predict_log() const;

  public:
  void clear_predict_log() ;
  const ::tensorflow::serving::PredictLog& predict_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictLog* release_predict_log();
  ::tensorflow::serving::PredictLog* mutable_predict_log();
  void set_allocated_predict_log(::tensorflow::serving::PredictLog* value);
  void unsafe_arena_set_allocated_predict_log(::tensorflow::serving::PredictLog* value);
  ::tensorflow::serving::PredictLog* unsafe_arena_release_predict_log();

  private:
  const ::tensorflow::serving::PredictLog& _internal_predict_log() const;
  ::tensorflow::serving::PredictLog* _internal_mutable_predict_log();

  public:
  // .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
  bool has_predict_streamed_log() const;
  private:
  bool _internal_has_predict_streamed_log() const;

  public:
  void clear_predict_streamed_log() ;
  const ::tensorflow::serving::PredictStreamedLog& predict_streamed_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::PredictStreamedLog* release_predict_streamed_log();
  ::tensorflow::serving::PredictStreamedLog* mutable_predict_streamed_log();
  void set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* value);
  void unsafe_arena_set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* value);
  ::tensorflow::serving::PredictStreamedLog* unsafe_arena_release_predict_streamed_log();

  private:
  const ::tensorflow::serving::PredictStreamedLog& _internal_predict_streamed_log() const;
  ::tensorflow::serving::PredictStreamedLog* _internal_mutable_predict_streamed_log();

  public:
  // .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
  bool has_multi_inference_log() const;
  private:
  bool _internal_has_multi_inference_log() const;

  public:
  void clear_multi_inference_log() ;
  const ::tensorflow::serving::MultiInferenceLog& multi_inference_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::MultiInferenceLog* release_multi_inference_log();
  ::tensorflow::serving::MultiInferenceLog* mutable_multi_inference_log();
  void set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* value);
  void unsafe_arena_set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* value);
  ::tensorflow::serving::MultiInferenceLog* unsafe_arena_release_multi_inference_log();

  private:
  const ::tensorflow::serving::MultiInferenceLog& _internal_multi_inference_log() const;
  ::tensorflow::serving::MultiInferenceLog* _internal_mutable_multi_inference_log();

  public:
  // .tensorflow.serving.SessionRunLog session_run_log = 5;
  bool has_session_run_log() const;
  private:
  bool _internal_has_session_run_log() const;

  public:
  void clear_session_run_log() ;
  const ::tensorflow::serving::SessionRunLog& session_run_log() const;
  PROTOBUF_NODISCARD ::tensorflow::serving::SessionRunLog* release_session_run_log();
  ::tensorflow::serving::SessionRunLog* mutable_session_run_log();
  void set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* value);
  void unsafe_arena_set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* value);
  ::tensorflow::serving::SessionRunLog* unsafe_arena_release_session_run_log();

  private:
  const ::tensorflow::serving::SessionRunLog& _internal_session_run_log() const;
  ::tensorflow::serving::SessionRunLog* _internal_mutable_session_run_log();

  public:
  void clear_log_type();
  LogTypeCase log_type_case() const;
  // @@protoc_insertion_point(class_scope:tensorflow.serving.PredictionLog)
 private:
  class _Internal;
  void set_has_classify_log();
  void set_has_regress_log();
  void set_has_predict_log();
  void set_has_predict_streamed_log();
  void set_has_multi_inference_log();
  void set_has_session_run_log();
  inline bool has_log_type() const;
  inline void clear_has_log_type();
  friend class ::google::protobuf::internal::TcParser;
  static const ::google::protobuf::internal::TcParseTable<
      0, 7, 7,
      0, 2>
      _table_;

  friend class ::google::protobuf::MessageLite;
  friend class ::google::protobuf::Arena;
  template <typename T>
  friend class ::google::protobuf::Arena::InternalHelper;
  using InternalArenaConstructable_ = void;
  using DestructorSkippable_ = void;
  struct Impl_ {
    inline explicit constexpr Impl_(
        ::google::protobuf::internal::ConstantInitialized) noexcept;
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena);
    inline explicit Impl_(::google::protobuf::internal::InternalVisibility visibility,
                          ::google::protobuf::Arena* arena, const Impl_& from,
                          const PredictionLog& from_msg);
    ::google::protobuf::internal::HasBits<1> _has_bits_;
    ::google::protobuf::internal::CachedSize _cached_size_;
    ::tensorflow::serving::LogMetadata* log_metadata_;
    union LogTypeUnion {
      constexpr LogTypeUnion() : _constinit_{} {}
      ::google::protobuf::internal::ConstantInitialized _constinit_;
      ::tensorflow::serving::ClassifyLog* classify_log_;
      ::tensorflow::serving::RegressLog* regress_log_;
      ::tensorflow::serving::PredictLog* predict_log_;
      ::tensorflow::serving::PredictStreamedLog* predict_streamed_log_;
      ::tensorflow::serving::MultiInferenceLog* multi_inference_log_;
      ::tensorflow::serving::SessionRunLog* session_run_log_;
    } log_type_;
    ::uint32_t _oneof_case_[1];
    PROTOBUF_TSAN_DECLARE_MEMBER
  };
  union { Impl_ _impl_; };
  friend struct ::TableStruct_tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto;
};

// ===================================================================




// ===================================================================


#ifdef __GNUC__
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// -------------------------------------------------------------------

// ClassifyLog

// .tensorflow.serving.ClassificationRequest request = 1;
inline bool ClassifyLog::has_request() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::ClassificationRequest& ClassifyLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::ClassificationRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ClassificationRequest&>(::tensorflow::serving::_ClassificationRequest_default_instance_);
}
inline const ::tensorflow::serving::ClassificationRequest& ClassifyLog::request() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ClassifyLog.request)
  return _internal_request();
}
inline void ClassifyLog::unsafe_arena_set_allocated_request(::tensorflow::serving::ClassificationRequest* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = reinterpret_cast<::tensorflow::serving::ClassificationRequest*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.request)
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::ClassificationRequest* released = _impl_.request_;
  _impl_.request_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::unsafe_arena_release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.ClassifyLog.request)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::ClassificationRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.request_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::ClassificationRequest>(GetArena());
    _impl_.request_ = reinterpret_cast<::tensorflow::serving::ClassificationRequest*>(p);
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::ClassificationRequest* ClassifyLog::mutable_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::ClassificationRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ClassifyLog.request)
  return _msg;
}
inline void ClassifyLog::set_allocated_request(::tensorflow::serving::ClassificationRequest* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.request_ = reinterpret_cast<::tensorflow::serving::ClassificationRequest*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ClassifyLog.request)
}

// .tensorflow.serving.ClassificationResponse response = 2;
inline bool ClassifyLog::has_response() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.response_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::ClassificationResponse& ClassifyLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::ClassificationResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::ClassificationResponse&>(::tensorflow::serving::_ClassificationResponse_default_instance_);
}
inline const ::tensorflow::serving::ClassificationResponse& ClassifyLog::response() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ClassifyLog.response)
  return _internal_response();
}
inline void ClassifyLog::unsafe_arena_set_allocated_response(::tensorflow::serving::ClassificationResponse* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = reinterpret_cast<::tensorflow::serving::ClassificationResponse*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ClassifyLog.response)
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::ClassificationResponse* released = _impl_.response_;
  _impl_.response_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::unsafe_arena_release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.ClassifyLog.response)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::ClassificationResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.response_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::ClassificationResponse>(GetArena());
    _impl_.response_ = reinterpret_cast<::tensorflow::serving::ClassificationResponse*>(p);
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::ClassificationResponse* ClassifyLog::mutable_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::tensorflow::serving::ClassificationResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ClassifyLog.response)
  return _msg;
}
inline void ClassifyLog::set_allocated_response(::tensorflow::serving::ClassificationResponse* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.response_ = reinterpret_cast<::tensorflow::serving::ClassificationResponse*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ClassifyLog.response)
}

// -------------------------------------------------------------------

// RegressLog

// .tensorflow.serving.RegressionRequest request = 1;
inline bool RegressLog::has_request() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::RegressionRequest& RegressLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::RegressionRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::RegressionRequest&>(::tensorflow::serving::_RegressionRequest_default_instance_);
}
inline const ::tensorflow::serving::RegressionRequest& RegressLog::request() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.RegressLog.request)
  return _internal_request();
}
inline void RegressLog::unsafe_arena_set_allocated_request(::tensorflow::serving::RegressionRequest* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = reinterpret_cast<::tensorflow::serving::RegressionRequest*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.request)
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::RegressionRequest* released = _impl_.request_;
  _impl_.request_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::unsafe_arena_release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.RegressLog.request)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::RegressionRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.request_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::RegressionRequest>(GetArena());
    _impl_.request_ = reinterpret_cast<::tensorflow::serving::RegressionRequest*>(p);
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::RegressionRequest* RegressLog::mutable_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::RegressionRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.RegressLog.request)
  return _msg;
}
inline void RegressLog::set_allocated_request(::tensorflow::serving::RegressionRequest* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.request_ = reinterpret_cast<::tensorflow::serving::RegressionRequest*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.RegressLog.request)
}

// .tensorflow.serving.RegressionResponse response = 2;
inline bool RegressLog::has_response() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.response_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::RegressionResponse& RegressLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::RegressionResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::RegressionResponse&>(::tensorflow::serving::_RegressionResponse_default_instance_);
}
inline const ::tensorflow::serving::RegressionResponse& RegressLog::response() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.RegressLog.response)
  return _internal_response();
}
inline void RegressLog::unsafe_arena_set_allocated_response(::tensorflow::serving::RegressionResponse* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = reinterpret_cast<::tensorflow::serving::RegressionResponse*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.RegressLog.response)
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::RegressionResponse* released = _impl_.response_;
  _impl_.response_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::unsafe_arena_release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.RegressLog.response)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::RegressionResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.response_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::RegressionResponse>(GetArena());
    _impl_.response_ = reinterpret_cast<::tensorflow::serving::RegressionResponse*>(p);
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::RegressionResponse* RegressLog::mutable_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::tensorflow::serving::RegressionResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.RegressLog.response)
  return _msg;
}
inline void RegressLog::set_allocated_response(::tensorflow::serving::RegressionResponse* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.response_ = reinterpret_cast<::tensorflow::serving::RegressionResponse*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.RegressLog.response)
}

// -------------------------------------------------------------------

// PredictLog

// .tensorflow.serving.PredictRequest request = 1;
inline bool PredictLog::has_request() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::PredictRequest& PredictLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::PredictRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictRequest&>(::tensorflow::serving::_PredictRequest_default_instance_);
}
inline const ::tensorflow::serving::PredictRequest& PredictLog::request() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictLog.request)
  return _internal_request();
}
inline void PredictLog::unsafe_arena_set_allocated_request(::tensorflow::serving::PredictRequest* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = reinterpret_cast<::tensorflow::serving::PredictRequest*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.request)
}
inline ::tensorflow::serving::PredictRequest* PredictLog::release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::PredictRequest* released = _impl_.request_;
  _impl_.request_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::unsafe_arena_release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictLog.request)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::PredictRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.request_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::PredictRequest>(GetArena());
    _impl_.request_ = reinterpret_cast<::tensorflow::serving::PredictRequest*>(p);
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::PredictRequest* PredictLog::mutable_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::PredictRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictLog.request)
  return _msg;
}
inline void PredictLog::set_allocated_request(::tensorflow::serving::PredictRequest* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.request_ = reinterpret_cast<::tensorflow::serving::PredictRequest*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictLog.request)
}

// .tensorflow.serving.PredictResponse response = 2;
inline bool PredictLog::has_response() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.response_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::PredictResponse& PredictLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::PredictResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::PredictResponse&>(::tensorflow::serving::_PredictResponse_default_instance_);
}
inline const ::tensorflow::serving::PredictResponse& PredictLog::response() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictLog.response)
  return _internal_response();
}
inline void PredictLog::unsafe_arena_set_allocated_response(::tensorflow::serving::PredictResponse* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = reinterpret_cast<::tensorflow::serving::PredictResponse*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictLog.response)
}
inline ::tensorflow::serving::PredictResponse* PredictLog::release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::PredictResponse* released = _impl_.response_;
  _impl_.response_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::unsafe_arena_release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictLog.response)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::PredictResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.response_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::PredictResponse>(GetArena());
    _impl_.response_ = reinterpret_cast<::tensorflow::serving::PredictResponse*>(p);
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::PredictResponse* PredictLog::mutable_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::tensorflow::serving::PredictResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictLog.response)
  return _msg;
}
inline void PredictLog::set_allocated_response(::tensorflow::serving::PredictResponse* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.response_ = reinterpret_cast<::tensorflow::serving::PredictResponse*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictLog.response)
}

// -------------------------------------------------------------------

// PredictStreamedLog

// repeated .tensorflow.serving.PredictRequest request = 1;
inline int PredictStreamedLog::_internal_request_size() const {
  return _internal_request().size();
}
inline int PredictStreamedLog::request_size() const {
  return _internal_request_size();
}
inline ::tensorflow::serving::PredictRequest* PredictStreamedLog::mutable_request(int index)
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictStreamedLog.request)
  return _internal_mutable_request()->Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>* PredictStreamedLog::mutable_request()
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.PredictStreamedLog.request)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  return _internal_mutable_request();
}
inline const ::tensorflow::serving::PredictRequest& PredictStreamedLog::request(int index) const
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedLog.request)
  return _internal_request().Get(index);
}
inline ::tensorflow::serving::PredictRequest* PredictStreamedLog::add_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::tensorflow::serving::PredictRequest* _add = _internal_mutable_request()->Add();
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictStreamedLog.request)
  return _add;
}
inline const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>& PredictStreamedLog::request() const
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_list:tensorflow.serving.PredictStreamedLog.request)
  return _internal_request();
}
inline const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>&
PredictStreamedLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.request_;
}
inline ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictRequest>*
PredictStreamedLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return &_impl_.request_;
}

// repeated .tensorflow.serving.PredictResponse response = 2;
inline int PredictStreamedLog::_internal_response_size() const {
  return _internal_response().size();
}
inline int PredictStreamedLog::response_size() const {
  return _internal_response_size();
}
inline ::tensorflow::serving::PredictResponse* PredictStreamedLog::mutable_response(int index)
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictStreamedLog.response)
  return _internal_mutable_response()->Mutable(index);
}
inline ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>* PredictStreamedLog::mutable_response()
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.PredictStreamedLog.response)
  ::google::protobuf::internal::TSanWrite(&_impl_);
  return _internal_mutable_response();
}
inline const ::tensorflow::serving::PredictResponse& PredictStreamedLog::response(int index) const
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictStreamedLog.response)
  return _internal_response().Get(index);
}
inline ::tensorflow::serving::PredictResponse* PredictStreamedLog::add_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  ::tensorflow::serving::PredictResponse* _add = _internal_mutable_response()->Add();
  // @@protoc_insertion_point(field_add:tensorflow.serving.PredictStreamedLog.response)
  return _add;
}
inline const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>& PredictStreamedLog::response() const
    ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_list:tensorflow.serving.PredictStreamedLog.response)
  return _internal_response();
}
inline const ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>&
PredictStreamedLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return _impl_.response_;
}
inline ::google::protobuf::RepeatedPtrField<::tensorflow::serving::PredictResponse>*
PredictStreamedLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanRead(&_impl_);
  return &_impl_.response_;
}

// -------------------------------------------------------------------

// MultiInferenceLog

// .tensorflow.serving.MultiInferenceRequest request = 1;
inline bool MultiInferenceLog::has_request() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::MultiInferenceRequest& MultiInferenceLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::MultiInferenceRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::MultiInferenceRequest&>(::tensorflow::serving::_MultiInferenceRequest_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceRequest& MultiInferenceLog::request() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.MultiInferenceLog.request)
  return _internal_request();
}
inline void MultiInferenceLog::unsafe_arena_set_allocated_request(::tensorflow::serving::MultiInferenceRequest* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = reinterpret_cast<::tensorflow::serving::MultiInferenceRequest*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::MultiInferenceRequest* released = _impl_.request_;
  _impl_.request_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::unsafe_arena_release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.MultiInferenceLog.request)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::MultiInferenceRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.request_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::MultiInferenceRequest>(GetArena());
    _impl_.request_ = reinterpret_cast<::tensorflow::serving::MultiInferenceRequest*>(p);
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::MultiInferenceRequest* MultiInferenceLog::mutable_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::MultiInferenceRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.MultiInferenceLog.request)
  return _msg;
}
inline void MultiInferenceLog::set_allocated_request(::tensorflow::serving::MultiInferenceRequest* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.request_ = reinterpret_cast<::tensorflow::serving::MultiInferenceRequest*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.MultiInferenceLog.request)
}

// .tensorflow.serving.MultiInferenceResponse response = 2;
inline bool MultiInferenceLog::has_response() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.response_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::MultiInferenceResponse& MultiInferenceLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::MultiInferenceResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::MultiInferenceResponse&>(::tensorflow::serving::_MultiInferenceResponse_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceResponse& MultiInferenceLog::response() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.MultiInferenceLog.response)
  return _internal_response();
}
inline void MultiInferenceLog::unsafe_arena_set_allocated_response(::tensorflow::serving::MultiInferenceResponse* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = reinterpret_cast<::tensorflow::serving::MultiInferenceResponse*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::MultiInferenceResponse* released = _impl_.response_;
  _impl_.response_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::unsafe_arena_release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.MultiInferenceLog.response)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::MultiInferenceResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.response_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::MultiInferenceResponse>(GetArena());
    _impl_.response_ = reinterpret_cast<::tensorflow::serving::MultiInferenceResponse*>(p);
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::MultiInferenceResponse* MultiInferenceLog::mutable_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::tensorflow::serving::MultiInferenceResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.MultiInferenceLog.response)
  return _msg;
}
inline void MultiInferenceLog::set_allocated_response(::tensorflow::serving::MultiInferenceResponse* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.response_ = reinterpret_cast<::tensorflow::serving::MultiInferenceResponse*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.MultiInferenceLog.response)
}

// -------------------------------------------------------------------

// SessionRunLog

// .tensorflow.serving.SessionRunRequest request = 1;
inline bool SessionRunLog::has_request() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.request_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::SessionRunRequest& SessionRunLog::_internal_request() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::SessionRunRequest* p = _impl_.request_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::SessionRunRequest&>(::tensorflow::serving::_SessionRunRequest_default_instance_);
}
inline const ::tensorflow::serving::SessionRunRequest& SessionRunLog::request() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunLog.request)
  return _internal_request();
}
inline void SessionRunLog::unsafe_arena_set_allocated_request(::tensorflow::serving::SessionRunRequest* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }
  _impl_.request_ = reinterpret_cast<::tensorflow::serving::SessionRunRequest*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.request)
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::SessionRunRequest* released = _impl_.request_;
  _impl_.request_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::unsafe_arena_release_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunLog.request)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::SessionRunRequest* temp = _impl_.request_;
  _impl_.request_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::_internal_mutable_request() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.request_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::SessionRunRequest>(GetArena());
    _impl_.request_ = reinterpret_cast<::tensorflow::serving::SessionRunRequest*>(p);
  }
  return _impl_.request_;
}
inline ::tensorflow::serving::SessionRunRequest* SessionRunLog::mutable_request() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::SessionRunRequest* _msg = _internal_mutable_request();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunLog.request)
  return _msg;
}
inline void SessionRunLog::set_allocated_request(::tensorflow::serving::SessionRunRequest* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.request_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.request_ = reinterpret_cast<::tensorflow::serving::SessionRunRequest*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunLog.request)
}

// .tensorflow.serving.SessionRunResponse response = 2;
inline bool SessionRunLog::has_response() const {
  bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.response_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::SessionRunResponse& SessionRunLog::_internal_response() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::SessionRunResponse* p = _impl_.response_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::SessionRunResponse&>(::tensorflow::serving::_SessionRunResponse_default_instance_);
}
inline const ::tensorflow::serving::SessionRunResponse& SessionRunLog::response() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionRunLog.response)
  return _internal_response();
}
inline void SessionRunLog::unsafe_arena_set_allocated_response(::tensorflow::serving::SessionRunResponse* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }
  _impl_.response_ = reinterpret_cast<::tensorflow::serving::SessionRunResponse*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.SessionRunLog.response)
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::SessionRunResponse* released = _impl_.response_;
  _impl_.response_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::unsafe_arena_release_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionRunLog.response)

  _impl_._has_bits_[0] &= ~0x00000002u;
  ::tensorflow::serving::SessionRunResponse* temp = _impl_.response_;
  _impl_.response_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::_internal_mutable_response() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.response_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::SessionRunResponse>(GetArena());
    _impl_.response_ = reinterpret_cast<::tensorflow::serving::SessionRunResponse*>(p);
  }
  return _impl_.response_;
}
inline ::tensorflow::serving::SessionRunResponse* SessionRunLog::mutable_response() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000002u;
  ::tensorflow::serving::SessionRunResponse* _msg = _internal_mutable_response();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionRunLog.response)
  return _msg;
}
inline void SessionRunLog::set_allocated_response(::tensorflow::serving::SessionRunResponse* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.response_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000002u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000002u;
  }

  _impl_.response_ = reinterpret_cast<::tensorflow::serving::SessionRunResponse*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionRunLog.response)
}

// -------------------------------------------------------------------

// PredictionLog

// .tensorflow.serving.LogMetadata log_metadata = 1;
inline bool PredictionLog::has_log_metadata() const {
  bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || _impl_.log_metadata_ != nullptr);
  return value;
}
inline const ::tensorflow::serving::LogMetadata& PredictionLog::_internal_log_metadata() const {
  ::google::protobuf::internal::TSanRead(&_impl_);
  const ::tensorflow::serving::LogMetadata* p = _impl_.log_metadata_;
  return p != nullptr ? *p : reinterpret_cast<const ::tensorflow::serving::LogMetadata&>(::tensorflow::serving::_LogMetadata_default_instance_);
}
inline const ::tensorflow::serving::LogMetadata& PredictionLog::log_metadata() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.log_metadata)
  return _internal_log_metadata();
}
inline void PredictionLog::unsafe_arena_set_allocated_log_metadata(::tensorflow::serving::LogMetadata* value) {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (GetArena() == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.log_metadata_);
  }
  _impl_.log_metadata_ = reinterpret_cast<::tensorflow::serving::LogMetadata*>(value);
  if (value != nullptr) {
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::release_log_metadata() {
  ::google::protobuf::internal::TSanWrite(&_impl_);

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::LogMetadata* released = _impl_.log_metadata_;
  _impl_.log_metadata_ = nullptr;
  if (::google::protobuf::internal::DebugHardenForceCopyInRelease()) {
    auto* old = reinterpret_cast<::google::protobuf::MessageLite*>(released);
    released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    if (GetArena() == nullptr) {
      delete old;
    }
  } else {
    if (GetArena() != nullptr) {
      released = ::google::protobuf::internal::DuplicateIfNonNull(released);
    }
  }
  return released;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::unsafe_arena_release_log_metadata() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.log_metadata)

  _impl_._has_bits_[0] &= ~0x00000001u;
  ::tensorflow::serving::LogMetadata* temp = _impl_.log_metadata_;
  _impl_.log_metadata_ = nullptr;
  return temp;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::_internal_mutable_log_metadata() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (_impl_.log_metadata_ == nullptr) {
    auto* p = ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::LogMetadata>(GetArena());
    _impl_.log_metadata_ = reinterpret_cast<::tensorflow::serving::LogMetadata*>(p);
  }
  return _impl_.log_metadata_;
}
inline ::tensorflow::serving::LogMetadata* PredictionLog::mutable_log_metadata() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  _impl_._has_bits_[0] |= 0x00000001u;
  ::tensorflow::serving::LogMetadata* _msg = _internal_mutable_log_metadata();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.log_metadata)
  return _msg;
}
inline void PredictionLog::set_allocated_log_metadata(::tensorflow::serving::LogMetadata* value) {
  ::google::protobuf::Arena* message_arena = GetArena();
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (message_arena == nullptr) {
    delete reinterpret_cast<::google::protobuf::MessageLite*>(_impl_.log_metadata_);
  }

  if (value != nullptr) {
    ::google::protobuf::Arena* submessage_arena = reinterpret_cast<::google::protobuf::MessageLite*>(value)->GetArena();
    if (message_arena != submessage_arena) {
      value = ::google::protobuf::internal::GetOwnedMessage(message_arena, value, submessage_arena);
    }
    _impl_._has_bits_[0] |= 0x00000001u;
  } else {
    _impl_._has_bits_[0] &= ~0x00000001u;
  }

  _impl_.log_metadata_ = reinterpret_cast<::tensorflow::serving::LogMetadata*>(value);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.PredictionLog.log_metadata)
}

// .tensorflow.serving.ClassifyLog classify_log = 2;
inline bool PredictionLog::has_classify_log() const {
  return log_type_case() == kClassifyLog;
}
inline bool PredictionLog::_internal_has_classify_log() const {
  return log_type_case() == kClassifyLog;
}
inline void PredictionLog::set_has_classify_log() {
  _impl_._oneof_case_[0] = kClassifyLog;
}
inline void PredictionLog::clear_classify_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kClassifyLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.classify_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.classify_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::release_classify_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.classify_log)
  if (log_type_case() == kClassifyLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.classify_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.classify_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::ClassifyLog& PredictionLog::_internal_classify_log() const {
  return log_type_case() == kClassifyLog ? *_impl_.log_type_.classify_log_ : reinterpret_cast<::tensorflow::serving::ClassifyLog&>(::tensorflow::serving::_ClassifyLog_default_instance_);
}
inline const ::tensorflow::serving::ClassifyLog& PredictionLog::classify_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.classify_log)
  return _internal_classify_log();
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::unsafe_arena_release_classify_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.classify_log)
  if (log_type_case() == kClassifyLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.classify_log_;
    _impl_.log_type_.classify_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_classify_log(::tensorflow::serving::ClassifyLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_classify_log();
    _impl_.log_type_.classify_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.classify_log)
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::_internal_mutable_classify_log() {
  if (log_type_case() != kClassifyLog) {
    clear_log_type();
    set_has_classify_log();
    _impl_.log_type_.classify_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::ClassifyLog>(GetArena());
  }
  return _impl_.log_type_.classify_log_;
}
inline ::tensorflow::serving::ClassifyLog* PredictionLog::mutable_classify_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::ClassifyLog* _msg = _internal_mutable_classify_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.classify_log)
  return _msg;
}

// .tensorflow.serving.RegressLog regress_log = 3;
inline bool PredictionLog::has_regress_log() const {
  return log_type_case() == kRegressLog;
}
inline bool PredictionLog::_internal_has_regress_log() const {
  return log_type_case() == kRegressLog;
}
inline void PredictionLog::set_has_regress_log() {
  _impl_._oneof_case_[0] = kRegressLog;
}
inline void PredictionLog::clear_regress_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kRegressLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.regress_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.regress_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::RegressLog* PredictionLog::release_regress_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.regress_log)
  if (log_type_case() == kRegressLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.regress_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.regress_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::RegressLog& PredictionLog::_internal_regress_log() const {
  return log_type_case() == kRegressLog ? *_impl_.log_type_.regress_log_ : reinterpret_cast<::tensorflow::serving::RegressLog&>(::tensorflow::serving::_RegressLog_default_instance_);
}
inline const ::tensorflow::serving::RegressLog& PredictionLog::regress_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.regress_log)
  return _internal_regress_log();
}
inline ::tensorflow::serving::RegressLog* PredictionLog::unsafe_arena_release_regress_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.regress_log)
  if (log_type_case() == kRegressLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.regress_log_;
    _impl_.log_type_.regress_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_regress_log(::tensorflow::serving::RegressLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_regress_log();
    _impl_.log_type_.regress_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.regress_log)
}
inline ::tensorflow::serving::RegressLog* PredictionLog::_internal_mutable_regress_log() {
  if (log_type_case() != kRegressLog) {
    clear_log_type();
    set_has_regress_log();
    _impl_.log_type_.regress_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::RegressLog>(GetArena());
  }
  return _impl_.log_type_.regress_log_;
}
inline ::tensorflow::serving::RegressLog* PredictionLog::mutable_regress_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::RegressLog* _msg = _internal_mutable_regress_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.regress_log)
  return _msg;
}

// .tensorflow.serving.PredictLog predict_log = 6;
inline bool PredictionLog::has_predict_log() const {
  return log_type_case() == kPredictLog;
}
inline bool PredictionLog::_internal_has_predict_log() const {
  return log_type_case() == kPredictLog;
}
inline void PredictionLog::set_has_predict_log() {
  _impl_._oneof_case_[0] = kPredictLog;
}
inline void PredictionLog::clear_predict_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kPredictLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.predict_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.predict_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::PredictLog* PredictionLog::release_predict_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.predict_log)
  if (log_type_case() == kPredictLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.predict_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.predict_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::PredictLog& PredictionLog::_internal_predict_log() const {
  return log_type_case() == kPredictLog ? *_impl_.log_type_.predict_log_ : reinterpret_cast<::tensorflow::serving::PredictLog&>(::tensorflow::serving::_PredictLog_default_instance_);
}
inline const ::tensorflow::serving::PredictLog& PredictionLog::predict_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.predict_log)
  return _internal_predict_log();
}
inline ::tensorflow::serving::PredictLog* PredictionLog::unsafe_arena_release_predict_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.predict_log)
  if (log_type_case() == kPredictLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.predict_log_;
    _impl_.log_type_.predict_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_predict_log(::tensorflow::serving::PredictLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_predict_log();
    _impl_.log_type_.predict_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.predict_log)
}
inline ::tensorflow::serving::PredictLog* PredictionLog::_internal_mutable_predict_log() {
  if (log_type_case() != kPredictLog) {
    clear_log_type();
    set_has_predict_log();
    _impl_.log_type_.predict_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::PredictLog>(GetArena());
  }
  return _impl_.log_type_.predict_log_;
}
inline ::tensorflow::serving::PredictLog* PredictionLog::mutable_predict_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::PredictLog* _msg = _internal_mutable_predict_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.predict_log)
  return _msg;
}

// .tensorflow.serving.PredictStreamedLog predict_streamed_log = 7;
inline bool PredictionLog::has_predict_streamed_log() const {
  return log_type_case() == kPredictStreamedLog;
}
inline bool PredictionLog::_internal_has_predict_streamed_log() const {
  return log_type_case() == kPredictStreamedLog;
}
inline void PredictionLog::set_has_predict_streamed_log() {
  _impl_._oneof_case_[0] = kPredictStreamedLog;
}
inline void PredictionLog::clear_predict_streamed_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kPredictStreamedLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.predict_streamed_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.predict_streamed_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::release_predict_streamed_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.predict_streamed_log)
  if (log_type_case() == kPredictStreamedLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.predict_streamed_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.predict_streamed_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::PredictStreamedLog& PredictionLog::_internal_predict_streamed_log() const {
  return log_type_case() == kPredictStreamedLog ? *_impl_.log_type_.predict_streamed_log_ : reinterpret_cast<::tensorflow::serving::PredictStreamedLog&>(::tensorflow::serving::_PredictStreamedLog_default_instance_);
}
inline const ::tensorflow::serving::PredictStreamedLog& PredictionLog::predict_streamed_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.predict_streamed_log)
  return _internal_predict_streamed_log();
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::unsafe_arena_release_predict_streamed_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.predict_streamed_log)
  if (log_type_case() == kPredictStreamedLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.predict_streamed_log_;
    _impl_.log_type_.predict_streamed_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_predict_streamed_log(::tensorflow::serving::PredictStreamedLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_predict_streamed_log();
    _impl_.log_type_.predict_streamed_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.predict_streamed_log)
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::_internal_mutable_predict_streamed_log() {
  if (log_type_case() != kPredictStreamedLog) {
    clear_log_type();
    set_has_predict_streamed_log();
    _impl_.log_type_.predict_streamed_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::PredictStreamedLog>(GetArena());
  }
  return _impl_.log_type_.predict_streamed_log_;
}
inline ::tensorflow::serving::PredictStreamedLog* PredictionLog::mutable_predict_streamed_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::PredictStreamedLog* _msg = _internal_mutable_predict_streamed_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.predict_streamed_log)
  return _msg;
}

// .tensorflow.serving.MultiInferenceLog multi_inference_log = 4;
inline bool PredictionLog::has_multi_inference_log() const {
  return log_type_case() == kMultiInferenceLog;
}
inline bool PredictionLog::_internal_has_multi_inference_log() const {
  return log_type_case() == kMultiInferenceLog;
}
inline void PredictionLog::set_has_multi_inference_log() {
  _impl_._oneof_case_[0] = kMultiInferenceLog;
}
inline void PredictionLog::clear_multi_inference_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kMultiInferenceLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.multi_inference_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.multi_inference_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::release_multi_inference_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.multi_inference_log)
  if (log_type_case() == kMultiInferenceLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.multi_inference_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.multi_inference_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::MultiInferenceLog& PredictionLog::_internal_multi_inference_log() const {
  return log_type_case() == kMultiInferenceLog ? *_impl_.log_type_.multi_inference_log_ : reinterpret_cast<::tensorflow::serving::MultiInferenceLog&>(::tensorflow::serving::_MultiInferenceLog_default_instance_);
}
inline const ::tensorflow::serving::MultiInferenceLog& PredictionLog::multi_inference_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.multi_inference_log)
  return _internal_multi_inference_log();
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::unsafe_arena_release_multi_inference_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.multi_inference_log)
  if (log_type_case() == kMultiInferenceLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.multi_inference_log_;
    _impl_.log_type_.multi_inference_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_multi_inference_log(::tensorflow::serving::MultiInferenceLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_multi_inference_log();
    _impl_.log_type_.multi_inference_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.multi_inference_log)
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::_internal_mutable_multi_inference_log() {
  if (log_type_case() != kMultiInferenceLog) {
    clear_log_type();
    set_has_multi_inference_log();
    _impl_.log_type_.multi_inference_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::MultiInferenceLog>(GetArena());
  }
  return _impl_.log_type_.multi_inference_log_;
}
inline ::tensorflow::serving::MultiInferenceLog* PredictionLog::mutable_multi_inference_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::MultiInferenceLog* _msg = _internal_mutable_multi_inference_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.multi_inference_log)
  return _msg;
}

// .tensorflow.serving.SessionRunLog session_run_log = 5;
inline bool PredictionLog::has_session_run_log() const {
  return log_type_case() == kSessionRunLog;
}
inline bool PredictionLog::_internal_has_session_run_log() const {
  return log_type_case() == kSessionRunLog;
}
inline void PredictionLog::set_has_session_run_log() {
  _impl_._oneof_case_[0] = kSessionRunLog;
}
inline void PredictionLog::clear_session_run_log() {
  ::google::protobuf::internal::TSanWrite(&_impl_);
  if (log_type_case() == kSessionRunLog) {
    if (GetArena() == nullptr) {
      delete _impl_.log_type_.session_run_log_;
    } else if (::google::protobuf::internal::DebugHardenClearOneofMessageOnArena()) {
      ::google::protobuf::internal::MaybePoisonAfterClear(_impl_.log_type_.session_run_log_);
    }
    clear_has_log_type();
  }
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::release_session_run_log() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.PredictionLog.session_run_log)
  if (log_type_case() == kSessionRunLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.session_run_log_;
    if (GetArena() != nullptr) {
      temp = ::google::protobuf::internal::DuplicateIfNonNull(temp);
    }
    _impl_.log_type_.session_run_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline const ::tensorflow::serving::SessionRunLog& PredictionLog::_internal_session_run_log() const {
  return log_type_case() == kSessionRunLog ? *_impl_.log_type_.session_run_log_ : reinterpret_cast<::tensorflow::serving::SessionRunLog&>(::tensorflow::serving::_SessionRunLog_default_instance_);
}
inline const ::tensorflow::serving::SessionRunLog& PredictionLog::session_run_log() const ABSL_ATTRIBUTE_LIFETIME_BOUND {
  // @@protoc_insertion_point(field_get:tensorflow.serving.PredictionLog.session_run_log)
  return _internal_session_run_log();
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::unsafe_arena_release_session_run_log() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.PredictionLog.session_run_log)
  if (log_type_case() == kSessionRunLog) {
    clear_has_log_type();
    auto* temp = _impl_.log_type_.session_run_log_;
    _impl_.log_type_.session_run_log_ = nullptr;
    return temp;
  } else {
    return nullptr;
  }
}
inline void PredictionLog::unsafe_arena_set_allocated_session_run_log(::tensorflow::serving::SessionRunLog* value) {
  // We rely on the oneof clear method to free the earlier contents
  // of this oneof. We can directly use the pointer we're given to
  // set the new value.
  clear_log_type();
  if (value) {
    set_has_session_run_log();
    _impl_.log_type_.session_run_log_ = value;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.PredictionLog.session_run_log)
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::_internal_mutable_session_run_log() {
  if (log_type_case() != kSessionRunLog) {
    clear_log_type();
    set_has_session_run_log();
    _impl_.log_type_.session_run_log_ =
        ::google::protobuf::Message::DefaultConstruct<::tensorflow::serving::SessionRunLog>(GetArena());
  }
  return _impl_.log_type_.session_run_log_;
}
inline ::tensorflow::serving::SessionRunLog* PredictionLog::mutable_session_run_log() ABSL_ATTRIBUTE_LIFETIME_BOUND {
  ::tensorflow::serving::SessionRunLog* _msg = _internal_mutable_session_run_log();
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.PredictionLog.session_run_log)
  return _msg;
}

inline bool PredictionLog::has_log_type() const {
  return log_type_case() != LOG_TYPE_NOT_SET;
}
inline void PredictionLog::clear_has_log_type() {
  _impl_._oneof_case_[0] = LOG_TYPE_NOT_SET;
}
inline PredictionLog::LogTypeCase PredictionLog::log_type_case() const {
  return PredictionLog::LogTypeCase(_impl_._oneof_case_[0]);
}
#ifdef __GNUC__
#pragma GCC diagnostic pop
#endif  // __GNUC__

// @@protoc_insertion_point(namespace_scope)
}  // namespace serving
}  // namespace tensorflow


// @@protoc_insertion_point(global_scope)

#include "google/protobuf/port_undef.inc"

#endif  // tensorflow_5fserving_2fapis_2fprediction_5flog_2eproto_2epb_2eh
